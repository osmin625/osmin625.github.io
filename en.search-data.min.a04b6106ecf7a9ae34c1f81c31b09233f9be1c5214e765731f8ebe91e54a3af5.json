[{"id":0,"href":"/posts/creating-a-new-theme/","title":"Creating a New Theme","section":"Blog","content":"\rIntroduction\r#\rThis tutorial will show you how to create a simple theme in Hugo. I assume that you are familiar with HTML, the bash command line, and that you are comfortable using Markdown to format content. I\u0026rsquo;ll explain how Hugo uses templates and how you can organize your templates to create a theme. I won\u0026rsquo;t cover using CSS to style your theme.\nWe\u0026rsquo;ll start with creating a new site with a very basic template. Then we\u0026rsquo;ll add in a few pages and posts. With small variations on that, you will be able to create many different types of web sites.\nIn this tutorial, commands that you enter will start with the \u0026ldquo;$\u0026rdquo; prompt. The output will follow. Lines that start with \u0026ldquo;#\u0026rdquo; are comments that I\u0026rsquo;ve added to explain a point. When I show updates to a file, the \u0026ldquo;:wq\u0026rdquo; on the last line means to save the file.\nHere\u0026rsquo;s an example:\n## this is a comment\r$ echo this is a command\rthis is a command\r## edit the file\r$ vi foo.md\r+++\rdate = \u0026#34;2014-09-28\u0026#34;\rtitle = \u0026#34;creating a new theme\u0026#34;\r+++\rbah and humbug\r:wq\r## show it\r$ cat foo.md\r+++\rdate = \u0026#34;2014-09-28\u0026#34;\rtitle = \u0026#34;creating a new theme\u0026#34;\r+++\rbah and humbug\r$ Some Definitions\r#\rThere are a few concepts that you need to understand before creating a theme.\nSkins\r#\rSkins are the files responsible for the look and feel of your site. It’s the CSS that controls colors and fonts, it’s the Javascript that determines actions and reactions. It’s also the rules that Hugo uses to transform your content into the HTML that the site will serve to visitors.\nYou have two ways to create a skin. The simplest way is to create it in the layouts/ directory. If you do, then you don’t have to worry about configuring Hugo to recognize it. The first place that Hugo will look for rules and files is in the layouts/ directory so it will always find the skin.\nYour second choice is to create it in a sub-directory of the themes/ directory. If you do, then you must always tell Hugo where to search for the skin. It’s extra work, though, so why bother with it?\nThe difference between creating a skin in layouts/ and creating it in themes/ is very subtle. A skin in layouts/ can’t be customized without updating the templates and static files that it is built from. A skin created in themes/, on the other hand, can be and that makes it easier for other people to use it.\nThe rest of this tutorial will call a skin created in the themes/ directory a theme.\nNote that you can use this tutorial to create a skin in the layouts/ directory if you wish to. The main difference will be that you won’t need to update the site’s configuration file to use a theme.\nThe Home Page\r#\rThe home page, or landing page, is the first page that many visitors to a site see. It is the index.html file in the root directory of the web site. Since Hugo writes files to the public/ directory, our home page is public/index.html.\nSite Configuration File\r#\rWhen Hugo runs, it looks for a configuration file that contains settings that override default values for the entire site. The file can use TOML, YAML, or JSON. I prefer to use TOML for my configuration files. If you prefer to use JSON or YAML, you’ll need to translate my examples. You’ll also need to change the name of the file since Hugo uses the extension to determine how to process it.\nHugo translates Markdown files into HTML. By default, Hugo expects to find Markdown files in your content/ directory and template files in your themes/ directory. It will create HTML files in your public/ directory. You can change this by specifying alternate locations in the configuration file.\nContent\r#\rContent is stored in text files that contain two sections. The first section is the “front matter,” which is the meta-information on the content. The second section contains Markdown that will be converted to HTML.\nFront Matter\r#\rThe front matter is information about the content. Like the configuration file, it can be written in TOML, YAML, or JSON. Unlike the configuration file, Hugo doesn’t use the file’s extension to know the format. It looks for markers to signal the type. TOML is surrounded by “+++”, YAML by “---”, and JSON is enclosed in curly braces. I prefer to use TOML, so you’ll need to translate my examples if you prefer YAML or JSON.\nThe information in the front matter is passed into the template before the content is rendered into HTML.\nMarkdown\r#\rContent is written in Markdown which makes it easier to create the content. Hugo runs the content through a Markdown engine to create the HTML which will be written to the output file.\nTemplate Files\r#\rHugo uses template files to render content into HTML. Template files are a bridge between the content and presentation. Rules in the template define what content is published, where it\u0026rsquo;s published to, and how it will rendered to the HTML file. The template guides the presentation by specifying the style to use.\nThere are three types of templates: single, list, and partial. Each type takes a bit of content as input and transforms it based on the commands in the template.\nHugo uses its knowledge of the content to find the template file used to render the content. If it can’t find a template that is an exact match for the content, it will shift up a level and search from there. It will continue to do so until it finds a matching template or runs out of templates to try. If it can’t find a template, it will use the default template for the site.\nPlease note that you can use the front matter to influence Hugo’s choice of templates.\nSingle Template\r#\rA single template is used to render a single piece of content. For example, an article or post would be a single piece of content and use a single template.\nList Template\r#\rA list template renders a group of related content. That could be a summary of recent postings or all articles in a category. List templates can contain multiple groups.\nThe homepage template is a special type of list template. Hugo assumes that the home page of your site will act as the portal for the rest of the content in the site.\nPartial Template\r#\rA partial template is a template that can be included in other templates. Partial templates must be called using the “partial” template command. They are very handy for rolling up common behavior. For example, your site may have a banner that all pages use. Instead of copying the text of the banner into every single and list template, you could create a partial with the banner in it. That way if you decide to change the banner, you only have to change the partial template.\nCreate a New Site\r#\rLet\u0026rsquo;s use Hugo to create a new web site. I\u0026rsquo;m a Mac user, so I\u0026rsquo;ll create mine in my home directory, in the Sites folder. If you\u0026rsquo;re using Linux, you might have to create the folder first.\nThe \u0026ldquo;new site\u0026rdquo; command will create a skeleton of a site. It will give you the basic directory structure and a useable configuration file.\n$ hugo new site ~/Sites/zafta\r$ cd ~/Sites/zafta\r$ ls -l\rtotal 8\rdrwxr-xr-x 7 quoha staff 238 Sep 29 16:49 .\rdrwxr-xr-x 3 quoha staff 102 Sep 29 16:49 ..\rdrwxr-xr-x 2 quoha staff 68 Sep 29 16:49 archetypes\r-rw-r--r-- 1 quoha staff 82 Sep 29 16:49 config.toml\rdrwxr-xr-x 2 quoha staff 68 Sep 29 16:49 content\rdrwxr-xr-x 2 quoha staff 68 Sep 29 16:49 layouts\rdrwxr-xr-x 2 quoha staff 68 Sep 29 16:49 static\r$ Take a look in the content/ directory to confirm that it is empty.\nThe other directories (archetypes/, layouts/, and static/) are used when customizing a theme. That\u0026rsquo;s a topic for a different tutorial, so please ignore them for now.\nGenerate the HTML For the New Site\r#\rRunning the hugo command with no options will read all the available content and generate the HTML files. It will also copy all static files (that\u0026rsquo;s everything that\u0026rsquo;s not content). Since we have an empty site, it won\u0026rsquo;t do much, but it will do it very quickly.\n$ hugo --verbose\rINFO: 2014/09/29 Using config file: config.toml\rINFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/\rWARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html]\rWARN: 2014/09/29 Unable to locate layout: [404.html]\r0 draft content 0 future content 0 pages created 0 tags created\r0 categories created\rin 2 ms\r$ The \u0026ldquo;--verbose\u0026rdquo; flag gives extra information that will be helpful when we build the template. Every line of the output that starts with \u0026ldquo;INFO:\u0026rdquo; or \u0026ldquo;WARN:\u0026rdquo; is present because we used that flag. The lines that start with \u0026ldquo;WARN:\u0026rdquo; are warning messages. We\u0026rsquo;ll go over them later.\nWe can verify that the command worked by looking at the directory again.\n$ ls -l\rtotal 8\rdrwxr-xr-x 2 quoha staff 68 Sep 29 16:49 archetypes\r-rw-r--r-- 1 quoha staff 82 Sep 29 16:49 config.toml\rdrwxr-xr-x 2 quoha staff 68 Sep 29 16:49 content\rdrwxr-xr-x 2 quoha staff 68 Sep 29 16:49 layouts\rdrwxr-xr-x 4 quoha staff 136 Sep 29 17:02 public\rdrwxr-xr-x 2 quoha staff 68 Sep 29 16:49 static\r$ See that new public/ directory? Hugo placed all generated content there. When you\u0026rsquo;re ready to publish your web site, that\u0026rsquo;s the place to start. For now, though, let\u0026rsquo;s just confirm that we have what we\u0026rsquo;d expect from a site with no content.\n$ ls -l public\rtotal 16\r-rw-r--r-- 1 quoha staff 416 Sep 29 17:02 index.xml\r-rw-r--r-- 1 quoha staff 262 Sep 29 17:02 sitemap.xml\r$ Hugo created two XML files, which is standard, but there are no HTML files.\nTest the New Site\r#\rVerify that you can run the built-in web server. It will dramatically shorten your development cycle if you do. Start it by running the \u0026ldquo;server\u0026rdquo; command. If it is successful, you will see output similar to the following:\n$ hugo server --verbose\rINFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml\rINFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/\rWARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html]\rWARN: 2014/09/29 Unable to locate layout: [404.html]\r0 draft content 0 future content 0 pages created 0 tags created\r0 categories created\rin 2 ms\rServing pages from /Users/quoha/Sites/zafta/public\rWeb Server is available at http://localhost:1313\rPress Ctrl+C to stop Connect to the listed URL (it\u0026rsquo;s on the line that starts with \u0026ldquo;Web Server\u0026rdquo;). If everything is working correctly, you should get a page that shows the following:\nindex.xml\rsitemap.xml That\u0026rsquo;s a listing of your public/ directory. Hugo didn\u0026rsquo;t create a home page because our site has no content. When there\u0026rsquo;s no index.html file in a directory, the server lists the files in the directory, which is what you should see in your browser.\nLet’s go back and look at those warnings again.\nWARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html]\rWARN: 2014/09/29 Unable to locate layout: [404.html] That second warning is easier to explain. We haven’t created a template to be used to generate “page not found errors.” The 404 message is a topic for a separate tutorial.\nNow for the first warning. It is for the home page. You can tell because the first layout that it looked for was “index.html.” That’s only used by the home page.\nI like that the verbose flag causes Hugo to list the files that it\u0026rsquo;s searching for. For the home page, they are index.html, _default/list.html, and _default/single.html. There are some rules that we\u0026rsquo;ll cover later that explain the names and paths. For now, just remember that Hugo couldn\u0026rsquo;t find a template for the home page and it told you so.\nAt this point, you\u0026rsquo;ve got a working installation and site that we can build upon. All that’s left is to add some content and a theme to display it.\nCreate a New Theme\r#\rHugo doesn\u0026rsquo;t ship with a default theme. There are a few available (I counted a dozen when I first installed Hugo) and Hugo comes with a command to create new themes.\nWe\u0026rsquo;re going to create a new theme called \u0026ldquo;zafta.\u0026rdquo; Since the goal of this tutorial is to show you how to fill out the files to pull in your content, the theme will not contain any CSS. In other words, ugly but functional.\nAll themes have opinions on content and layout. For example, Zafta uses \u0026ldquo;post\u0026rdquo; over \u0026ldquo;blog\u0026rdquo;. Strong opinions make for simpler templates but differing opinions make it tougher to use themes. When you build a theme, consider using the terms that other themes do.\nCreate a Skeleton\r#\rUse the hugo \u0026ldquo;new\u0026rdquo; command to create the skeleton of a theme. This creates the directory structure and places empty files for you to fill out.\n$ hugo new theme zafta\r$ ls -l\rtotal 8\rdrwxr-xr-x 2 quoha staff 68 Sep 29 16:49 archetypes\r-rw-r--r-- 1 quoha staff 82 Sep 29 16:49 config.toml\rdrwxr-xr-x 2 quoha staff 68 Sep 29 16:49 content\rdrwxr-xr-x 2 quoha staff 68 Sep 29 16:49 layouts\rdrwxr-xr-x 4 quoha staff 136 Sep 29 17:02 public\rdrwxr-xr-x 2 quoha staff 68 Sep 29 16:49 static\rdrwxr-xr-x 3 quoha staff 102 Sep 29 17:31 themes\r$ find themes -type f | xargs ls -l\r-rw-r--r-- 1 quoha staff 1081 Sep 29 17:31 themes/zafta/LICENSE.md\r-rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/archetypes/default.md\r-rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/list.html\r-rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/single.html\r-rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/index.html\r-rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/footer.html\r-rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/header.html\r-rw-r--r-- 1 quoha staff 93 Sep 29 17:31 themes/zafta/theme.toml\r$ The skeleton includes templates (the files ending in .html), license file, a description of your theme (the theme.toml file), and an empty archetype.\nPlease take a minute to fill out the theme.toml and LICENSE.md files. They\u0026rsquo;re optional, but if you\u0026rsquo;re going to be distributing your theme, it tells the world who to praise (or blame). It\u0026rsquo;s also nice to declare the license so that people will know how they can use the theme.\n$ vi themes/zafta/theme.toml\rauthor = \u0026#34;michael d henderson\u0026#34;\rdescription = \u0026#34;a minimal working template\u0026#34;\rlicense = \u0026#34;MIT\u0026#34;\rname = \u0026#34;zafta\u0026#34;\rsource_repo = \u0026#34;\u0026#34;\rtags = [\u0026#34;tags\u0026#34;, \u0026#34;categories\u0026#34;]\r:wq\r## also edit themes/zafta/LICENSE.md and change\r## the bit that says \u0026#34;YOUR_NAME_HERE\u0026#34; Note that the the skeleton\u0026rsquo;s template files are empty. Don\u0026rsquo;t worry, we\u0026rsquo;ll be changing that shortly.\n$ find themes/zafta -name \u0026#39;*.html\u0026#39; | xargs ls -l\r-rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/list.html\r-rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/single.html\r-rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/index.html\r-rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/footer.html\r-rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/header.html\r$ Update the Configuration File to Use the Theme\r#\rNow that we\u0026rsquo;ve got a theme to work with, it\u0026rsquo;s a good idea to add the theme name to the configuration file. This is optional, because you can always add \u0026ldquo;-t zafta\u0026rdquo; on all your commands. I like to put it the configuration file because I like shorter command lines. If you don\u0026rsquo;t put it in the configuration file or specify it on the command line, you won\u0026rsquo;t use the template that you\u0026rsquo;re expecting to.\nEdit the file to add the theme, add a title for the site, and specify that all of our content will use the TOML format.\n$ vi config.toml\rtheme = \u0026#34;zafta\u0026#34;\rbaseurl = \u0026#34;\u0026#34;\rlanguageCode = \u0026#34;en-us\u0026#34;\rtitle = \u0026#34;zafta - totally refreshing\u0026#34;\rMetaDataFormat = \u0026#34;toml\u0026#34;\r:wq\r$ Generate the Site\r#\rNow that we have an empty theme, let\u0026rsquo;s generate the site again.\n$ hugo --verbose\rINFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml\rINFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/\rINFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/\rWARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html]\r0 draft content 0 future content 0 pages created 0 tags created\r0 categories created\rin 2 ms\r$ Did you notice that the output is different? The warning message for the home page has disappeared and we have an additional information line saying that Hugo is syncing from the theme\u0026rsquo;s directory.\nLet\u0026rsquo;s check the public/ directory to see what Hugo\u0026rsquo;s created.\n$ ls -l public\rtotal 16\rdrwxr-xr-x 2 quoha staff 68 Sep 29 17:56 css\r-rw-r--r-- 1 quoha staff 0 Sep 29 17:56 index.html\r-rw-r--r-- 1 quoha staff 407 Sep 29 17:56 index.xml\rdrwxr-xr-x 2 quoha staff 68 Sep 29 17:56 js\r-rw-r--r-- 1 quoha staff 243 Sep 29 17:56 sitemap.xml\r$ Notice four things:\nHugo created a home page. This is the file public/index.html. Hugo created a css/ directory. Hugo created a js/ directory. Hugo claimed that it created 0 pages. It created a file and copied over static files, but didn\u0026rsquo;t create any pages. That\u0026rsquo;s because it considers a \u0026ldquo;page\u0026rdquo; to be a file created directly from a content file. It doesn\u0026rsquo;t count things like the index.html files that it creates automatically. The Home Page\r#\rHugo supports many different types of templates. The home page is special because it gets its own type of template and its own template file. The file, layouts/index.html, is used to generate the HTML for the home page. The Hugo documentation says that this is the only required template, but that depends. Hugo\u0026rsquo;s warning message shows that it looks for three different templates:\nWARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html] If it can\u0026rsquo;t find any of these, it completely skips creating the home page. We noticed that when we built the site without having a theme installed.\nWhen Hugo created our theme, it created an empty home page template. Now, when we build the site, Hugo finds the template and uses it to generate the HTML for the home page. Since the template file is empty, the HTML file is empty, too. If the template had any rules in it, then Hugo would have used them to generate the home page.\n$ find . -name index.html | xargs ls -l\r-rw-r--r-- 1 quoha staff 0 Sep 29 20:21 ./public/index.html\r-rw-r--r-- 1 quoha staff 0 Sep 29 17:31 ./themes/zafta/layouts/index.html\r$ The Magic of Static\r#\rHugo does two things when generating the site. It uses templates to transform content into HTML and it copies static files into the site. Unlike content, static files are not transformed. They are copied exactly as they are.\nHugo assumes that your site will use both CSS and JavaScript, so it creates directories in your theme to hold them. Remember opinions? Well, Hugo\u0026rsquo;s opinion is that you\u0026rsquo;ll store your CSS in a directory named css/ and your JavaScript in a directory named js/. If you don\u0026rsquo;t like that, you can change the directory names in your theme directory or even delete them completely. Hugo\u0026rsquo;s nice enough to offer its opinion, then behave nicely if you disagree.\n$ find themes/zafta -type d | xargs ls -ld\rdrwxr-xr-x 7 quoha staff 238 Sep 29 17:38 themes/zafta\rdrwxr-xr-x 3 quoha staff 102 Sep 29 17:31 themes/zafta/archetypes\rdrwxr-xr-x 5 quoha staff 170 Sep 29 17:31 themes/zafta/layouts\rdrwxr-xr-x 4 quoha staff 136 Sep 29 17:31 themes/zafta/layouts/_default\rdrwxr-xr-x 4 quoha staff 136 Sep 29 17:31 themes/zafta/layouts/partials\rdrwxr-xr-x 4 quoha staff 136 Sep 29 17:31 themes/zafta/static\rdrwxr-xr-x 2 quoha staff 68 Sep 29 17:31 themes/zafta/static/css\rdrwxr-xr-x 2 quoha staff 68 Sep 29 17:31 themes/zafta/static/js\r$ The Theme Development Cycle\r#\rWhen you\u0026rsquo;re working on a theme, you will make changes in the theme\u0026rsquo;s directory, rebuild the site, and check your changes in the browser. Hugo makes this very easy:\nPurge the public/ directory. Run the built in web server in watch mode. Open your site in a browser. Update the theme. Glance at your browser window to see changes. Return to step 4. I’ll throw in one more opinion: never work on a theme on a live site. Always work on a copy of your site. Make changes to your theme, test them, then copy them up to your site. For added safety, use a tool like Git to keep a revision history of your content and your theme. Believe me when I say that it is too easy to lose both your mind and your changes.\nCheck the main Hugo site for information on using Git with Hugo.\nPurge the public/ Directory\r#\rWhen generating the site, Hugo will create new files and update existing ones in the public/ directory. It will not delete files that are no longer used. For example, files that were created in the wrong directory or with the wrong title will remain. If you leave them, you might get confused by them later. I recommend cleaning out your site prior to generating it.\nNote: If you\u0026rsquo;re building on an SSD, you should ignore this. Churning on a SSD can be costly.\nHugo\u0026rsquo;s Watch Option\r#\rHugo\u0026rsquo;s \u0026ldquo;--watch\u0026rdquo; option will monitor the content/ and your theme directories for changes and rebuild the site automatically.\nLive Reload\r#\rHugo\u0026rsquo;s built in web server supports live reload. As pages are saved on the server, the browser is told to refresh the page. Usually, this happens faster than you can say, \u0026ldquo;Wow, that\u0026rsquo;s totally amazing.\u0026rdquo;\nDevelopment Commands\r#\rUse the following commands as the basis for your workflow.\n## purge old files. hugo will recreate the public directory.\r##\r$ rm -rf public\r##\r## run hugo in watch mode\r##\r$ hugo server --watch --verbose Here\u0026rsquo;s sample output showing Hugo detecting a change to the template for the home page. Once generated, the web browser automatically reloaded the page. I\u0026rsquo;ve said this before, it\u0026rsquo;s amazing.\n$ rm -rf public\r$ hugo server --watch --verbose\rINFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml\rINFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/\rINFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/\rWARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html]\r0 draft content 0 future content 0 pages created 0 tags created\r0 categories created\rin 2 ms\rWatching for changes in /Users/quoha/Sites/zafta/content\rServing pages from /Users/quoha/Sites/zafta/public\rWeb Server is available at http://localhost:1313\rPress Ctrl+C to stop\rINFO: 2014/09/29 File System Event: [\u0026#34;/Users/quoha/Sites/zafta/themes/zafta/layouts/index.html\u0026#34;: MODIFY|ATTRIB]\rChange detected, rebuilding site\rWARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html]\r0 draft content 0 future content 0 pages created 0 tags created\r0 categories created\rin 1 ms Update the Home Page Template\r#\rThe home page is one of a few special pages that Hugo creates automatically. As mentioned earlier, it looks for one of three files in the theme\u0026rsquo;s layout/ directory:\nindex.html _default/list.html _default/single.html We could update one of the default templates, but a good design decision is to update the most specific template available. That\u0026rsquo;s not a hard and fast rule (in fact, we\u0026rsquo;ll break it a few times in this tutorial), but it is a good generalization.\nMake a Static Home Page\r#\rRight now, that page is empty because we don\u0026rsquo;t have any content and we don\u0026rsquo;t have any logic in the template. Let\u0026rsquo;s change that by adding some text to the template.\n$ vi themes/zafta/layouts/index.html\r\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;hugo says hello!\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq\r$ Build the web site and then verify the results.\n$ hugo --verbose\rINFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml\rINFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/\rINFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/\rWARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html]\r0 draft content 0 future content 0 pages created 0 tags created\r0 categories created\rin 2 ms\r$ find public -type f -name \u0026#39;*.html\u0026#39; | xargs ls -l\r-rw-r--r-- 1 quoha staff 78 Sep 29 21:26 public/index.html\r$ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;hugo says hello!\u0026lt;/p\u0026gt; \u0026lt;/html\u0026gt; Live Reload\r#\rNote: If you\u0026rsquo;re running the server with the --watch option, you\u0026rsquo;ll see different content in the file:\n$ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;hugo says hello!\u0026lt;/p\u0026gt; \u0026lt;script\u0026gt;document.write(\u0026#39;\u0026lt;script src=\u0026#34;http://\u0026#39; + (location.host || \u0026#39;localhost\u0026#39;).split(\u0026#39;:\u0026#39;)[0] + \u0026#39;:1313/livereload.js?mindelay=10\u0026#34;\u0026gt;\u0026lt;/\u0026#39; + \u0026#39;script\u0026gt;\u0026#39;)\u0026lt;/script\u0026gt;\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; When you use --watch, the Live Reload script is added by Hugo. Look for live reload in the documentation to see what it does and how to disable it.\nBuild a \u0026ldquo;Dynamic\u0026rdquo; Home Page\r#\r\u0026ldquo;Dynamic home page?\u0026rdquo; Hugo\u0026rsquo;s a static web site generator, so this seems an odd thing to say. I mean let\u0026rsquo;s have the home page automatically reflect the content in the site every time Hugo builds it. We\u0026rsquo;ll use iteration in the template to do that.\nCreate New Posts\r#\rNow that we have the home page generating static content, let\u0026rsquo;s add some content to the site. We\u0026rsquo;ll display these posts as a list on the home page and on their own page, too.\nHugo has a command to generate a skeleton post, just like it does for sites and themes.\n$ hugo --verbose new post/first.md\rINFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml\rINFO: 2014/09/29 attempting to create post/first.md of post\rINFO: 2014/09/29 curpath: /Users/quoha/Sites/zafta/themes/zafta/archetypes/default.md\rERROR: 2014/09/29 Unable to Cast \u0026lt;nil\u0026gt; to map[string]interface{}\r$ That wasn\u0026rsquo;t very nice, was it?\nThe \u0026ldquo;new\u0026rdquo; command uses an archetype to create the post file. Hugo created an empty default archetype file, but that causes an error when there\u0026rsquo;s a theme. For me, the workaround was to create an archetypes file specifically for the post type.\n$ vi themes/zafta/archetypes/post.md\r+++\rDescription = \u0026#34;\u0026#34;\rTags = []\rCategories = []\r+++\r:wq\r$ find themes/zafta/archetypes -type f | xargs ls -l\r-rw-r--r-- 1 quoha staff 0 Sep 29 21:53 themes/zafta/archetypes/default.md\r-rw-r--r-- 1 quoha staff 51 Sep 29 21:54 themes/zafta/archetypes/post.md\r$ hugo --verbose new post/first.md\rINFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml\rINFO: 2014/09/29 attempting to create post/first.md of post\rINFO: 2014/09/29 curpath: /Users/quoha/Sites/zafta/themes/zafta/archetypes/post.md\rINFO: 2014/09/29 creating /Users/quoha/Sites/zafta/content/post/first.md\r/Users/quoha/Sites/zafta/content/post/first.md created\r$ hugo --verbose new post/second.md\rINFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml\rINFO: 2014/09/29 attempting to create post/second.md of post\rINFO: 2014/09/29 curpath: /Users/quoha/Sites/zafta/themes/zafta/archetypes/post.md\rINFO: 2014/09/29 creating /Users/quoha/Sites/zafta/content/post/second.md\r/Users/quoha/Sites/zafta/content/post/second.md created\r$ ls -l content/post\rtotal 16\r-rw-r--r-- 1 quoha staff 104 Sep 29 21:54 first.md\r-rw-r--r-- 1 quoha staff 105 Sep 29 21:57 second.md\r$ cat content/post/first.md +++\rCategories = []\rDescription = \u0026#34;\u0026#34;\rTags = []\rdate = \u0026#34;2014-09-29T21:54:53-05:00\u0026#34;\rtitle = \u0026#34;first\u0026#34;\r+++\rmy first post\r$ cat content/post/second.md +++\rCategories = []\rDescription = \u0026#34;\u0026#34;\rTags = []\rdate = \u0026#34;2014-09-29T21:57:09-05:00\u0026#34;\rtitle = \u0026#34;second\u0026#34;\r+++\rmy second post\r$ Build the web site and then verify the results.\n$ rm -rf public\r$ hugo --verbose\rINFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml\rINFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/\rINFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/\rINFO: 2014/09/29 found taxonomies: map[string]string{\u0026#34;category\u0026#34;:\u0026#34;categories\u0026#34;, \u0026#34;tag\u0026#34;:\u0026#34;tags\u0026#34;}\rWARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html]\r0 draft content 0 future content 2 pages created 0 tags created\r0 categories created\rin 4 ms\r$ The output says that it created 2 pages. Those are our new posts:\n$ find public -type f -name \u0026#39;*.html\u0026#39; | xargs ls -l\r-rw-r--r-- 1 quoha staff 78 Sep 29 22:13 public/index.html\r-rw-r--r-- 1 quoha staff 0 Sep 29 22:13 public/post/first/index.html\r-rw-r--r-- 1 quoha staff 0 Sep 29 22:13 public/post/index.html\r-rw-r--r-- 1 quoha staff 0 Sep 29 22:13 public/post/second/index.html\r$ The new files are empty because because the templates used to generate the content are empty. The homepage doesn\u0026rsquo;t show the new content, either. We have to update the templates to add the posts.\nList and Single Templates\r#\rIn Hugo, we have three major kinds of templates. There\u0026rsquo;s the home page template that we updated previously. It is used only by the home page. We also have \u0026ldquo;single\u0026rdquo; templates which are used to generate output for a single content file. We also have \u0026ldquo;list\u0026rdquo; templates that are used to group multiple pieces of content before generating output.\nGenerally speaking, list templates are named \u0026ldquo;list.html\u0026rdquo; and single templates are named \u0026ldquo;single.html.\u0026rdquo;\nThere are three other types of templates: partials, content views, and terms. We will not go into much detail on these.\nAdd Content to the Homepage\r#\rThe home page will contain a list of posts. Let\u0026rsquo;s update its template to add the posts that we just created. The logic in the template will run every time we build the site.\n$ vi themes/zafta/layouts/index.html \u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html\u0026gt;\r\u0026lt;body\u0026gt;\r{{ range first 10 .Data.Pages }}\r\u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt;\r{{ end }}\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\r:wq\r$ Hugo uses the Go template engine. That engine scans the template files for commands which are enclosed between \u0026ldquo;{{\u0026rdquo; and \u0026ldquo;}}\u0026rdquo;. In our template, the commands are:\nrange .Title end The \u0026ldquo;range\u0026rdquo; command is an iterator. We\u0026rsquo;re going to use it to go through the first ten pages. Every HTML file that Hugo creates is treated as a page, so looping through the list of pages will look at every file that will be created.\nThe \u0026ldquo;.Title\u0026rdquo; command prints the value of the \u0026ldquo;title\u0026rdquo; variable. Hugo pulls it from the front matter in the Markdown file.\nThe \u0026ldquo;end\u0026rdquo; command signals the end of the range iterator. The engine loops back to the top of the iteration when it finds \u0026ldquo;end.\u0026rdquo; Everything between the \u0026ldquo;range\u0026rdquo; and \u0026ldquo;end\u0026rdquo; is evaluated every time the engine goes through the iteration. In this file, that would cause the title from the first ten pages to be output as heading level one.\nIt\u0026rsquo;s helpful to remember that some variables, like .Data, are created before any output files. Hugo loads every content file into the variable and then gives the template a chance to process before creating the HTML files.\nBuild the web site and then verify the results.\n$ rm -rf public\r$ hugo --verbose\rINFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml\rINFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/\rINFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/\rINFO: 2014/09/29 found taxonomies: map[string]string{\u0026#34;tag\u0026#34;:\u0026#34;tags\u0026#34;, \u0026#34;category\u0026#34;:\u0026#34;categories\u0026#34;}\rWARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html]\r0 draft content 0 future content 2 pages created 0 tags created\r0 categories created\rin 4 ms\r$ find public -type f -name \u0026#39;*.html\u0026#39; | xargs ls -l -rw-r--r-- 1 quoha staff 94 Sep 29 22:23 public/index.html\r-rw-r--r-- 1 quoha staff 0 Sep 29 22:23 public/post/first/index.html\r-rw-r--r-- 1 quoha staff 0 Sep 29 22:23 public/post/index.html\r-rw-r--r-- 1 quoha staff 0 Sep 29 22:23 public/post/second/index.html\r$ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;h1\u0026gt;second\u0026lt;/h1\u0026gt;\r\u0026lt;h1\u0026gt;first\u0026lt;/h1\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\r$ Congratulations, the home page shows the title of the two posts. The posts themselves are still empty, but let\u0026rsquo;s take a moment to appreciate what we\u0026rsquo;ve done. Your template now generates output dynamically. Believe it or not, by inserting the range command inside of those curly braces, you\u0026rsquo;ve learned everything you need to know to build a theme. All that\u0026rsquo;s really left is understanding which template will be used to generate each content file and becoming familiar with the commands for the template engine.\nAnd, if that were entirely true, this tutorial would be much shorter. There are a few things to know that will make creating a new template much easier. Don\u0026rsquo;t worry, though, that\u0026rsquo;s all to come.\nAdd Content to the Posts\r#\rWe\u0026rsquo;re working with posts, which are in the content/post/ directory. That means that their section is \u0026ldquo;post\u0026rdquo; (and if we don\u0026rsquo;t do something weird, their type is also \u0026ldquo;post\u0026rdquo;).\nHugo uses the section and type to find the template file for every piece of content. Hugo will first look for a template file that matches the section or type name. If it can\u0026rsquo;t find one, then it will look in the _default/ directory. There are some twists that we\u0026rsquo;ll cover when we get to categories and tags, but for now we can assume that Hugo will try post/single.html, then _default/single.html.\nNow that we know the search rule, let\u0026rsquo;s see what we actually have available:\n$ find themes/zafta -name single.html | xargs ls -l\r-rw-r--r-- 1 quoha staff 132 Sep 29 17:31 themes/zafta/layouts/_default/single.html We could create a new template, post/single.html, or change the default. Since we don\u0026rsquo;t know of any other content types, let\u0026rsquo;s start with updating the default.\nRemember, any content that we haven\u0026rsquo;t created a template for will end up using this template. That can be good or bad. Bad because I know that we\u0026rsquo;re going to be adding different types of content and we\u0026rsquo;re going to end up undoing some of the changes we\u0026rsquo;ve made. It\u0026rsquo;s good because we\u0026rsquo;ll be able to see immediate results. It\u0026rsquo;s also good to start here because we can start to build the basic layout for the site. As we add more content types, we\u0026rsquo;ll refactor this file and move logic around. Hugo makes that fairly painless, so we\u0026rsquo;ll accept the cost and proceed.\nPlease see the Hugo documentation on template rendering for all the details on determining which template to use. And, as the docs mention, if you\u0026rsquo;re building a single page application (SPA) web site, you can delete all of the other templates and work with just the default single page. That\u0026rsquo;s a refreshing amount of joy right there.\nUpdate the Template File\r#\r$ vi themes/zafta/layouts/_default/single.html \u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;title\u0026gt;{{ .Title }}\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt;\r{{ .Content }}\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\r:wq\r$ Build the web site and verify the results.\n$ rm -rf public\r$ hugo --verbose\rINFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml\rINFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/\rINFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/\rINFO: 2014/09/29 found taxonomies: map[string]string{\u0026#34;tag\u0026#34;:\u0026#34;tags\u0026#34;, \u0026#34;category\u0026#34;:\u0026#34;categories\u0026#34;}\rWARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html]\r0 draft content 0 future content 2 pages created 0 tags created\r0 categories created\rin 4 ms\r$ find public -type f -name \u0026#39;*.html\u0026#39; | xargs ls -l\r-rw-r--r-- 1 quoha staff 94 Sep 29 22:40 public/index.html\r-rw-r--r-- 1 quoha staff 125 Sep 29 22:40 public/post/first/index.html\r-rw-r--r-- 1 quoha staff 0 Sep 29 22:40 public/post/index.html\r-rw-r--r-- 1 quoha staff 128 Sep 29 22:40 public/post/second/index.html\r$ cat public/post/first/index.html \u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;title\u0026gt;first\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;h1\u0026gt;first\u0026lt;/h1\u0026gt;\r\u0026lt;p\u0026gt;my first post\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\r$ cat public/post/second/index.html \u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;title\u0026gt;second\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;h1\u0026gt;second\u0026lt;/h1\u0026gt;\r\u0026lt;p\u0026gt;my second post\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\r$ Notice that the posts now have content. You can go to localhost:1313/post/first to verify.\nLinking to Content\r#\rThe posts are on the home page. Let\u0026rsquo;s add a link from there to the post. Since this is the home page, we\u0026rsquo;ll update its template.\n$ vi themes/zafta/layouts/index.html\r\u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html\u0026gt;\r\u0026lt;body\u0026gt;\r{{ range first 10 .Data.Pages }}\r\u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt;\r{{ end }}\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt; Build the web site and verify the results.\n$ rm -rf public\r$ hugo --verbose\rINFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml\rINFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/\rINFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/\rINFO: 2014/09/29 found taxonomies: map[string]string{\u0026#34;tag\u0026#34;:\u0026#34;tags\u0026#34;, \u0026#34;category\u0026#34;:\u0026#34;categories\u0026#34;}\rWARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html]\r0 draft content 0 future content 2 pages created 0 tags created\r0 categories created\rin 4 ms\r$ find public -type f -name \u0026#39;*.html\u0026#39; | xargs ls -l\r-rw-r--r-- 1 quoha staff 149 Sep 29 22:44 public/index.html\r-rw-r--r-- 1 quoha staff 125 Sep 29 22:44 public/post/first/index.html\r-rw-r--r-- 1 quoha staff 0 Sep 29 22:44 public/post/index.html\r-rw-r--r-- 1 quoha staff 128 Sep 29 22:44 public/post/second/index.html\r$ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;/post/second/\u0026#34;\u0026gt;second\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt;\r\u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;/post/first/\u0026#34;\u0026gt;first\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\r$ Create a Post Listing\r#\rWe have the posts displaying on the home page and on their own page. We also have a file public/post/index.html that is empty. Let\u0026rsquo;s make it show a list of all posts (not just the first ten).\nWe need to decide which template to update. This will be a listing, so it should be a list template. Let\u0026rsquo;s take a quick look and see which list templates are available.\n$ find themes/zafta -name list.html | xargs ls -l\r-rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/list.html As with the single post, we have to decide to update _default/list.html or create post/list.html. We still don\u0026rsquo;t have multiple content types, so let\u0026rsquo;s stay consistent and update the default list template.\nCreating Top Level Pages\r#\rLet\u0026rsquo;s add an \u0026ldquo;about\u0026rdquo; page and display it at the top level (as opposed to a sub-level like we did with posts).\nThe default in Hugo is to use the directory structure of the content/ directory to guide the location of the generated html in the public/ directory. Let\u0026rsquo;s verify that by creating an \u0026ldquo;about\u0026rdquo; page at the top level:\n$ vi content/about.md +++\rtitle = \u0026#34;about\u0026#34;\rdescription = \u0026#34;about this site\u0026#34;\rdate = \u0026#34;2014-09-27\u0026#34;\rslug = \u0026#34;about time\u0026#34;\r+++\r## about us\ri\u0026#39;m speechless\r:wq Generate the web site and verify the results.\n$ find public -name \u0026#39;*.html\u0026#39; | xargs ls -l\r-rw-rw-r-- 1 mdhender staff 334 Sep 27 15:08 public/about-time/index.html\r-rw-rw-r-- 1 mdhender staff 527 Sep 27 15:08 public/index.html\r-rw-rw-r-- 1 mdhender staff 358 Sep 27 15:08 public/post/first-post/index.html\r-rw-rw-r-- 1 mdhender staff 0 Sep 27 15:08 public/post/index.html\r-rw-rw-r-- 1 mdhender staff 342 Sep 27 15:08 public/post/second-post/index.html Notice that the page wasn\u0026rsquo;t created at the top level. It was created in a sub-directory named \u0026lsquo;about-time/\u0026rsquo;. That name came from our slug. Hugo will use the slug to name the generated content. It\u0026rsquo;s a reasonable default, by the way, but we can learn a few things by fighting it for this file.\nOne other thing. Take a look at the home page.\n$ cat public/index.html\r\u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;http://localhost:1313/post/theme/\u0026#34;\u0026gt;creating a new theme\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt;\r\u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;http://localhost:1313/about-time/\u0026#34;\u0026gt;about\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt;\r\u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;http://localhost:1313/post/second-post/\u0026#34;\u0026gt;second\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt;\r\u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;http://localhost:1313/post/first-post/\u0026#34;\u0026gt;first\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt;\r\u0026lt;script\u0026gt;document.write(\u0026#39;\u0026lt;script src=\u0026#34;http://\u0026#39;\r+ (location.host || \u0026#39;localhost\u0026#39;).split(\u0026#39;:\u0026#39;)[0]\r+ \u0026#39;:1313/livereload.js?mindelay=10\u0026#34;\u0026gt;\u0026lt;/\u0026#39;\r+ \u0026#39;script\u0026gt;\u0026#39;)\u0026lt;/script\u0026gt;\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt; Notice that the \u0026ldquo;about\u0026rdquo; link is listed with the posts? That\u0026rsquo;s not desirable, so let\u0026rsquo;s change that first.\n$ vi themes/zafta/layouts/index.html\r\u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;h1\u0026gt;posts\u0026lt;/h1\u0026gt;\r{{ range first 10 .Data.Pages }}\r{{ if eq .Type \u0026#34;post\u0026#34;}}\r\u0026lt;h2\u0026gt;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt;\r{{ end }}\r{{ end }}\r\u0026lt;h1\u0026gt;pages\u0026lt;/h1\u0026gt;\r{{ range .Data.Pages }}\r{{ if eq .Type \u0026#34;page\u0026#34; }}\r\u0026lt;h2\u0026gt;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt;\r{{ end }}\r{{ end }}\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\r:wq Generate the web site and verify the results. The home page has two sections, posts and pages, and each section has the right set of headings and links in it.\nBut, that about page still renders to about-time/index.html.\n$ find public -name \u0026#39;*.html\u0026#39; | xargs ls -l\r-rw-rw-r-- 1 mdhender staff 334 Sep 27 15:33 public/about-time/index.html\r-rw-rw-r-- 1 mdhender staff 645 Sep 27 15:33 public/index.html\r-rw-rw-r-- 1 mdhender staff 358 Sep 27 15:33 public/post/first-post/index.html\r-rw-rw-r-- 1 mdhender staff 0 Sep 27 15:33 public/post/index.html\r-rw-rw-r-- 1 mdhender staff 342 Sep 27 15:33 public/post/second-post/index.html Knowing that hugo is using the slug to generate the file name, the simplest solution is to change the slug. Let\u0026rsquo;s do it the hard way and change the permalink in the configuration file.\n$ vi config.toml\r[permalinks]\rpage = \u0026#34;/:title/\u0026#34;\rabout = \u0026#34;/:filename/\u0026#34; Generate the web site and verify that this didn\u0026rsquo;t work. Hugo lets \u0026ldquo;slug\u0026rdquo; or \u0026ldquo;URL\u0026rdquo; override the permalinks setting in the configuration file. Go ahead and comment out the slug in content/about.md, then generate the web site to get it to be created in the right place.\nSharing Templates\r#\rIf you\u0026rsquo;ve been following along, you probably noticed that posts have titles in the browser and the home page doesn\u0026rsquo;t. That\u0026rsquo;s because we didn\u0026rsquo;t put the title in the home page\u0026rsquo;s template (layouts/index.html). That\u0026rsquo;s an easy thing to do, but let\u0026rsquo;s look at a different option.\nWe can put the common bits into a shared template that\u0026rsquo;s stored in the themes/zafta/layouts/partials/ directory.\nCreate the Header and Footer Partials\r#\rIn Hugo, a partial is a sugar-coated template. Normally a template reference has a path specified. Partials are different. Hugo searches for them along a TODO defined search path. This makes it easier for end-users to override the theme\u0026rsquo;s presentation.\n$ vi themes/zafta/layouts/partials/header.html\r\u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;title\u0026gt;{{ .Title }}\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r:wq\r$ vi themes/zafta/layouts/partials/footer.html\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\r:wq Update the Home Page Template to Use the Partials\r#\rThe most noticeable difference between a template call and a partials call is the lack of path:\n{{ template \u0026#34;theme/partials/header.html\u0026#34; . }} versus\n{{ partial \u0026#34;header.html\u0026#34; . }} Both pass in the context.\nLet\u0026rsquo;s change the home page template to use these new partials.\n$ vi themes/zafta/layouts/index.html\r{{ partial \u0026#34;header.html\u0026#34; . }}\r\u0026lt;h1\u0026gt;posts\u0026lt;/h1\u0026gt;\r{{ range first 10 .Data.Pages }}\r{{ if eq .Type \u0026#34;post\u0026#34;}}\r\u0026lt;h2\u0026gt;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt;\r{{ end }}\r{{ end }}\r\u0026lt;h1\u0026gt;pages\u0026lt;/h1\u0026gt;\r{{ range .Data.Pages }}\r{{ if or (eq .Type \u0026#34;page\u0026#34;) (eq .Type \u0026#34;about\u0026#34;) }}\r\u0026lt;h2\u0026gt;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .Type }} - {{ .Title }} - {{ .RelPermalink }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt;\r{{ end }}\r{{ end }}\r{{ partial \u0026#34;footer.html\u0026#34; . }}\r:wq Generate the web site and verify the results. The title on the home page is now \u0026ldquo;your title here\u0026rdquo;, which comes from the \u0026ldquo;title\u0026rdquo; variable in the config.toml file.\nUpdate the Default Single Template to Use the Partials\r#\r$ vi themes/zafta/layouts/_default/single.html\r{{ partial \u0026#34;header.html\u0026#34; . }}\r\u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt;\r{{ .Content }}\r{{ partial \u0026#34;footer.html\u0026#34; . }}\r:wq Generate the web site and verify the results. The title on the posts and the about page should both reflect the value in the markdown file.\nAdd “Date Published” to Posts\r#\rIt\u0026rsquo;s common to have posts display the date that they were written or published, so let\u0026rsquo;s add that. The front matter of our posts has a variable named \u0026ldquo;date.\u0026rdquo; It\u0026rsquo;s usually the date the content was created, but let\u0026rsquo;s pretend that\u0026rsquo;s the value we want to display.\nAdd “Date Published” to the Template\r#\rWe\u0026rsquo;ll start by updating the template used to render the posts. The template code will look like:\n{{ .Date.Format \u0026#34;Mon, Jan 2, 2006\u0026#34; }} Posts use the default single template, so we\u0026rsquo;ll change that file.\n$ vi themes/zafta/layouts/_default/single.html\r{{ partial \u0026#34;header.html\u0026#34; . }}\r\u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt;\r\u0026lt;h2\u0026gt;{{ .Date.Format \u0026#34;Mon, Jan 2, 2006\u0026#34; }}\u0026lt;/h2\u0026gt;\r{{ .Content }}\r{{ partial \u0026#34;footer.html\u0026#34; . }}\r:wq Generate the web site and verify the results. The posts now have the date displayed in them. There\u0026rsquo;s a problem, though. The \u0026ldquo;about\u0026rdquo; page also has the date displayed.\nAs usual, there are a couple of ways to make the date display only on posts. We could do an \u0026ldquo;if\u0026rdquo; statement like we did on the home page. Another way would be to create a separate template for posts.\nThe \u0026ldquo;if\u0026rdquo; solution works for sites that have just a couple of content types. It aligns with the principle of \u0026ldquo;code for today,\u0026rdquo; too.\nLet\u0026rsquo;s assume, though, that we\u0026rsquo;ve made our site so complex that we feel we have to create a new template type. In Hugo-speak, we\u0026rsquo;re going to create a section template.\nLet\u0026rsquo;s restore the default single template before we forget.\n$ mkdir themes/zafta/layouts/post\r$ vi themes/zafta/layouts/_default/single.html\r{{ partial \u0026#34;header.html\u0026#34; . }}\r\u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt;\r{{ .Content }}\r{{ partial \u0026#34;footer.html\u0026#34; . }}\r:wq Now we\u0026rsquo;ll update the post\u0026rsquo;s version of the single template. If you remember Hugo\u0026rsquo;s rules, the template engine will use this version over the default.\n$ vi themes/zafta/layouts/post/single.html\r{{ partial \u0026#34;header.html\u0026#34; . }}\r\u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt;\r\u0026lt;h2\u0026gt;{{ .Date.Format \u0026#34;Mon, Jan 2, 2006\u0026#34; }}\u0026lt;/h2\u0026gt;\r{{ .Content }}\r{{ partial \u0026#34;footer.html\u0026#34; . }}\r:wq Note that we removed the date logic from the default template and put it in the post template. Generate the web site and verify the results. Posts have dates and the about page doesn\u0026rsquo;t.\nDon\u0026rsquo;t Repeat Yourself\r#\rDRY is a good design goal and Hugo does a great job supporting it. Part of the art of a good template is knowing when to add a new template and when to update an existing one. While you\u0026rsquo;re figuring that out, accept that you\u0026rsquo;ll be doing some refactoring. Hugo makes that easy and fast, so it\u0026rsquo;s okay to delay splitting up a template.\n"},{"id":1,"href":"/posts/migrate-from-jekyll/","title":"Migrating from Jekyll","section":"Blog","content":"\rMove static content to static\r#\rJekyll has a rule that any directory not starting with _ will be copied as-is to the _site output. Hugo keeps all static content under static. You should therefore move it all there. With Jekyll, something that looked like\n▾ \u0026lt;root\u0026gt;/\r▾ images/\rlogo.png\rshould become\n▾ \u0026lt;root\u0026gt;/\r▾ static/\r▾ images/\rlogo.png\rAdditionally, you\u0026rsquo;ll want any files that should reside at the root (such as CNAME) to be moved to static.\nCreate your Hugo configuration file\r#\rHugo can read your configuration as JSON, YAML or TOML. Hugo supports parameters custom configuration too. Refer to the Hugo configuration documentation for details.\nSet your configuration publish folder to _site\r#\rThe default is for Jekyll to publish to _site and for Hugo to publish to public. If, like me, you have _site mapped to a git submodule on the gh-pages branch, you\u0026rsquo;ll want to do one of two alternatives:\nChange your submodule to point to map gh-pages to public instead of _site (recommended).\ngit submodule deinit _site\rgit rm _site\rgit submodule add -b gh-pages git@github.com:your-username/your-repo.git public\rOr, change the Hugo configuration to use _site instead of public.\n{\r..\r\u0026quot;publishdir\u0026quot;: \u0026quot;_site\u0026quot;,\r..\r}\rConvert Jekyll templates to Hugo templates\r#\rThat\u0026rsquo;s the bulk of the work right here. The documentation is your friend. You should refer to Jekyll\u0026rsquo;s template documentation if you need to refresh your memory on how you built your blog and Hugo\u0026rsquo;s template to learn Hugo\u0026rsquo;s way.\nAs a single reference data point, converting my templates for heyitsalex.net took me no more than a few hours.\nConvert Jekyll plugins to Hugo shortcodes\r#\rJekyll has plugins; Hugo has shortcodes. It\u0026rsquo;s fairly trivial to do a port.\nImplementation\r#\rAs an example, I was using a custom image_tag plugin to generate figures with caption when running Jekyll. As I read about shortcodes, I found Hugo had a nice built-in shortcode that does exactly the same thing.\nJekyll\u0026rsquo;s plugin:\nmodule Jekyll\rclass ImageTag \u0026lt; Liquid::Tag\r@url = nil\r@caption = nil\r@class = nil\r@link = nil\r// Patterns\rIMAGE_URL_WITH_CLASS_AND_CAPTION =\rIMAGE_URL_WITH_CLASS_AND_CAPTION_AND_LINK = /(\\w+)(\\s+)((https?:\\/\\/|\\/)(\\S+))(\\s+)\u0026quot;(.*?)\u0026quot;(\\s+)-\u0026gt;((https?:\\/\\/|\\/)(\\S+))(\\s*)/i\rIMAGE_URL_WITH_CAPTION = /((https?:\\/\\/|\\/)(\\S+))(\\s+)\u0026quot;(.*?)\u0026quot;/i\rIMAGE_URL_WITH_CLASS = /(\\w+)(\\s+)((https?:\\/\\/|\\/)(\\S+))/i\rIMAGE_URL = /((https?:\\/\\/|\\/)(\\S+))/i\rdef initialize(tag_name, markup, tokens)\rsuper\rif markup =~ IMAGE_URL_WITH_CLASS_AND_CAPTION_AND_LINK\r@class = $1\r@url = $3\r@caption = $7\r@link = $9\relsif markup =~ IMAGE_URL_WITH_CLASS_AND_CAPTION\r@class = $1\r@url = $3\r@caption = $7\relsif markup =~ IMAGE_URL_WITH_CAPTION\r@url = $1\r@caption = $5\relsif markup =~ IMAGE_URL_WITH_CLASS\r@class = $1\r@url = $3\relsif markup =~ IMAGE_URL\r@url = $1\rend\rend\rdef render(context)\rif @class\rsource = \u0026quot;\u0026lt;figure class='#{@class}'\u0026gt;\u0026quot;\relse\rsource = \u0026quot;\u0026lt;figure\u0026gt;\u0026quot;\rend\rif @link\rsource += \u0026quot;\u0026lt;a href=\\\u0026quot;#{@link}\\\u0026quot;\u0026gt;\u0026quot;\rend\rsource += \u0026quot;\u0026lt;img src=\\\u0026quot;#{@url}\\\u0026quot;\u0026gt;\u0026quot;\rif @link\rsource += \u0026quot;\u0026lt;/a\u0026gt;\u0026quot;\rend\rsource += \u0026quot;\u0026lt;figcaption\u0026gt;#{@caption}\u0026lt;/figcaption\u0026gt;\u0026quot; if @caption\rsource += \u0026quot;\u0026lt;/figure\u0026gt;\u0026quot;\rsource\rend\rend\rend\rLiquid::Template.register_tag('image', Jekyll::ImageTag)\ris written as this Hugo shortcode:\n\u0026lt;!-- image --\u0026gt;\r\u0026lt;figure {{ with .Get \u0026quot;class\u0026quot; }}class=\u0026quot;{{.}}\u0026quot;{{ end }}\u0026gt;\r{{ with .Get \u0026quot;link\u0026quot;}}\u0026lt;a href=\u0026quot;{{.}}\u0026quot;\u0026gt;{{ end }}\r\u0026lt;img src=\u0026quot;{{ .Get \u0026quot;src\u0026quot; }}\u0026quot; {{ if or (.Get \u0026quot;alt\u0026quot;) (.Get \u0026quot;caption\u0026quot;) }}alt=\u0026quot;{{ with .Get \u0026quot;alt\u0026quot;}}{{.}}{{else}}{{ .Get \u0026quot;caption\u0026quot; }}{{ end }}\u0026quot;{{ end }} /\u0026gt;\r{{ if .Get \u0026quot;link\u0026quot;}}\u0026lt;/a\u0026gt;{{ end }}\r{{ if or (or (.Get \u0026quot;title\u0026quot;) (.Get \u0026quot;caption\u0026quot;)) (.Get \u0026quot;attr\u0026quot;)}}\r\u0026lt;figcaption\u0026gt;{{ if isset .Params \u0026quot;title\u0026quot; }}\r{{ .Get \u0026quot;title\u0026quot; }}{{ end }}\r{{ if or (.Get \u0026quot;caption\u0026quot;) (.Get \u0026quot;attr\u0026quot;)}}\u0026lt;p\u0026gt;\r{{ .Get \u0026quot;caption\u0026quot; }}\r{{ with .Get \u0026quot;attrlink\u0026quot;}}\u0026lt;a href=\u0026quot;{{.}}\u0026quot;\u0026gt; {{ end }}\r{{ .Get \u0026quot;attr\u0026quot; }}\r{{ if .Get \u0026quot;attrlink\u0026quot;}}\u0026lt;/a\u0026gt; {{ end }}\r\u0026lt;/p\u0026gt; {{ end }}\r\u0026lt;/figcaption\u0026gt;\r{{ end }}\r\u0026lt;/figure\u0026gt;\r\u0026lt;!-- image --\u0026gt;\rUsage\r#\rI simply changed:\n{% image full http://farm5.staticflickr.com/4136/4829260124_57712e570a_o_d.jpg \u0026quot;One of my favorite touristy-type photos. I secretly waited for the good light while we were \u0026quot;having fun\u0026quot; and took this. Only regret: a stupid pole in the top-left corner of the frame I had to clumsily get rid of at post-processing.\u0026quot; -\u0026gt;http://www.flickr.com/photos/alexnormand/4829260124/in/set-72157624547713078/ %}\rto this (this example uses a slightly extended version named fig, different than the built-in figure):\n{{% fig class=\u0026quot;full\u0026quot; src=\u0026quot;http://farm5.staticflickr.com/4136/4829260124_57712e570a_o_d.jpg\u0026quot; title=\u0026quot;One of my favorite touristy-type photos. I secretly waited for the good light while we were having fun and took this. Only regret: a stupid pole in the top-left corner of the frame I had to clumsily get rid of at post-processing.\u0026quot; link=\u0026quot;http://www.flickr.com/photos/alexnormand/4829260124/in/set-72157624547713078/\u0026quot; %}}\rAs a bonus, the shortcode named parameters are, arguably, more readable.\nFinishing touches\r#\rFix content\r#\rDepending on the amount of customization that was done with each post with Jekyll, this step will require more or less effort. There are no hard and fast rules here except that hugo server --watch is your friend. Test your changes and fix errors as needed.\nClean up\r#\rYou\u0026rsquo;ll want to remove the Jekyll configuration at this point. If you have anything else that isn\u0026rsquo;t used, delete it.\nA practical example in a diff\r#\rHey, it\u0026rsquo;s Alex was migrated in less than a father-with-kids day from Jekyll to Hugo. You can see all the changes (and screw-ups) by looking at this diff.\n"},{"id":2,"href":"/posts/2023-05-14-MF-Matrix-Factorization/","title":"MF: Matrix Factorization","section":"Blog","content":" 간단 요약\n행렬을 인수분해 후 재생성하여 결측치를 예측하는 방법\n인수분해를 다양하게 시도하여 대상 행렬을 가장 잘 복구하는 최적의 하위행렬을 찾는 과정 {: .prompt-info } Latent Factors, Matrix Factorization, SGD\n행렬을 인수분해 후 재생성하여 결측치를 예측하는 방법\n대상 행렬을 두개의 하위 행렬로 분해한다.\nUser-Item 행렬을 User와 Item 각각에 대한 저차원의 latent factor 행렬로 분해한다.\n두 하위 행렬을 다시 곱해서 대상 행렬과 동일한 크기의 단일 행렬로 만든다.\n위의 과정에서 기존 행렬의 빈공간이 채워진다.\n이는 행렬의 성질을 이용한 것이다.\n즉, 결측값(비평가 항목)에 대해 임의로 Imputation을 수행하지 않는다.\n실제로 관측된 값만 활용한다.\n요약하면, 인수분해를 다양하게 시도하여 대상 행렬을 가장 잘 복구하는 최적의 하위행렬을 찾는 과정이다.\n기계가 해석하기 위한 행렬, 즉 블랙 박스 모델에 더 가깝다.\n추천시스템에서 두 개의 하위행렬은 각각 유저 임베딩(User Latent Factors)과 아이템 임베딩(Item Latent Factors)이 된다.\n결국 MF를 학습하는 것은 latent feature들을 학습하는 것과 같다.\n범주형 feature의 잠재 요인을 feature로 사용하고자 할 경우 이 잠재 요인을 가장 손쉽게 구할 수 있는 방법이다.\nLatent 행렬을 각각 P, Q라고 했을 때, MF는 Rating Matrix를 $P$와 $Q$로 분해하여 $R$과 최대한 유사하게 $\\hat R$을 추론한다.(최적화)\n$$ R \\approx P \\times Q^T = \\widehat R $$\n모델 학습 과정\r#\rObject Function을 정의하고 최적화 문제를 푸는 모델학습 과정을 살펴보자.\n$$ R \\approx P \\times Q^T = \\widehat R\\ P \\rightarrow |U| \\times k\\ Q \\rightarrow |I| \\times k $$\n![MF](/imgs/Matrix Factorization.png)\nObjective Function\r#\r기본 형태\r#\r$$ \\tt \\min {P, Q} \\sum{\\text {observed } r_{u, i}}\\left(r_{u, i}-p_u^T q_i\\right)^2 $$\n$r_{u,i}:$ 학습 데이터에 있는 유저 $u$의 아이템 $i$에 대한 실제 rating\n$p_u,q_i:$ 유저($u$)와 아이템($i$)의 latent vector\n학습을 통해 알아내고자 하는 목표\n최적화 문제를 통해 갱신되는 파라미터\n$\\widehat {r_{u,i}} = p_u^Tq_i$ : 예측된 Rating Matrix\n원본 수식처럼 $p \\times q^T$ 가 아닌 $p^T \\times q$ 인 이유\n우선, $r_{u,i}$, $p_{u,x}$, 그리고 $q_{x,i}$는 각각 다음을 의미한다.($Q^T$ 헷갈리지 않게 주의)\n$r_{u,i}$ : $R$의 $(u,i)$번째 원소\n$p_{u,x}$ : $P$의 $(u,x)$번째 원소\n$q_{x,i}$ : $Q^T$의 $(x,i)$번째 원소\n또한, 행렬 연산에서 벡터는 보통 \u0026ldquo;열벡터(column vector)\u0026ldquo;를 의미하므로\n$P$의 $u$번째 행($p_{u,1:k}$)은 $P^T$의 $u$번째 열($p^T_{1:k,u}$), 즉 $p^T_u$로 표현할 수 있다.\n따라서, 해당 공식에서 $R$의 $(u,i)$번째 원소의 추정치인 $\\widehat{r_{u,i}}$는\n$P^T$의 $u$번째 열벡터($p^T_u$)와 $Q^T$의 $i$번째 열벡터($q_i$)를 곱한 값이라고 할 수 있다.\n물론, $\\widehat{r_{u,i}}$는 $1 \\times 1$ 크기의 행렬이므로 우측 항에 전치를 취해도 결과가 동일하다.\n( $\\therefore \\widehat{r_{u,i}} = p^T_u \\cdot q_i = q^T_i \\cdot p_u$ )\n최종 형태\r#\r$$ \\tt \\min {P, Q} \\sum{\\text {observed }r_{u,i}}\\left(r_{u, i}-p_u^T q_i\\right)^2 +{\\lambda\\left(\\left|p_u\\right|_2^2+\\left|q_i\\right|_2^2\\right)} $$\n$\\lambda$(상수)배 된 penalty term은 L2 — Regularization(규제)\n학습 데이터에 과적합되는 것을 방지한다.\nMF 학습\r#\rSGD: Stochastic gradient descent(확률적 경사 하강법)\nMF 모델에서의 SGD\nError $e_{ui}$\n$$ \\tt e_{u i}=r_{u i}-p_u^T q_i\n$$\nLoss $L$\n$$ \\tt L=\\sum\\left(r_{u, i}-p_u^T q_i\\right)^2+\\lambda\\left(\\left|p_u\\right|_2^2+\\left|q_i\\right|_2^2\\right) \\quad\n$$\nLoss를 $p_u$로 미분하여 최솟값 계산\nGradient\n$$ {\\tt{\\frac{\\partial L}{\\partial p_u}=\\frac{\\partial\\left(r_{u i}-p_u^T q_i\\right)^2}{\\partial p_u}+\\frac{\\partial \\lambda\\left|p_u\\right|2^2}{\\partial p_u}}}\\\\tt{ \\=-2\\left(r{u i}-p_u^T q_i\\right) q_i+2 \\lambda p_u}\n$$\n이를 Error Term을 활용하여 아래와 같이 나타낼 수 있다.\n$$ \\tt \\frac{\\partial L}{\\partial p_u}=-2\\left(e_{u i} q_i-\\lambda p_u\\right) $$\nGradient의 반대 방향으로 $p_u$, $q_i$를 업데이트\n$$ {\\tt \\p_u \\leftarrow p_u+\\eta \\cdot\\left(e_{u i} q_i-\\lambda p_u\\right)}\\ \\tt q_i \\leftarrow q_i+\\eta \\cdot\\left(e_{u i} p_u-\\lambda q_i\\right) $$\n부호가 바뀐다.\nMF 기반 추천으로 가장 널리 알려진 논문\r#\rMatrix Factorization Techniques for Recommender Systems\n기본적인 MF에 다양한 테크닉을 추가하여 성능을 향상시켰다.\nAdding Biases\r#\r어떤 유저는 모든 영화에 대해 평점을 낮게 줄 수도 있다.\n아이템도 마찬가지로 편향이 발생할 수 있다.\n⇒ 전체 평균 $\\mu$, 유저, 아이템의 bias를 추가하여 예측 성능을 높인다.\n기존 목적 함수\n$$ \\tt \\min {P, Q} \\sum{\\text {observed }r_{u,i}}\\left(r_{u, i}-p_u^T q_i\\right)^2+\\lambda\\left(\\left|p_u\\right|_2^2+\\left|q_i\\right|_2^2\\right) $$\nBias가 추가된 목적 함수\n$$ {\\tt \\min {P, Q} \\sum{\\text {observed } r_{u,i}}\\left(r_{u, i}-{\\mu - b_u-b_i}-p_u^T q_i\\right)^2} \\+\\tt \\lambda\\left(|| p_u\\left|_2^2+|| q_i\\right|_2^2+{b_u^2+b_i^2}\\right) $$\n마찬가지로 bias가 규제 term에 추가되어 과적합되지 않게 한다.\nError\n$$ \\tt e_{u,i} = r_{u,i} - \\mu - b_u - b_i - p_u^Tq_i $$\nGradient의 반대방향으로 $\\tt b_u, b_i, x_u, y_i$를 업데이트\n$$ \\begin{aligned}\u0026amp; {b_u \\leftarrow b_u+\\gamma \\cdot\\left(e_{u i}-\\lambda b_u\\right)} \\\u0026amp; {b_i \\leftarrow b_i+\\gamma \\cdot\\left(e_{u i}-\\lambda b_i\\right) } \\\u0026amp; p_u \\leftarrow p_u+\\gamma \\cdot\\left(e_{u i} q_i-\\lambda p_u\\right) \\\u0026amp; q_i \\leftarrow q_i+\\gamma \\cdot\\left(e_{u i} p_u-\\lambda q_i\\right)\\end{aligned} $$\nAdding Confidence Level\r#\r모든 평점이 동일한 신뢰도를 갖지 않는다. ⇒ $r_{u,i}$에 대한 신뢰도를 의미하는 $c_{u,i}$를 추가\n대규모 광고 집행과 같이 특정 아이템이 많이 노출되어 클릭되는 경우\n유저의 아이템에 대한 평점이 정확하지 않은 경우(implicit Feedback)\n기존 목적 함수\n$$ {\\tt \\min {P, Q} \\sum{\\text {observed } r_{u,i}}\\left(r_{u, i}-\\mu-b_u-b_i-p_u^T q_i\\right)^2} \\+\\tt\\lambda\\left(|| p_u\\left|_2^2+|| q_i\\right|_2^2+b_u^2+b_i^2\\right) $$\nConfidence Level이 추가된 목적함수\n$$ {\\tt \\min {P, Q} \\sum{\\text {observed } r_{u, i}} {c_{u, i}}\\left(r_{u, i}-\\mu-b_u-b_i-p_u^T q_i\\right)^2}\\+\\tt\\lambda\\left(|| p_u\\left|_2^2+|| q_i\\right|_2^2+b_u^2+b_i^2\\right) $$\nAdding Temporal Dynamics\r#\r시간에 따라 변하는 유저, 아이템의 특성을 반영하고 싶다.\n아이템이 시간이 지남에 따라 인기도가 떨어진다.\n유저가 시간이 흐르면서 평점을 내리는 기준이 엄격해진다.\n시간을 반영한 평점 예측\n학습 파라미터가 시간을 반영하도록 모델 설계\n$$ \\tt \\widehat r_{ui}(t) = \\mu + b_u(t) + b_i(t) + p^T_uq_i(t) $$\n단점\r#\rp, q 변수가 2개라서 빠른계산이 불가능하다. SGD를 학습하는 과정에서 업데이트를 여러 번 하기 때문에 빠른 계산이 불가능하다는 단점이 누적된다. 유저 수와 아이템 수가 커질수록 반복문으로 인한 연산량 증가 예시\r여기서는 정답 횟수를 행렬의 값으로 사용하였지만 문제별로 사용한 시간의 평균 혹은 다른 feature를 값으로 활용한다면 다른 잠재 요인 값들을 얻어낼 수 있다.\n$R \\approx PQ^{T}$ $R$ : 유저들에 대한 문제별 정답 횟수 행렬 $P$ : 유저와 잠재 요인의 행렬 $Q$ : 문제와 잠재 요인의 행렬 참고하면 좋은 자료\nUnderstanding of Matrix Factorization (MF) and Singular Value Decomposition (SVD) - Medium Latent Matrix Factorization - Medium "},{"id":3,"href":"/posts/2023-05-20-1x1-Convolution/","title":"1 x 1 Convolution","section":"Blog","content":"차원 축소를 위해 활용한다.\n이미지에서 단 하나의 픽셀만 보기 때문에, 이미지에서 영역을 살펴보는 의미는 없다.\n다만, 1 * 1 Convolution을 이용하여 기존 Spatial Dimension을 그대로 유지한 채, 채널의 개수를 128개에서 32개로 줄인다.\n![1x1 Conv_1](/imgs/1x1 Conv_1.png)\n이를 통해 NN의 층을 더 깊게 쌓으면서도, 채널의 수를 줄여서 파라미터의 수를 줄일 수 있다.\n1 * 1 Convolution을 사용하지 않는 경우\n![1x1 Conv_2](/imgs/1x1 Conv_2.png)\n1 * 1 Convolution을 사용한 경우\n![1x1 Conv_3](/imgs/1x1 Conv_3.png)\n파라미터 수를 147,456개에서 40,960개로 효과적으로 줄일 수 있다.\n대표적인 예로 Bottleneck architecture 구조가 1 * 1 Convolution을 이용한다.\n1x1 convolution의 의미 = 차원 축소, 그리고 bottleneck (컨볼루션과 보틀넥)\n"},{"id":4,"href":"/posts/goisforlovers/","title":"(Hu)go Template Primer","section":"Blog","content":"Hugo uses the excellent Go html/template library for its template engine. It is an extremely lightweight engine that provides a very small amount of logic. In our experience that it is just the right amount of logic to be able to create a good static website. If you have used other template systems from different languages or frameworks you will find a lot of similarities in Go templates.\nThis document is a brief primer on using Go templates. The Go docs provide more details.\nIntroduction to Go Templates\r#\rGo templates provide an extremely simple template language. It adheres to the belief that only the most basic of logic belongs in the template or view layer. One consequence of this simplicity is that Go templates parse very quickly.\nA unique characteristic of Go templates is they are content aware. Variables and content will be sanitized depending on the context of where they are used. More details can be found in the Go docs.\nBasic Syntax\r#\rGolang templates are HTML files with the addition of variables and functions.\nGo variables and functions are accessible within {{ }}\nAccessing a predefined variable \u0026ldquo;foo\u0026rdquo;:\n{{ foo }}\rParameters are separated using spaces\nCalling the add function with input of 1, 2:\n{{ add 1 2 }}\rMethods and fields are accessed via dot notation\nAccessing the Page Parameter \u0026ldquo;bar\u0026rdquo;\n{{ .Params.bar }}\rParentheses can be used to group items together\n{{ if or (isset .Params \u0026quot;alt\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;) }} Caption {{ end }}\rVariables\r#\rEach Go template has a struct (object) made available to it. In hugo each template is passed either a page or a node struct depending on which type of page you are rendering. More details are available on the variables page.\nA variable is accessed by referencing the variable name.\n\u0026lt;title\u0026gt;{{ .Title }}\u0026lt;/title\u0026gt;\rVariables can also be defined and referenced.\n{{ $address := \u0026quot;123 Main St.\u0026quot;}}\r{{ $address }}\rFunctions\r#\rGo template ship with a few functions which provide basic functionality. The Go template system also provides a mechanism for applications to extend the available functions with their own. Hugo template functions provide some additional functionality we believe are useful for building websites. Functions are called by using their name followed by the required parameters separated by spaces. Template functions cannot be added without recompiling hugo.\nExample:\n{{ add 1 2 }}\rIncludes\r#\rWhen including another template you will pass to it the data it will be able to access. To pass along the current context please remember to include a trailing dot. The templates location will always be starting at the /layout/ directory within Hugo.\nExample:\n{{ template \u0026quot;chrome/header.html\u0026quot; . }}\rLogic\r#\rGo templates provide the most basic iteration and conditional logic.\nIteration\r#\rJust like in Go, the Go templates make heavy use of range to iterate over a map, array or slice. The following are different examples of how to use range.\nExample 1: Using Context\n{{ range array }}\r{{ . }}\r{{ end }}\rExample 2: Declaring value variable name\n{{range $element := array}}\r{{ $element }}\r{{ end }}\rExample 2: Declaring key and value variable name\n{{range $index, $element := array}}\r{{ $index }}\r{{ $element }}\r{{ end }}\rConditionals\r#\rIf, else, with, or, \u0026amp; and provide the framework for handling conditional logic in Go Templates. Like range, each statement is closed with end.\nGo Templates treat the following values as false:\nfalse 0 any array, slice, map, or string of length zero Example 1: If\n{{ if isset .Params \u0026quot;title\u0026quot; }}\u0026lt;h4\u0026gt;{{ index .Params \u0026quot;title\u0026quot; }}\u0026lt;/h4\u0026gt;{{ end }}\rExample 2: If -\u0026gt; Else\n{{ if isset .Params \u0026quot;alt\u0026quot; }}\r{{ index .Params \u0026quot;alt\u0026quot; }}\r{{else}}\r{{ index .Params \u0026quot;caption\u0026quot; }}\r{{ end }}\rExample 3: And \u0026amp; Or\n{{ if and (or (isset .Params \u0026quot;title\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;)) (isset .Params \u0026quot;attr\u0026quot;)}}\rExample 4: With\nAn alternative way of writing \u0026ldquo;if\u0026rdquo; and then referencing the same value is to use \u0026ldquo;with\u0026rdquo; instead. With rebinds the context . within its scope, and skips the block if the variable is absent.\nThe first example above could be simplified as:\n{{ with .Params.title }}\u0026lt;h4\u0026gt;{{ . }}\u0026lt;/h4\u0026gt;{{ end }}\rExample 5: If -\u0026gt; Else If\n{{ if isset .Params \u0026quot;alt\u0026quot; }}\r{{ index .Params \u0026quot;alt\u0026quot; }}\r{{ else if isset .Params \u0026quot;caption\u0026quot; }}\r{{ index .Params \u0026quot;caption\u0026quot; }}\r{{ end }}\rPipes\r#\rOne of the most powerful components of Go templates is the ability to stack actions one after another. This is done by using pipes. Borrowed from unix pipes, the concept is simple, each pipeline\u0026rsquo;s output becomes the input of the following pipe.\nBecause of the very simple syntax of Go templates, the pipe is essential to being able to chain together function calls. One limitation of the pipes is that they only can work with a single value and that value becomes the last parameter of the next pipeline.\nA few simple examples should help convey how to use the pipe.\nExample 1 :\n{{ if eq 1 1 }} Same {{ end }}\ris the same as\n{{ eq 1 1 | if }} Same {{ end }}\rIt does look odd to place the if at the end, but it does provide a good illustration of how to use the pipes.\nExample 2 :\n{{ index .Params \u0026quot;disqus_url\u0026quot; | html }}\rAccess the page parameter called \u0026ldquo;disqus_url\u0026rdquo; and escape the HTML.\nExample 3 :\n{{ if or (or (isset .Params \u0026quot;title\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;)) (isset .Params \u0026quot;attr\u0026quot;)}}\rStuff Here\r{{ end }}\rCould be rewritten as\n{{ isset .Params \u0026quot;caption\u0026quot; | or isset .Params \u0026quot;title\u0026quot; | or isset .Params \u0026quot;attr\u0026quot; | if }}\rStuff Here\r{{ end }}\rContext (aka. the dot)\r#\rThe most easily overlooked concept to understand about Go templates is that {{ . }} always refers to the current context. In the top level of your template this will be the data set made available to it. Inside of a iteration it will have the value of the current item. When inside of a loop the context has changed. . will no longer refer to the data available to the entire page. If you need to access this from within the loop you will likely want to set it to a variable instead of depending on the context.\nExample:\n{{ $title := .Site.Title }}\r{{ range .Params.tags }}\r\u0026lt;li\u0026gt; \u0026lt;a href=\u0026quot;{{ $baseurl }}/tags/{{ . | urlize }}\u0026quot;\u0026gt;{{ . }}\u0026lt;/a\u0026gt; - {{ $title }} \u0026lt;/li\u0026gt;\r{{ end }}\rNotice how once we have entered the loop the value of {{ . }} has changed. We have defined a variable outside of the loop so we have access to it from within the loop.\nHugo Parameters\r#\rHugo provides the option of passing values to the template language through the site configuration (for sitewide values), or through the meta data of each specific piece of content. You can define any values of any type (supported by your front matter/config format) and use them however you want to inside of your templates.\nUsing Content (page) Parameters\r#\rIn each piece of content you can provide variables to be used by the templates. This happens in the front matter.\nAn example of this is used in this documentation site. Most of the pages benefit from having the table of contents provided. Sometimes the TOC just doesn\u0026rsquo;t make a lot of sense. We\u0026rsquo;ve defined a variable in our front matter of some pages to turn off the TOC from being displayed.\nHere is the example front matter:\n---\rtitle: \u0026#34;Permalinks\u0026#34;\rdate: \u0026#34;2013-11-18\u0026#34;\raliases:\r- \u0026#34;/doc/permalinks/\u0026#34;\rgroups: [\u0026#34;extras\u0026#34;]\rgroups_weight: 30\rnotoc: true\r--- Here is the corresponding code inside of the template:\n{{ if not .Params.notoc }}\r\u0026lt;div id=\u0026quot;toc\u0026quot; class=\u0026quot;well col-md-4 col-sm-6\u0026quot;\u0026gt;\r{{ .TableOfContents }}\r\u0026lt;/div\u0026gt;\r{{ end }}\rUsing Site (config) Parameters\r#\rIn your top-level configuration file (eg, config.yaml) you can define site parameters, which are values which will be available to you in chrome.\nFor instance, you might declare:\nparams: CopyrightHTML: \u0026#34;Copyright \u0026amp;#xA9; 2013 John Doe. All Rights Reserved.\u0026#34; TwitterUser: \u0026#34;spf13\u0026#34; SidebarRecentLimit: 5 Within a footer layout, you might then declare a \u0026lt;footer\u0026gt; which is only provided if the CopyrightHTML parameter is provided, and if it is given, you would declare it to be HTML-safe, so that the HTML entity is not escaped again. This would let you easily update just your top-level config file each January 1st, instead of hunting through your templates.\n{{if .Site.Params.CopyrightHTML}}\u0026lt;footer\u0026gt;\r\u0026lt;div class=\u0026#34;text-center\u0026#34;\u0026gt;{{.Site.Params.CopyrightHTML | safeHtml}}\u0026lt;/div\u0026gt;\r\u0026lt;/footer\u0026gt;{{end}} An alternative way of writing the \u0026ldquo;if\u0026rdquo; and then referencing the same value is to use \u0026ldquo;with\u0026rdquo; instead. With rebinds the context . within its scope, and skips the block if the variable is absent:\n{{with .Site.Params.TwitterUser}}\u0026lt;span class=\u0026#34;twitter\u0026#34;\u0026gt;\r\u0026lt;a href=\u0026#34;https://twitter.com/{{.}}\u0026#34; rel=\u0026#34;author\u0026#34;\u0026gt;\r\u0026lt;img src=\u0026#34;/images/twitter.png\u0026#34; width=\u0026#34;48\u0026#34; height=\u0026#34;48\u0026#34; title=\u0026#34;Twitter: {{.}}\u0026#34;\ralt=\u0026#34;Twitter\u0026#34;\u0026gt;\u0026lt;/a\u0026gt;\r\u0026lt;/span\u0026gt;{{end}} Finally, if you want to pull \u0026ldquo;magic constants\u0026rdquo; out of your layouts, you can do so, such as in this example:\n\u0026lt;nav class=\u0026#34;recent\u0026#34;\u0026gt;\r\u0026lt;h1\u0026gt;Recent Posts\u0026lt;/h1\u0026gt;\r\u0026lt;ul\u0026gt;{{range first .Site.Params.SidebarRecentLimit .Site.Recent}}\r\u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;{{.RelPermalink}}\u0026#34;\u0026gt;{{.Title}}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r{{end}}\u0026lt;/ul\u0026gt;\r\u0026lt;/nav\u0026gt; "},{"id":5,"href":"/posts/hugoisforlovers/","title":"Getting Started with Hugo","section":"Blog","content":"\rStep 1. Install Hugo\r#\rGo to Hugo releases and download the appropriate version for your OS and architecture.\nSave it somewhere specific as we will be using it in the next step.\nMore complete instructions are available at Install Hugo\nStep 2. Build the Docs\r#\rHugo has its own example site which happens to also be the documentation site you are reading right now.\nFollow the following steps:\nClone the Hugo repository Go into the repo Run hugo in server mode and build the docs Open your browser to http://localhost:1313 Corresponding pseudo commands:\ngit clone https://github.com/spf13/hugo\rcd hugo\r/path/to/where/you/installed/hugo server --source=./docs\r\u0026gt; 29 pages created\r\u0026gt; 0 tags index created\r\u0026gt; in 27 ms\r\u0026gt; Web Server is available at http://localhost:1313\r\u0026gt; Press ctrl+c to stop\rOnce you\u0026rsquo;ve gotten here, follow along the rest of this page on your local build.\nStep 3. Change the docs site\r#\rStop the Hugo process by hitting Ctrl+C.\nNow we are going to run hugo again, but this time with hugo in watch mode.\n/path/to/hugo/from/step/1/hugo server --source=./docs --watch\r\u0026gt; 29 pages created\r\u0026gt; 0 tags index created\r\u0026gt; in 27 ms\r\u0026gt; Web Server is available at http://localhost:1313\r\u0026gt; Watching for changes in /Users/spf13/Code/hugo/docs/content\r\u0026gt; Press ctrl+c to stop\rOpen your favorite editor and change one of the source content pages. How about changing this very file to fix the typo. How about changing this very file to fix the typo.\nContent files are found in docs/content/. Unless otherwise specified, files are located at the same relative location as the url, in our case docs/content/overview/quickstart.md.\nChange and save this file.. Notice what happened in your terminal.\n\u0026gt; Change detected, rebuilding site\r\u0026gt; 29 pages created\r\u0026gt; 0 tags index created\r\u0026gt; in 26 ms\rRefresh the browser and observe that the typo is now fixed.\nNotice how quick that was. Try to refresh the site before it\u0026rsquo;s finished building. I double dare you. Having nearly instant feedback enables you to have your creativity flow without waiting for long builds.\nStep 4. Have fun\r#\rThe best way to learn something is to play with it.\n"},{"id":6,"href":"/posts/2023-10-12-LeakGAN/","title":"[논문 리뷰] LeakGAN: Long Text Generation via Adversarial Training with Leaked Information","section":"Blog","content":" ✔️ 간단 요약\nSparsity와 Non-Informative를 효과적으로 해결한다.\n분별망에게 스파이를 심어 생성망이 분별망을 더 잘 속일 수 있도록 구성한다.\nHierarchical RL architecture (MANAGER, WORKER)\nMANAGER (LSTM)\n중재자 역할 D로부터 고수준 feature representation을 받음 → Leakage WORKER (LSTM)\n$s_t$를 인코딩한 후, MANAGER가 넘겨준 Goal 임베딩과 결합한다. (내적) D가 넘겨준 guiding signal은 scalar 보상 값으로도 쓰이고, 문장 생성 과정에서 Goal 임베딩으로도 쓰인다. {: .prompt-info } logit, temperature parameter, highway network(gate), leakgan의 3가지 학습 방법, CNN for text classification, truncated normalization\n배경\r#\r1. RNN – 문장 생성을 위한 가장 기본적인 방법\r#\r이전에 생성된 단어를 활용하여 다음 단어를 생성해내는 방식\nground-truth 단어들의 log-likelihood를 최대화한다.\nSupervising(Ground-Truth에 대한 설정) 필요\n학습과 추론 단계의 불일치에 의해 편차가 발생\n해결책으로 Scheduled sampling approach 제안 → 실패\n2. GAN – 목적은 생성망 G의 성능을 개선하는 것\r#\r이를 위해 생성물의 진위 여부를 평가하는 분별망 D와 대립 Jenson-Shannon 거리 활용 생성망의 성능이 충분히 좋아지면 분별망 갖다버림 3. GAN의 한계 및 해결책\r#\r제한적인 생성 가능한 문장의 길이(최대 20단어)\nNon-informative guiding signal\n문장 → 스칼라 값(guiding signal)\n변환 과정에서 G가 학습하는 문장의 구조 및 의미를 보장하지 않음.\n⇒ D가 G에게 점수와 함께 임베딩(feature representation)을 제공하여 해결\nG는 D의 feature representation에 일치하도록 임베딩 학습\nSparsity\n긴 문장 생성 시 binary guiding signal을 활용 → 전체 문장이 생성되었을 때만 가능\n⇒ 문장 생성을 여러 단계(계층)으로 구분하여 signal을 더 많이 제공\nSparsity가 일부 해결될 뿐만 아니라, Task가 작아져 모델 학습 용이\nbut, 문장 생성 단계에 대한 사전 정의가 필요\n⇒ 랜덤 문장 생성에는 적용 불가능\n아이디어\r#\rSparsity와 Non-Informative를 효과적으로 해결하기 위해 LeakGAN 제안한다.\n분별망에게 스파이를 심어 생성망이 분별망을 더 잘 속일 수 있도록 구성한다.\nMANAGER (LSTM)\r#\r중재자 역할 D로부터 고수준 feature representation을 받는다. → Leakage 따라서 해당 정보는 전역적으로 관리된다. 물론 게임 진행 중에는 G에게 해당 정보를 제공하지 않는다. 해당 정보를 바탕으로 Goal 임베딩 생성 후 WORKER에게 넘긴다. WORKER (LSTM)\r#\r현재까지 생성된 문장을 인코딩한 후, MANAGER가 넘겨준 Goal 임베딩과 결합한다. (내적) D가 넘겨준 guiding signal은 scalar 보상 값으로도 쓰이고, 문장 생성 과정에서 Goal 임베딩으로도 쓰인다.\n구체적 방법론\r#\r텍스트 생성 문제 → Sequential Decision Making Process\n$s_t : t$ 시점까지 생성된 단어들. $(x_1,\\dots, x_i, \\dots, x_t)$ $x_i:$ 단어(token) 생성망 $G_\\theta$\r#\r$G_\\theta:$ 파라미터가 $\\theta$인 생성망\n$s_t$를 전체 어휘 분포와 매핑시킨다.\nex) $x_{t+1}$에서 \u0026amp;G_\\theta(\\sdot | s_t)\u0026amp; 학습\n분별망이 유출해준 정보를 계층 구조를 통해 효과적으로 포함하여 문장을 생성한다.\n생성망의 계층 구조\r#\rD의 유출된 정보를 이용하기 위한 MANAGER-WORKER 계층 구조\nMANAGER: $t$시점마다 추출된 $f_t$를 활용해 $g_t$ 생성\n$f_t$를 LSTM에 입력한 후 goal vector $g_t$를 생성한다.\n$$ \\begin{aligned}\\hat{g}t, h_t^M \u0026amp; =\\mathcal{M}\\left(f_t, h{t-1}^M ; \\theta_m\\right) \\g_t \u0026amp; =\\hat{g}_t /\\left|\\hat{g}_t\\right|\\end{aligned} $$\n$M:$ LSTM 모델\n$\\mathcal{M}:$ MANAGER 모듈\n$\\theta_m :$ $\\mathcal M$의 파라미터\n$h_t:$ t시점의 hidden state\nclass Manager(nn.Module):\rinit, init_params\ndef __init__(self, batch_size, hidden_dim, goal_out_size): super(Manager, self).__init__() self.batch_size = batch_size self.hidden_dim = hidden_dim self.goal_out_size = goal_out_size self.recurrent_unit = nn.LSTMCell( self.goal_out_size, #input size self.hidden_dim #hidden size ) self.fc = nn.Linear( self.hidden_dim, #in_features self.goal_out_size #out_features ) self.goal_init = nn.Parameter(torch.zeros(self.batch_size, self.goal_out_size)) self._init_params() def _init_params(self): for param in self.parameters(): nn.init.normal_(param, std=0.1) self.goal_init.data = truncated_normal( self.goal_init.data.shape ) forward\ndef forward(self, f_t, h_m_t, c_m_t): \u0026#34;\u0026#34;\u0026#34; f_t = feature of CNN from discriminator leaked at time t, it is input into LSTM h_m_t = ouput of previous LSTMCell c_m_t = previous cell state \u0026#34;\u0026#34;\u0026#34; h_m_tp1, c_m_tp1 = self.recurrent_unit(f_t, (h_m_t, c_m_t)) sub_goal = self.fc(h_m_tp1) # 하위 텐서의 p-norm이 값 maxnorm보다 낮도록 # 차원에 따라 입력의 각 하위 텐서가 정규화되는 텐서를 반환한다. sub_goal = torch.renorm(sub_goal, 2, 0, 1.0) return sub_goal, h_m_tp1, c_m_tp1 WORKER: MANAGER의 $g_t$를 토대로 보상을 높이는 다음 단어 생성\nMANAGER의 $g_t$를 포함하기 위해 가중치 행렬 $W_\\psi$로 최근 c개의 목표들에 대한 선형 변환을 수행한다.\n이를 통해 k차원의 goal embedding vector $w_t$를 얻는다.\n$$ w_t=\\psi\\left(\\sum_{i=1}^c g_{t-i}\\right)=W_\\psi\\left(\\sum_{i=1}^c g_{t-i}\\right) $$\n$\\psi:$ 선형 변환(행렬 곱셈) $$ \\begin{aligned}O_t, h_t^W \u0026amp; =\\mathcal{W}\\left(x_t, h_{t-1}^W ; \\theta_w\\right) \\G_\\theta\\left(\\cdot \\mid s_t\\right) \u0026amp; =\\operatorname{softmax}\\left(O_t \\cdot w_t / \\alpha\\right) \\end{aligned} $$\n$\\mathcal W:$ WORKER 모듈\n$x_t:$ input. (t 시점의 단어)\n$\\theta_w :$ $\\mathcal W$의 파라미터\n$O_t :$ 행렬 내적으로 $w_t$와 추가로 결합된 행렬. $|V| \\times k$\n모든 단어에 대한 벡터 집합을 의미한다.\n따라서, $O_t \\cdot w_t$ 는 모든 단어에 대해 logit을 계산한다.\n$\\alpha :$ generation entropy를 조절하기 위한 temperature parameter\n즉, 생성되는 문장의 참신함을 조절한다.\nsoftmax를 통해 현재까지 생성된 단어 집합 $s_t$에서 최종 action space 분포를 결정한다.\nclass Worker(nn.Module):\rinit, init_params\ndef __init__(self, batch_size, vocab_size, embed_dim, hidden_dim, goal_out_size, goal_size): super(Worker, self).__init__() self.batch_size = batch_size self.vocab_size = vocab_size self.embed_dim = embed_dim self.hidden_dim = hidden_dim self.goal_out_size = goal_out_size self.goal_size = goal_size **self.emb = nn.Embedding(self.vocab_size, self.embed_dim)** **self.recurrent_unit = nn.LSTMCell(self.embed_dim, self.hidden_dim)** **self.fc = nn.Linear(self.hidden_dim, self.goal_size*self.vocab_size)** **self.goal_change = nn.Parameter(torch.zeros(self.goal_out_size, self.goal_size))** self._init_params() def _init_params(self): for param in self.parameters(): nn.init.normal_(param, std=0.1) forward\ndef forward(self, x_t, h_w_t, c_w_t): \u0026#34;\u0026#34;\u0026#34; x_t = last word h_w_t = last output of LSTM in Worker c_w_t = last cell state of LSTM in Worker \u0026#34;\u0026#34;\u0026#34; x_t_emb = self.emb(x_t) h_w_tp1, c_w_tp1 = self.recurrent_unit(x_t_emb, (h_w_t, c_w_t)) output_tp1 = self.fc(h_w_tp1) output_tp1 = output_tp1.view(self.batch_size, self.vocab_size, self.goal_size) return output_tp1, h_w_tp1, c_w_tp1 생성망 G 학습\r#\r앞에서 설명한 G의 모든 과정은 미분 가능한 구조로 되어있다.\n따라서, REINFORCE와 같은 policy gradient algorithm을 적용하여 모델을 학습할 수 있다.\nLeakGAN 모델이 유의미한 의미 패턴을 찾을 수 있도록 MANAGER와 WORKER는 개별적으로 훈련한다.\nMANAGER — 식별 가능한 feature space에서의 이동 방향을 예측하도록 훈련된다.\nMANAGER의 gradient\n$$ \\nabla_{\\theta_m}^{\\mathrm{adv}} g_t=-Q_{\\mathcal{F}}\\left(s_t, g_t\\right) \\nabla_{\\theta_m} d_{\\cos }\\left(f_{t+c}-f_t, g_t\\left(\\theta_m\\right)\\right) $$\n$Q_{\\mathcal{F}}\\left(s_t, g_t\\right)=Q\\left(\\mathcal{F}\\left(s_t\\right), g_t\\right)=Q\\left(f_t, g_t\\right)=\\mathbb{E}\\left[r_t\\right]$\n몬테 카를로 탐색으로 추정한 현재 정책에 대한 보상 기댓값\n$d_{\\cos }:$ cosine similarity(similarity인지 distance인지 확인해보기)\n$c$번의 전환 후 feature representation의 변화$(f_{t+c} - f_t)$와 목적 벡터 $g_t$의 차이\n손실 함수에서는 높은 보상을 달성하기 위해 $g_t$가 특징 공간의 전환과 일치하도록 강제한다.\n$$ \\begin{aligned}\u0026amp; \\nabla_{\\theta_w} \\mathbb{E}{s{t-1} \\sim G}\\left[\\sum_{x_t} r_t^I \\mathcal{W}\\left(x_t \\mid s_{t-1} ; \\theta_w\\right)\\right]\\ = \u0026amp; \\mathbb{E}{s{t-1} \\sim G, x_t \\sim \\mathcal{W}\\left(x_t \\mid s_{t-1}\\right)}\\left[r_t^I \\nabla_{\\theta_w} \\log \\mathcal{W}\\left(x_t \\mid s_{t-1} ; \\theta_w\\right)\\right]\\end{aligned} $$\nWORKER — MANAGER의 지시를 따르도록 보상이 주어진다.\nREINFORCE 알고리즘을 활용하여 보상을 최대화한다.\n이는 $s_{t-1}$ 상태와 함께 WORKER가 취한 $x_t$ 작업을 샘플링하여 근사할 수 있다.\nWORKER에 제공되는 보상은 다음과 같이 정의된다.\n$$ r_t^I=\\frac{1}{c} \\sum_{i=1}^c d_{\\cos }\\left(f_t-f_{t-i}, g_{t-i}\\right) $$\n실제로는 $G_\\theta$는 적대적 학습 전에 사전 학습이 필요하다.\n사전 학습 시 일관성을 유지하기 위해 MANAGER의 기울기를 통한 별도의 훈련 체계를 사용한다.\n$$ \\nabla_{\\theta_m}^{\\mathrm{pre}} g_t=-\\nabla_{\\theta_m} d_{\\cos }\\left(\\hat{f}_{t+c}-\\hat{f}_t, g_t\\left(\\theta_m\\right)\\right) $$\n$\\hat{f}_t=\\mathcal{F}\\left(\\hat{s}t\\right), \\hat s_t, \\hat s{t + c}:$ 실제 텍스트의 상태 해당 수식은 앞에서 정의한 MANAGER 미분식에서 $Q_{\\mathcal{F}}\\left(s_t, g_t\\right)$가 $1$인 상태이다.\n사전 학습에 사용된 데이터는 모두 실제 문장이기 때문이다.\nfeature space에서 실제 문장 샘플의 전환을 모방하도록 학습된다.\nMLE(Maximum Likelihood Estimation)를 통해 훈련된다.\n학습 과정에서 $G_\\theta$와 $D_\\phi$는 번갈아가며 훈련된다.\n생성망에서도 MANAGER와 WORKER는 번갈아가며 서로를 고정한 채 훈련된다.\n분별망 $D_\\phi$\r#\r$D_\\phi:$ 파라미터가 $\\phi$인 분별망\n1. Scalar Guiding Signal $D_\\phi(s)$ 제공\r#\r전체 문장 $s_T$가 생성된 후 생성망이 파라미터를 조정할 때 가이드 역할을 한다.\n이 때, $D_\\phi(s)$는 문장이 길어질수록 정보량이 적어지므로, 이를 해결하기 위해 추가적인 정보 $f_t$를 제공한다.\nGuiding Signal(Leaked Features)\r#\r$$ D_\\phi(s)=\\operatorname{sigmoid}\\left(\\phi_l^{\\top} \\mathcal{F}\\left(s ; \\phi_f\\right)\\right)=\\operatorname{sigmoid}\\left(\\phi_l^{\\top} f\\right) $$\n$s:$ input. 생성된 문장. $\\mathcal F:$ CNN (특징맵 추출기) $f : D_\\phi(s)$ 의 마지막 Layer에서의 feature vector(유출된 정보) $\\phi_l^{\\top}:$ 가중치 벡터 즉, $f$에 의해 Reward Value가 결정되기 때문에, 보상을 높이도록 feature(특징맵)을 뽑아야 한다.\nLeakGAN에서는 Feature Extractor로 CNN을 활용하지만, LSTM이나 다른 신경망을 활용하여 구현할 수도 있다.\n2. $f_t = s_t$에서의 features\r#\r$f_t$는 분별망이 분별을 위해서 쓰이는 정보이기도 하다.\n따라서, 전역적으로 관리된다.\n3. Learned Reward Function을 설정한다.\r#\rBlack Box인 기존 RL 모델들과 대비된다.\nclass Discriminator(nn.Module):\rtext 분류를 위한 CNN 모델\nnum_filters (int): This is the output dim for each convolutional layer, which is the number of \u0026ldquo;filters\u0026rdquo; learned by that layer.\n__init__\ndef __init__(self, seq_len, num_classes, vocab_size, dis_emb_dim, filter_sizes, num_filters, start_token, goal_out_size, step_size, dropout_prob, l2_reg_lambda): super(Discriminator, self).__init__() self.seq_len = seq_len self.num_classes = num_classes self.vocab_size = vocab_size self.dis_emb_dim = dis_emb_dim self.filter_sizes = filter_sizes self.num_filters = num_filters self.start_token = start_token self.goal_out_size = goal_out_size self.step_size = step_size self.dropout_prob = dropout_prob self.l2_reg_lambda = l2_reg_lambda self.num_filters_total = sum(self.num_filters) #Building up layers **self.emb = nn.Embedding(self.vocab_size + 1, self.dis_emb_dim)** **self.convs = nn.ModuleList([ nn.Conv2d(1, num_f, (f_size, self.dis_emb_dim)) for f_size, num_f in zip(self.filter_sizes, self.num_filters) ])** **self.highway = nn.Linear(self.num_filters_total, self.num_filters_total)** #in_features = out_features = sum of num_festures self.dropout = nn.Dropout(p = self.dropout_prob) #Randomly zeroes some of the elements of the input tensor # with probability p using Bernouli distribution #Each channel will be zeroed independently onn every forward call **self.fc = nn.Linear(self.num_filters_total, self.num_classes)** highway\nclass Highway(nn.Module): #Highway Networks = Gating Function To Highway = y = xA^T + b def __init__(self, in_size, out_size): super(Highway, self).__init__() self.fc1 = nn.Linear(in_size, out_size) self.fc2 = nn.Linear(in_size, out_size) def forward(self, x): #highway = F.sigmoid(highway)*F.relu(highway) + (1. - transform)*pred # sets C = 1 - T g = F.relu(self.fc1) t = torch.sigmoid(self.fc2) out = g*t + (1. - t)*x return out t가 1이면 out = g\nt가 0이면 out = x\nt는 torch.sigmoid(self.fc2)에 의해 결정됨.\ntruncated_norm : 난수(절단된 정규분포)로 가중치 초기화에 사용\nimport torch from scipy.stats import truncnorm import torch.nn as nn import torch.nn.functional as F import numpy as np def truncated_normal(shape, lower=-0.2, upper=0.2): size = 1 for dim in shape: size *= dim w_truncated = truncnorm.rvs(lower, upper, size=size) w_truncated = torch.from_numpy(w_truncated).float() w_truncated = w_truncated.view(shape) return w_truncated forward\ndef forward(self, x): \u0026#34;\u0026#34;\u0026#34; Argument: x: shape(batch_size * self.seq_len) type(Variable containing torch.LongTensor) Return: pred: shape(batch_size * 2) For each sequence in the mini batch, output the probability of it belonging to positive sample and negative sample. feature: shape(batch_size * self.num_filters_total) Corresponding to f_t in original paper score: shape(batch_size, self.num_classes) \u0026#34;\u0026#34;\u0026#34; #1. Embedding Layer #2. Convolution + maxpool layer for each filter size #3. Combine all the pooled features into a prediction #4. Add highway #5. Add dropout. This is when feature should be extracted #6. Final unnormalized scores and predictions emb = self.emb(x).unsqueeze(1) convs = [F.relu(conv(emb)).squeeze(3) for conv in self.convs] # [batch_size * num_filter * seq_len] pooled_out = [F.max_pool1d(conv, conv.size(2)).squeeze(2) for conv in convs] # [batch_size * num_filter] pred = torch.cat(pooled_out, 1) # batch_size * sum(num_filters) highway = self.highway(pred) highway = torch.sigmoid(highway)* F.relu(highway) + (1.0 - torch.sigmoid(highway))*pred features = self.dropout(highway) score = self.fc(features) pred = F.log_softmax(score, dim=1) #batch * num_classes return {\u0026#34;pred\u0026#34;:pred, \u0026#34;feature\u0026#34;:features, \u0026#34;score\u0026#34;: score} def l2_loss(self): W = self.fc.weight b = self.fc.bias l2_loss = torch.sum(W*W) + torch.sum(b*b) l2_loss = self.l2_reg_lambda * l2_loss return l2_loss 학습 기술\r#\rBootstrapped Rescaled Activation\r#\r배경\nSeqGAN의 적대적 훈련 과정에서, $D$가 $G$보다 너무 강한 경우 심각한 gradient 소멸 문제가 발생한다.\n즉, 파라미터를 갱신하기에 보상이 너무 작기 때문에 $G$에게 값을 넘기기 전에 스케일 조정이 필요하다.\nRankGAN로부터 영감을 받은 rank 기반 방법\n보상 행렬 : $R_{B\\times T}$\n다음 수식으로 $t$번째 열 벡터 $R^t$의 스케일을 재조정한다.\n$$ R_i^t=\\sigma\\left(\\delta \\cdot\\left(0.5-\\frac{\\operatorname{rank}(i)}{B}\\right)\\right) $$\n$\\text {rank}(i):$ 열 벡터에서 i번째 원소의 ranking\n$\\delta :$ rescale 작업의 smoothness를 조정하는 하이퍼 파라미터\n$\\sigma(\\cdot) :$ 활성 함수(논문에서는 sigmoid)\n등간격 점수를 rank 기반으로 보다 효과적인 분포로 재구성한다.\n장점\n각 미니 배치에서 보상의 기대와 분산이 일정하다.\n값을 안정시켜 수치형 분산에 민감한 알고리즘에 도움이 된다.\n모든 ranking 방법과 동일하게, 모델 수렴을 가속화하는 gradient 소실 문제를 방지한다.\nInterleaved Training\r#\r사전 훈련 후 전부 GAN으로 학습하는 대신 일부는 지도 학습(ex — MLE)으로, 일부는 적대적 학습(ex — GAN)을 적용한다.\nex) 1 epoch 지도 학습 + 15 epoch 적대적 학습\nGAN이 local minima를 제거하는 데 도움을 준다. mode collapse를 예방한다. 삽입된 지도 학습이 생성 모델에 대해 암시적 규제를 수행하여 MLE 결과로부터 너무 멀리 떨어지는 것을 방지한다.\nTemperature Control\r#\r볼츠만 temperature $\\alpha$.\n탐험와 탐사의 균형을 맞추는 데 사용할 수 있는 요소\n모델 훈련 시 높은 temperature 설정 샘플 생성을 위해 모델 적용 시 낮은 temperature 설정 Pseudo Code\r#\r필요한 요소\r#\r계층 구조 생성망 $G(θ_m, θ_w)$\nMANAGER와 WORKER로 구성\n분별망 $D(φ)$\n이진 분류기\n훈련 데이터 셋\n시퀀스 데이터 집합 $S = {X_1:T}$\n알고리즘 단계\r#\r파라미터 초기화\n$G(θ_m, θ_w), D(φ)$를 랜덤 가중치 $θ_m, θ_w, φ$로 초기화\n사전 학습\n$D(φ)$ 사전 학습\n$D(φ)$를 시퀀스 데이터 집합 $S$를 양성 샘플로, $G$에서 생성된 시퀀스를 음성 샘플로 사용하여 사전 학습한다.\n이때, $D(φ)$는 특징 추출기($\\mathcal F$)와 출력 레이어(sigmoid)로 구성된다.\n$$ D_\\phi(s)=\\operatorname{sigmoid}\\left(\\phi_l^{\\top} \\mathcal{F}\\left(s ; \\phi_f\\right)\\right)=\\operatorname{sigmoid}\\left(\\phi_l^{\\top} f\\right) $$\n$G(θ_m, θ_w)$ 사전 학습\n$D(φ)$로부터 유출된 정보를 사용하여 학습한다.\n사전 학습을 수렴할 때까지 번갈아 수행한다.\n적대적 학습\n생성망 단계 (g-steps)\n$G(θ)$를 사용하여 시퀀스 $Y_1:T$를 생성\n각 $t$에 대해 $D(φ)$로부터 유출된 정보 $f_t$를 저장\n$Q\\left(f_t, g_t\\right)=\\mathbb{E}\\left[r_t\\right]$을 통해 Monte Carlo Search를 사용하여 $Q(f_t, g_t)$를 얻어낸다.\nMANAGER로부터 계산된 방향 $g_t$를 얻는다.\nWORKER 매개변수 $θ_w, ψ$, softmax를 갱신한다.\n$$ \\begin{aligned} \u0026amp; \\nabla_{\\theta_w} \\mathbb{E}{s{t-1} \\sim G}\\left[\\sum_{x_t} r_t^I \\mathcal{W}\\left(x_t \\mid s_{t-1} ; \\theta_w\\right)\\right] \\ = \u0026amp; \\mathbb{E}{s{t-1} \\sim G, x_t \\sim \\mathcal{W}\\left(x_t \\mid s_{t-1}\\right)}\\left[r_t^I \\nabla_{\\theta_w} \\log \\mathcal{W}\\left(x_t \\mid s_{t-1} ; \\theta_w\\right)\\right] \\end{aligned} $$\nMANAGER 매개변수 $θ_m$을 갱신한다.\n$$ \\nabla_{\\theta_m}^{\\mathrm{adv}} g_t=-Q\\left(f_t, g_t\\right) \\nabla_{\\theta_m} d_{\\cos }\\left(\\mathcal{F}\\left(s_{t+c}\\right)-\\mathcal{F}\\left(s_t\\right), g_t\\left(\\theta_m\\right)\\right) $$\n분별망 단계 (d-steps)\n현재 $G(θ_m, θ_w)$를 사용하여 음성 예제를 생성하고 주어진 양성 예제 S와 결합한다.\nk-epoch 동안 $D(φ)$를 훈련한다.\n$$ D_\\phi(s)=\\operatorname{sigmoid}\\left(\\phi_l \\cdot \\mathcal{F}\\left(s ; \\phi_f\\right)\\right)=\\operatorname{sigmoid}\\left(\\phi_l, f\\right) $$\nLeakGAN이 수렴할 때까지 반복한다.\n참고\r#\rLong Text Generation via Adversarial Training with Leaked Information\nPapers with Code - Text Generation\nLeakGAN Implement code with PyTorch - github\n"},{"id":7,"href":"/posts/2023-06-19-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EC%8B%9D%EB%B3%84-%EB%B0%8F-%EA%B4%80%EB%A6%AC/","title":"1. 프로젝트 식별 및 관리","section":"Blog","content":"프로젝트를 어떻게 시작하느냐에 대한 관점\n프로젝트를 시작하기 전, 어떻게 평가할 지, 그리고 어떻게 계획을 세울지를 설명한다.\n프로젝트 식별\r#\r1. System Request 작성\r#\rProject Sponsor\n프로젝트의 아이디어 제공자\n프로젝트의 금전적 지원자 아님.\nBusiness Need\nBusiness requirements\nBusiness Value : CEO의 입장에서 가장 먼저 보게된다.\n프로젝트의 Business Value가 명확해야 한다. Economic feasibility부분을 미리 고민해봐야 한다. Special issues or constraints\n프로젝트 마감 기간 등\nex) 크리스마스 시즌 전에 완성해야 한다.\n2. Feasibility Analysis(타당성 분석)\r#\r프로젝트를 진행하기 전에 분석해야 한다.\nTechnical feasibility\n기술적으로 개발이 가능한지에 대한 분석\n도메인과의 친숙도\n우리가 평소 개발하던 분야가 얼마나 해당 분야와 가까운가에 대한 것\n기술적 친숙도\n프로젝트 크기\n기존 시스템과의 경쟁성\n기존 시스템과의 호환성\n기존 프로젝트와의 비교\n외부 전문가의 평가\nEconomic feasibility\n해당 프로젝트가 돈이 되는지에 대한 분석\nNet present value(NPV)\nReturn on investment(ROI)\n클수록 좋다.\nBreak even point(BEP) : 손익분기점\n빠를수록 좋다.\nStep\nIdentify costs and benefits\nData Conversion Costs\n시스템 변경시 기존의 데이터를 새로운 시스템으로 옮기는 데 소모되는 비용\nTangible Benefits\n돈으로 쉽게 환산 가능한 이익\nIntangible Benefits\n돈으로 쉽게 환산하기 어려운 이익\n가능하면 Intangible Benefit을 돈으로 환산하여 수치화하는 것이 좋다. 가장 어렵다. Assign Cost and Benefit Values\n돈으로 환산하기\nDetermine Cash Flow\n재무재표 분석\nAssess Financial Viability\n현재가치로의 환산 : 복리를 활용\nNPV \u0026gt; 0 ⇒ 프로젝트가 괜찮다.\nOrganizational feasibility\n유저가 사용할 것인가에 대한 분석\nStrategic alignment\n이해관계자 분석(Stakeholder analysis)\nProject champion(s)\nOrganizational management\n예산에 대한 분석\nSystem users\n3. Project Selection Issues\r#\rPortfolio Management\n회사 전체의 포트폴리오 관점에서 진행할지 여부를 결정\n회사에서 진행하는 다른 프로젝트와의 밸런스 등을 고려, 최종적으로 진행여부를 결정.\n해당 방식이 반드시 회사 내에서 이뤄지지 않을 수도 있다.\n프로젝트의 요구사항(RFP)만 작성하면, 여러 외부업체들에서 프로젝트 제안서(proposal)을 받아서 업체를 선택하고, 완성된 프로젝트를 넘겨받는 방식도 존재한다.\nRFP를 작성하기 위해 프로젝트 관리에 대한 내용을 알아둬야 한다.\n원하는 프로젝트에 소요되는 시간, 비용, 노동력을 분석할 수 있어야 프로젝트를 합리적으로 요청할 수 있다.\n프로젝트 관리\r#\r프로젝트의 기간이 어떻게 되는지, 노동력은 얼마나 들어가는지에 대한 관점\n1. Identifying project size\r#\r비용을 결정하는 중요한 요소\nProject Estimation\nMathodology in use Actual previous projects Experienced developers 프로젝트의 비용과 시간과 크기는 서로 연관되기 때문에 시간의 흐름에 따라 계속 분석해야 한다.\nfunction points\n여기서 function은 프로그래밍 코드 상의 function이 아닌 진짜 기능을 의미한다.\n기능 유형\nInputs\n시스템에서 입력이 몇개나 필요한지에 대한 것.\n마찬가지로 단순한 파라미터를 의미하는 것이 아닌 입력 데이터의 종류를 의미한다.\nOutputs\nQueries\n참조하는 데이터의 개수? 좀 더 알아볼 것.\nFiles\nProgram Interfaces\n외부 Interface을 의미한다.\nfunction point 예시\n학점을 조회하는 것이 단순하게 출력만 한다면 EO라고 볼 수 있지만,\n학점을 가공하여 출력하는 경우 EQ가 된다.\n위의 학생 학점 조회는 EQ에 해당한다.(오타라고 짐작됨)\nLines of codes\nProject의 code line 수를 측정하면 대략적으로 알아낼 수 있다.\nfunction point를 계산하면 기능별 필요한 코드수가 나온다.\nPerson Months\n한 사람이 한달에 해내는 업무량\n만약 14 Person Months라면 한 사람이 14달동안 해야하는 작업량이라는 것.\n14명이 작업한다고 해서 작업기간이 1달로 줄지는 않는다.\n⇒ 업무에는 선후관계가 존재하기 때문이다.\n2. Creating and managing the workplan\r#\r프로젝트의 크기가 결정되고 난 후, PM은 계획을 짜야한다.\n계획을 짜기 위해서\n해야하는 업무를 나열해야 하고\n사람에게 업무를 할당해야 한다.\n업무가 너무 크다면 업무를 세분화시켜야 한다.\nWork Breakdown Structure\nworkplan\nTask name\nDuration of Dask\nCurrent task status\nTask dependencies\nMilestone (dates)\nworkplan 예시\n하지만 workplan으로는 파악하기가 불편하다. 시각화가 필요하다.\nGantt Chart\n간단한 모델\n업무의 기간만을 표시해놓은 바형 그래프\n정보가 너무 적다. 누가 해당 업무를 하는지, dependency에 대한 정보 등등이 없다. 정식 모델\nCritical Path\n어떤 업무가 조금이라도 밀린다면 전체 업무가 밀리는 경우\n업무간의 간격이 전혀 없는 경우\n위의 표에서 Alan의 path가 Critical path에 해당한다.\n보통 Critical Path는 가장 유능한 사람이 맡게 된다.\nAlan이 가장 유능하다고 짐작할 수 있다.\nPERT Chart\nX : 진행완료 \\ : 진행중 프로젝트 진행에 대한 예측 : 정밀한 예측은 절대 불가능하다.\n태풍의 경로를 예측하는 모델과 흡사하게 예상이 가능하다.\n과대평가 : 괜찮다. 과소평가 : 굉장히 위험하다. 따라서, 처음 예상을 할때 과대평가를 하는 것이 좋다.\n3. Staffing the project\r#\r4. Coordinating project activities\r#\r"},{"id":8,"href":"/posts/2023-08-06-5F-%EC%A3%BC%EA%B0%84%ED%9A%8C%EA%B3%A0%EB%A1%9D-230806/","title":"5F 8월 1주차 주간회고록","section":"Blog","content":"8월 2일 네트워킹 데이 때 기업에서 채용담당자 분들과 면담할 기회가 있었다.\n어떤 캠퍼가 기업관계자분께 *“신입 개발자에게 가장 중요한 것이 무엇이냐”*고 물었고, 이에 대한 대답으로\n문제를 잘 정의하고, 다양한 솔루션을 시도하는 역량\n이 중요하다고 말씀해주셨다.\n이 말을 캠퍼 50명과 함께 듣고 있었는데, 마치 나를 해주는 충고처럼 느껴졌다.\n아무래도 PM으로 프로젝트를 주도하다보니, 문제 정의와 다양한 솔루션 제안에서 많은 고민을 했기 때문에 더 크게 와닿았던 것이 아닐까 생각한다.\n그 충고를 듣고 보니 나는 일부 솔루션에 매몰되는 성향이 있었다.\n하나의 해결책이 보이면 그 해결책을 시도해보고, 안되면 다른 방법을 고민하기보단, 그 해결책을 되게 하느라 또 에너지를 쏟는다.\n여기까지는 탐구심이고 개발 역량을 키우는데 도움이 되기 때문에 문제가 없다.\n하지만 만약 하나의 해결책을 통해 끝내 성공하지 못한 경우, 최초의 문제 상황을 해결할 수 없다는 결론을 내려버린 경험이 꽤 있다.\n즉, 깊게 탐구한 이후에는 또다른 솔루션을 찾는 것에 피로감을 느껴 문제 해결을 포기해버린다.\n이런 상황을 어떻게 해결할까? 내가 생각한 해답은 이렇다.\n최초에 문제 상황을 명확하게 정의하고, 솔루션을 여러 개 나열해본 후에 수행하자. 이렇게 되면 하나의 솔루션이 실패하더라도, 나머지 솔루션이 남아있다는 사실을 망각하지 않을 수 있다.\n또한, 다른 솔루션들이 남아있다는 사실을 인지하고 있기 때문에, 하나의 솔루션에 과도한 노력을 투자하지 않을 수 있겠다.\n"},{"id":9,"href":"/posts/2023-05-20-Alexnet-%EB%AA%A8%EB%8D%B8%EC%9D%98-%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0-%EC%88%98-%EA%B3%84%EC%82%B0%ED%95%B4%EB%B3%B4%EA%B8%B0/","title":"Alexnet 모델의 파라미터 수 계산","section":"Blog","content":"\rConv Layer\r#\rLayer 1 파라미터 수 = 11 * 11 * 3 * 48 * 2 ⇒ 35k\n입력 : 224 * 224 * 3\nfilter : 11 * 11 * (3)\n3은 생략되어 있지만, 입력 크기와 동일한 채널을 가질 것이기 때문에 3으로 유추할 수 있다.\n모델 이미지상 커널이 위 아래로 두 개이기 때문에 * 2를 했다.\ngpu 메모리 용량 등의 이유로 이처럼 구성하는 경우가 많다.\nLayer 2 파라미터 수 = 5 * 5 * 48 * 128 * 2 ⇒ 307k\nLayer 3 파라미터 수 = 3 * 3 * 128 * 2 * 192 * 2 ⇒ 663k\nLayer 4 파라미터 수 = 3 * 3 * 192 * 128 * 2 ⇒ 884k\nLayer 5 파라미터 수 = 3 * 3 * 192 * 128 * 2 ⇒ 442k\nDense Layer\r#\rLayer 6 파라미터 수 = 13 * 13 * 128 * 2 * 2048 * 2 ⇒ 117M\nLayer 7 파라미터 수 = 2048 * 2 * 2048 * 2 ⇒ 16M\nLayer 8 파라미터 수 = 2048 * 2 * 1000 ⇒ 4M\nDense Layer의 파라미터가 Conv Layer의 파라미터 수에 비해 월등히 많은 것을 볼 수 있다.\n성능을 올리기 위해선 파라미터를 줄여야 한다.\n따라서, 네트워크가 발전됨에 따라 뒷부분의 Fully Connected Layer을 최대한 줄이고, 앞의 Conv Layer을 깊게 쌓게 된다.\n"},{"id":10,"href":"/posts/2023-06-29-Autoregression/","title":"Autoregression","section":"Blog","content":"회귀 분석의 관점에서 과거의 데이터를 보고 현재 또는 미래의 결과를 예측하는 것\n즉, Regression을 자기 자신에게 적용하는 것\n$$ y_1, \\ldots, y_n \\rightarrow y_{n+1} $$\n$$ \\mathrm{MSE}=\\frac{1}{n} \\sum_{i=1}^n\\left(f\\left(y_1, \\ldots y_i\\right)-y_{i+1}\\right)^2 $$\n종류\r#\rMoving Average(이동평균)\r#\r가장 간단한 방법\n최신 트렌드를 반영하기 위해 최근 K개의 평균을 향후 예측에 활용한다. K의 값에 따라 경향성을 다르게 모델링할 수 있다. K가 커질수록 최신 트렌드의 반영 정도가 줄어든다. 평균 뿐만 아니라 다양한 형태로 Moving Average의 모델링이 가능하다.\n$$ f\\left(y_1, \\ldots, y_n\\right)=\\frac{1}{K} \\sum_{k=0}^{K-1} y_{n-k} $$\n$$ f\\left(y_1, \\ldots, y_{n+1}\\right)=\\frac{1}{K}\\left(K \\cdot f\\left(y_1, \\ldots, y_n\\right){-y_{n-K+1}}{+y_{n+1}}\\right) $$\n${-y_{n-K+1}}$: 가장 오래된 값 삭제 ${+y_{n+1}}$ : 최근 값 추가 Weighted Moving Average\r#\r단순히 평균이 아니라 최근 값에 대한 가중치를 더 크게 주는 방법\n선형적으로 비중을 조절하는 것 뿐만 아니라 지수, 로그 등을 활용하여 다양한 방법으로 모델링이 가능하다.\n지수 함수를 활용하여 최근 값의 비중을 기하급수적으로 증가시켰다.\n$$ \\begin{gathered}f\\left(y_1\\right)=y_1 \\f\\left(y_1, \\ldots, y_{n+1}\\right)=\\alpha f\\left(y_1, \\ldots, y_n\\right)+(1-\\alpha) \\cdot y_{n+1}\\end{gathered} $$\nLearning-based Moving Average\r#\rWeighted moving average에서의 가중치를 학습하는 방법\n$$ f\\left(y_1, \\ldots, y_n\\right)=\\sum_{k=0}^{K-1} \\theta_k \\cdot y_{n-k} $$\n주기적인 변화가 있는 교통량 예측, 시즌 별 상품 소비 예측 등에 사용된다.\n주 단위, 월 단위 등의 주기성을 모델링하는 데 보다 적합하다.\n"},{"id":11,"href":"/posts/2023-09-25-backpropagation/","title":"Back Propagation(오차 역전파 알고리즘)","section":"Blog","content":"이 알고리즘으로 인해 ML Network에서의 학습이 가능하다는 것이 알려져, 암흑기에 있던 신경망 학계가 다시 관심을 받게 되었다.\n출력층에서 시작하여 역방향으로 오류를 전파한다는 뜻에서 오류 역전파라 부른다.\n내가 뽑고자 하는 target값과 실제 모델이 계산한 출력의 차이를 계산한다. 오차값을 다시 뒤로 전파해가면서 각 노드가 가지고 있는 변수들을 갱신한다. 직관적인 이해는 끝났다. 이제 제대로 이해해보자.\n오차 역전파가 중요한 이유를 알고 싶다면, 여기를 클릭하여 오차 역전파가 없을 시에 발생하는 문제점을 이해하자.\n오차 역전파\r#\r신경망을 학습하는 방법.\n연쇄 법칙을 활용하여 수치 미분에서의 연산량을 대폭 감소시킨다.\n수치 미분과 마찬가지로 손실 함수 위에서의 가중치의 기울기를 알게 해준다.\n즉, 해당 가중치가 얼마나 오차에 영향을 끼치는지 알게 해준다.\n(기울기에 대한 손실 함수의 미분)\n특정 가중치 w에 대해, 오차 L 위에서의 기울기는 $\\partial L\\over \\partial w$이다.\n연쇄 법칙(chain rule)\r#\r합성 함수의 미분은 합성 함수를 구성하는 각 함수의 미분의 곱으로 나타낼 수 있다.\n$$ {\\partial z\\over \\partial x} = {\\partial z\\over \\partial t}{\\partial t\\over \\partial x} $$\n합성 함수\n여러 함수로 구성된 함수\nex) $z = (x + y)^2$ $z = t^2$ $t = x + y$ 순전파, 역전파, 국소적 계산\r#\rex) $f(x) = y$\nf에 x를 집어넣으면 y가 튀어나온다.\n위의 그림처럼 어딘가에서 갑자기 등장한 $L$이라는 함수를 $y$로 미분한 값($\\partial L\\over \\partial y$)이 제공된다면?\n우리는 $L$이라는 함수를 모르지만, $x$로 미분한 값을 알 수 있다.\n연쇄법칙을 활용하면 된다.\n$$ {\\partial L\\over \\partial x} = {\\partial L\\over \\partial y}{\\partial y\\over \\partial x} $$\n우리는 $\\partial L\\over \\partial y$를 알고 있으니, $\\partial y\\over \\partial x$만 계산하면 된다.\n${\\partial y\\over \\partial x} = f\u0026rsquo;(x)$이므로, x에 대한 함수인 $f(x)$를 미분하면 된다.\nex) $f(x) = x^2 ⇒ f\u0026rsquo;(x) = 2x$\n이 때, 위의 예시에서 왼쪽에서 오른쪽으로 진행하는 단계를 순전파(forward propagation),\n오른쪽에서 왼쪽으로 진행하는 단계를 **역전파(backward propagation)**이라고 한다.\n국소적 계산\n전체에서 어떤 일이 벌어지든 상관없이 자신과 관계된 정보만을 결과로 출력할 수 있다.\n위의 예시처럼, 각 단계에서는 그저 $f(x)$의 미분값만 곱해서 하류로 흘러보낸 것이 전부다.\n단순한 국소적 계산이 연결되어 전체를 구성하는 복잡한 계산을 수행하게 된다.\n덧셈 노드에서의 역전파\r#\rex) $z = x + y$\n$\\partial z\\over \\partial x$ = 1 $\\partial z\\over \\partial y$ = 1 상류에서 내려온 신호인 $\\partial L\\over \\partial z$에 $\\partial z\\over \\partial x$를 곱함으로써 $\\partial L\\over \\partial x$을 구했다.\n단순한 덧셈 연산이기 때문에 미분값은 1이다.\n즉, 덧셈에서는 상류에서 내려온 값을 그대로 하류로 전달한다.\n곱셈 노드에서의 역전파\r#\rex) $z = xy$\n${\\partial z\\over \\partial x} = y$ ${\\partial z\\over \\partial y} = x$ 이므로,\n이 된다.\n즉, 단순한 곱셈 노드는 상류에서 내려온 신호를 교차시켜 곱한 후, 다시 하류로 보낸다.\n하지만 본질은 미분이다.\n$z = x^2$의 경우, 미분값은 $2x$가 되는 것을 명심하자.\n연쇄 법칙과 계산 그래프\r#\r처음에 예시로 들었던 함수 $z = (x+y)^2$를 그래프화 한 것이다.\n결론\r#\r역전파는 오차(손실 함수)를 상류에서 하류로 내려보내면서 각 가중치가 손실 함수에서의 기울기를 알 수 있도록 해주는 기법이다.\n이 때 수많은 노드와 복잡한 활성화 함수 등이 각 노드에서 국소적 계산을 한다.\n이런 값들이 누적되고 확산되어 단 한번의 신경망 계산(역방향)만으로도 모든 가중치와 편향을 갱신할 수 있다.\n곱셈 노드, 덧셈 노드뿐만 아니라 exp 노드, log 노드 등 수많은 노드들이 있지만,\n결국 기본 원리는 상류 노드에 해당 노드에서의 미분 값을 찾아서 곱한 뒤, 하류로 흘려보내는 것이 전부이다.\n그러므로 수치 미분보다는 당연히 빠르다.\n구현 코드\nclass MulLayer: # 곱셈 계층 def __init__(self) -\u0026gt; None: self.x = None self.y = None def forward(self, x, y): # 순전파, x와 y의 값을 저장해야만 backward때 사용할 수 있다. self.x = x self.y = y out = x * y return out def backward(self, dout): # 역전파로 상위 계층에서의 미분 값 * 반대 노드의 값을 출력한다. dx = dout * self.y dy = dout * self.x return dx, dy class AddLayer: # 덧셈 계층 def __init__(self) -\u0026gt; None: pass def forward(self, x, y): # 순전파, x와 y 값을 저장하지 않아도 된다. out = x + y return out def backward(self, dout): dx = dout * 1 dy = dout * 1 return dx, dy "},{"id":12,"href":"/posts/2023-08-16-Book-Rating-Prediction-Wrap-up-Report/","title":"Book Rating Prediction Wrap-up Report","section":"Blog","content":"\r1. 프로젝트 개요\r#\r개요\n본 프로젝트에서는 소비자들의 책 구매 결정에 도움을 주기 위해 개인화된 상품을 추천하는 문제를 해결하였습니다.\n본 프로젝트에서는 크게 세 가지 작업을 수행하였습니다.\n주어진 데이터셋을 바탕으로 데이터의 내용을 분석하고 시각화하는 과정을 통해 인사이트를 도출하였습니다. 주어진 모델 예제들을 변형하고 조합하여 다양한 모델에 대한 성능을 실험하였습니다. 앞서 명시한 작업들을 통해 최고 성능을 내는 모델을 발굴하였습니다. 본 프로젝트를 수행하면서 부스트코스 RecSys 트랙에서 학습하였던 머신러닝/딥러닝 모델을 이해하고 이를 PyTorch 구현하면서 실생활 문제에 적용하는 경험을 하였습니다.\n활용 장비 및 재료(개발 환경, 협업 tool 등)\n로컬 환경: Windows, Mac 서버: Linux (Tesla V100) 협업 툴: Slack, Notion, Github 사용 버전: Python == 3.8.5, Pandas == 2.0.0, Torch == 1.7.1 프로젝트 구조 및 사용 데이터셋의 구조\n본 프로젝트에서 활용된 데이터셋은 크게 세 가지 하위 데이터셋으로 나눌 수 있었습니다.\n📚 책과 관련된 정보를 저장한 데이터셋 (books.csv) - 149,570건의 데이터 👤 소비자와 관련된 정보를 저장한 데이터셋 (users.csv) - 68,092명의 데이터 🔢 소비자가 실제로 부여한 평점을 저장한 데이터셋 (ratings.csv) - 306,795건의 데이터 사용 데이터셋의 구조\ntrain_ratings의 rating 분포\n2. 프로젝트 팀 구성 및 역할\r#\r이름 역할 김지연_T5062 데이터 EDA (분석 및 시각화), 데이터 전처리, 하이퍼 파라미터 튜닝, 피처 엔지니어링 음이레_T5134 데이터 전처리, early stop 적용, CNN_FM, DeepCoNN에 dropout 적용, MLP activation function 선택지 추가 오승민_T5126 프로젝트 관리, 데이터 EDA 및 결측치 산입(Mice), 후처리, Bagging(Random Forest), Boosting(LGBM Regressor) 모델 튜닝, 데이터 시각화, 모델 앙상블 조재오_T5204 데이터 EDA \u0026amp; 전처리, K-Fold 구현, 데이터 분포 분석, 후처리(Post-processing) 윤한나_T5133 베이스라인 모델 실험, 데이터 전처리, 데이터 시각화, CatBoostRegressor , XGBRegressor모델 튜닝, 모델 앙상블 3. 프로젝트 수행 절차 및 방법\r#\r4. 프로젝트 수행 결과\r#\r순위 - 최종 순위 Public 7위 (RMSE: 2.1207) / Private 7위 (RMSE: 2.1159)\n탐색적 분석 및 전처리\n특수문자 및 중복 제거 location 변수의 특수 문자를 제거하고, category 변수의 대소문자를 통일하여 중복을 제거하였습니다. Label Encoding CatBoostRegressor의 경우, 수치형 데이터인 age 변수를 범주화하여 사용하였습니다. 결측치 제거 location_city가 null 값이 아닐 때, location_state와 location_country가 결측치인 경우, city를 기준으로 결측치를 채웠습니다. book_title이 null이 아닐 때, 책 제목이 같지만 language와 category가 결측치인 경우, book_title을 기준으로 결측치를 채웠습니다. Summary 불용어를 제거하고 word2vec 임베딩을 생성하였습니다. Feature Engineering 상위 카테고리 변수 추가: 5번 이상 등장한 카테고리의 경우로 이루어진 상위 카테고리 변수를 추가하였습니다. Heavy User / Light User: 책을 읽은 횟수가 5권 이상인 유저들을 Heavy User, 나머지 유저들을 Light User로 구분하는 변수를 추가하였습니다. 책 출판 횟수: 같은 책 제목의 isbn의 개수(출판 횟수) 변수를 추가하였습니다. 필드 생략 Feature importance 분석에서 city/state field가 country field에 비해 높은 중요도를 가지고 있다는 결과가 나옴에 따라, 도서 선택에 도시/주보다 국가가 더 높은 연관성을 가질 거라는 직관과 충돌하여 의문을 가졌습니다. 이후 city/state field를 누락하고 location 정보를 country만 사용한 결과 성능 향상을 얻었습니다. 모델 개요\n실험에 사용한 모델들은 다음과 같습니다.\nCARs(ML)\nFM FFM CARs(DL)\nNCF DCN WDN CNN_FM - 이미지 데이터 추가 활용 DeepCoNN - Summary 데이터 추가 활용 Bagging\nRandomForest Boosting\nLGBM XGBoost CatBoost 3. 모델 선정 및 분석\n최종 모델 선정 기준 / 앙상블 등\nFM\nContext-Aware Recommendation System 계열 ML Model\nGeneral Predictor + Latent Factor Model\nRMSE : 2.354\n성능이 가장 잘 나온 CatBoostRegressor와 예측 분포가 가장 다른 모델을 앙상블 해야 극단적인 값들이 중화되어 robust한 결과가 나올 것이라고 가정하였고, CatBoostRegressor와 가장 결과 예측 분포가 상이한 결과를 보였던 FM을 앙상블하여 RMSE 2.1299 → 2.1222로 큰 성능 향상 효과를 보였습니다.\nDeepCoNN\n텍스트 데이터 처리를 하는 딥러닝 모델로, 단일 모델의 성능은 RMSE 2.2228이었습니다. summary는 책의 내용을 나타내는 feature이기 때문에 책의 평점을 결정하는 데 유의미할 것이라고 가설을 세우고 실험하였고, 최종적으로 Deep_CoNN을 앙상블 모델에 포함하였습니다. CatBoostRegressor\n딥러닝 기반의 모델이 아닌 Decision Tree 기반의 모델로, 결측치가 존재하는 데이터에서 상대적으로 좋은 성능을 보였습니다. 주어진 데이터셋에서 age와 year_of_publication 변수를 제외한 모든 변수들이 범주형 데이터로 구성되어 있어, Boosting 기반의 회귀모델이며 범주형 데이터를 처리하는 데 강한, CatBoostRegressor를 사용하게 되었습니다. user embedding과 book embedding을 추가하고, train 데이터의 rating 분포가 imbalance하기 때문에 rating을 비율대로 나누어 train과 valid set을 분리하는 Stratified 10 K-Fold 방식을 사용하여 RMSE 2.1997 → 2.1306으로 성능 향상을 확인하였습니다. Optuna를 사용해 하이퍼 파라미터를 튜닝하여 RMSE 2.1306 → 2.1299로 성능 향상을 확인하였습니다. 앙상블 (simple-weighted ensemble사용)\nTrain의 분포와 결과 비교하며 weighted sum을 적용하였습니다.\nCatBoostRegressor, DeepCoNN, FM 모델의 결과 분포\n최종적으로, CatBoostRegressor +Deep_CoNN + FM 을 7:1:2의 비율로 가중치를 주어 앙상블함 → RMSE 2.1159(private 기준)으로 7등을 달성하였습니다.\n최종 Architecture - CatBoostRegressor + DeepCoNN + FM\n모델 평가 및 개선, 후처리\nStratified K-fold\nBaseline 및 여러 Boosting 계열 모델에 Stratified K-fold CV를 적용하여, 약간의 RMSE 개선과 모델의 일반화 성능을 향상시켰습니다.\nData Visualization\n제출 횟수가 부족한 상황에서 모델별 성능을 파악하기 위해 모델의 결과물인 Submission.csv 파일의 Rating 분포를 고려했습니다.\nRMSE가 내리는 상황에 데이터의 분포를 파악한 후, 데이터의 분포를 고려하여 개선 방향을 효과적으로 판단할 수 있었습니다.\nPost Processing\n평점 예측 결과가 1~10의 범위를 초과하는 값들을 각각 1, 10으로 조정해주어 성능을 향상시켰습니다.\n시연 결과\n프로젝트 진행 흐름에 따른 성능 추이\n5. 자체 평가 의견\r#\r배운 점 데이터셋 EDA 및 전처리를 통해 데이터를 정제하는 경험을 쌓을 수 있었습니다. 모델과 그 조합을 실험하며 성능의 증감 결과에 따른 이유를 추론하는 과정에서 부스트코스 학습 내용에 대해 더 깊이 이해할 수 있었습니다. 아쉬운 점 하루 10회의 리더보드 제출 권한을 충분히 활용하지 못한 점이 아쉬움으로 남습니다. 단일 모델에 집중하다가 Ensemble 실험을 충분히 하지 못한 점이 아쉽습니다. 시도할 점 WandB를 적극적으로 활용하여 파라미터를 조율해보고 싶습니다. Github를 통한 협업을 보다 유연하게 진행하고 싶습니다. Weighted ensemble 외 다양한 ensemble을 시도하고 싶습니다. 개인 리포트\r#\rTeam\r#\rNotion 기록을 통해 서로 수행하는 작업에 대한 공유가 잘 됐다. 발생한 문제점들을 빠르게 공유하고 처리했다. 역할 분담은 없었으나 서로 배려하는 마음으로 대회가 잘 진행됐다. 모델 구현 일정을 제대로 확정 짓지 않아 작업이 늦어져 마지막에 제출 횟수가 많이 모자랐다. Personal\r#\rProject Management — 팀원들에게 Git 활용법을 전파했다.\nEDA 및 앙상블 모델 선택 — FM\n대회 데이터셋이 정형데이터라는 점을 고려했을 때, ML계열을 앙상블에 활용해야 전체 성능이 잘 나올 것이라 짐작했다.\n이를 위해 대회를 시작하자마자 FM 모델의 성능을 개선하는 것에 집중했으며, 결과적으로 최종 제출물에도 개선한 FM모델이 포함될 수 있었다.\n활용한 모델 — FM, FFM, DeepCoNN, WDN, DCN, CNN_FM\nHyper Parameter Tuning — Batch_size, LR, Layer 개수, Dropout 등 조절\n데이터 전처리 — Mice\nBoosting 적용 — Light GBM Regressor\n결측치에 약한 LGBM 모델의 성능을 높이기 위해 MI 모듈 MICE를 접목했다.\nBagging 적용 — Random Forest Regressor\nData Visualization\n대회 마지막날 제출 횟수가 부족한 상황에서 모델별 성능을 파악하기 위해 모델의 결과물인 Submission.csv 파일의 Rating 분포를 고려했다.\nRMSE가 내리는 상황에 데이터의 분포를 파악한 후, 데이터의 분포를 고려하여 개선 방향을 효과적으로 판단할 수 있었다.\nEnsemble — 모델들의 성능과 데이터의 분포를 고려하며 sw 앙상블을 수행했다.\n한계 및 교훈\r#\r모델 성능에 대해 단편적인 정보만 활용한 것\n다양한 모델 평가 Metric을 활용해야겠다.\n배움보다는, 대회 성적에 더 집중한 것\nHyper Parameter Tuning보다는, 모델 자체에 집중하여, 코드를 수정하고 구조를 변경해보자.\nBaseline의 구조를 유지하고자 노력한 것\nBaseline의 형태를 고집할 필요는 전혀 없다.\n오히려 Baseline의 흐름을 벗어던진 후 Baseline을 완벽하게 이해할 수 있었다.\n시간 분배를 제대로 하지 못한 것\nLGBM의 성능개선을 미루다가 마지막 날의 제출 수가 부족하여 성능을 제대로 파악하지 못했다.\n일의 우선순위를 제대로 설정한 후, 우선순위에 맞게 일을 처리하자.\n다음 프로젝트에서 시도해보고 싶은 점\r#\rHybrid Model을 구현해보기. Valid Loss 뿐만 아니라 더 다양한 Metric으로 모델을 평가하기. 더 나은 방법으로 Hyper Parameter Tuning을 수행하기. Baseline에 얽매이지 않고, 바로 직접 모델 구현하기. "},{"id":13,"href":"/posts/2023-05-22-CBOW/","title":"CBOW: Continous Bag of Word","section":"Blog","content":" Word2Vec을 학습하는 방법 중 하나.\n앞뒤의 단어를 통해 중앙의 단어를 예측하는 방법\ninput — quick, brown, jumps, over output — fox 단어를 예측하기 위해 앞뒤로 몇 개의 단어(n)를 사용할지 정한다.\nMulti-Class Classification\nInput을 통해 One-Hot Vector의 각 원소가 0인지 1인지 예측한다.\n학습 파라미터\r#\r$W_{V\\times M}$: One-Hot Vector을 임베딩 벡터로 변환하는 행렬\n$V$: 단어의 총 개수(One-Hot Vector의 크기) $M$: 임베딩 벡터의 크기 $W\u0026rsquo;_{M\\times V}$: 임베딩 벡터를 One-Hot Vector의 길이로 변환하는 행렬\n학습과정\r#\rInput Layer\r#\r주변의 단어를 One-Hot Vector로 입력받는다. 입력받은 One-Hot Vector를 임베딩 벡터로 변환한다.($W_{V\\times M}$) Projection Layer\r#\r변환된 임베딩 벡터들을 평균내어 임베딩 벡터 $v$를 구한다. → Word2Vec 임베딩 벡터 $v$를 One-Hot Vector와 동일한 크기로 변환한다.($W\u0026rsquo;_{M\\times V}$)\n변환된 벡터 $z$를 Output Layer로 보낸다. Output Layer\r#\rSoftmax 함수를 통해 벡터 $z$를 확률 벡터로 변환한다.\n출력($\\hat y$)을 평가하기 위해 중앙 단어의 One-Hot Vector($y$)와 CE를 계산한다.\n"},{"id":14,"href":"/posts/2023-05-24-DeepFM/","title":"DeepFM","section":"Blog","content":"DeepFM: A Factorization-Machine based Neural Network for CTR Prediction\nWide \u0026amp; Deep 모델과 달리 두 요소(wide, deep)가 입력값을 공유하도록 한 end-to-end 방식의 논문\nBackground\r#\r추천 시스템에서는 implicit feature interaction을 학습하는 것이 중요하다.\n예시) 식사 시간에 배달앱 다운로드 수 증가 (order-2 interaction)\n10대 남성은 슈팅/RPG게임을 선호 (order-3 interaction)\n기존 모델들은 low-나 high-order interaction 중 어느 한 쪽에만 강하다.\nWide \u0026amp; Deep 모델은 이 둘을 통합하여 문제 해결\n하지만 wide component에 feature engineering(=Cross-Product Transformation)이 필요하다.\n이러한 문제를 해결하고자 DeepFM에서는 FM을 wide component로 사용하여 입력값을 공유한다.\nDeepFM = Factorization Machine + Deep Neural Network\n모델 구조\r#\rFM for low-order feature interaction\r#\r기존의 FM모델과 완전히 동일한 구조\n수식이 동일하다.\nFM 구조\n$$ \\hat{y}(\\mathrm{x})=w_0+\\sum_{i=1}^n w_i x_i{+\\sum_{i=1}^n \\sum_{j=i+1}^n\\left\\langle\\mathrm{v}_i, \\mathrm{v}_j\\right\\rangle x_i x_j} \\\nw_0 \\in \\mathbb{R}, \\quad w_i \\in \\mathbb{R}, \\quad \\mathrm{v}_i \\in \\mathbb{R}^k $$\norder-2 feature interaction을 효과적으로 잡는다.\n각 field가 하나의 feature를 의미한다.\n모두 Sparse한 feature로 구성한다.\nAddition으로 연결된 선\n1차 Term을 의미\n각각의 Feature은 동일한 차원으로 임베딩된 후, 내적을 통해 feature간 interaction을 학습한다.\nDNN for high-order feature interaction\r#\r모든 feature들은 동일한 차원(k)의 임베딩으로 치환된다.\n이 때, 임베딩에 사용되는 가중치는 FM Component의 가중치($v_{ij}$)와 동일하다.\n$$ \\begin{aligned}\u0026amp; a^0=\\left[e_1, e_2, \\ldots, e_m\\right] \\\u0026amp; a^{(l+1)}=\\sigma\\left(W^l a^l+b^l\\right) \\\u0026amp; y_{D N N}=W^{|H|+1} a^{|H|}+b^{|H|+1}\\end{aligned} $$\n각 Embedding은 모두 연결되어 가로로 붙게 된다.\n이렇게 탄생한 임베딩 벡터가 MLP Layer의 Input Layer가 된다.\n이후, L개의 Feed-Forward Network를 지나며 마지막에 클릭 여부를 Output으로 제출한다.\n전체 구조\r#\r$$ \\tt \\hat y = sigmoid(y_{FM} + y_{DNN}) $$\nFM과 Deep의 장점을 모두 가진다.\n타 모델과의 비교\r#\rFNN\r#\rFM 모델을 사용하지만, End-to-End 학습이 아니다.\nFM모델을 활용한 이후, 그 임베딩을 다시 가지고 와서 활용한다.\n즉, Pre-training이 필요하다.\nPNN\r#\rDeepFM과 흡사하지만, Low-order Interaction(Memorization부분)이 빠져있다.\n성능\r#\r"},{"id":15,"href":"/posts/2023-05-25-FFM-Field-aware-Factorization-Machine/","title":"FFM: Field-aware Factorization Machine","section":"Blog","content":"\r개요\r#\rField-aware Factorization Machines for CTR Prediction\nFM의 변형된 모델인 FFM을 제안하여 더 높은 성능을 보인 논문 FM은 예측 문제에 두루 적용 가능한 모델로, 특히 sparse 데이터로 구성된 CTR 예측에서 좋은 성능을 보인다.\nField-aware Factorization Machine (FFM)\r#\rFM을 발전시킨 모델\nPITF 모델에서 아이디어를 얻었다.\nPITF : Pairwise Interaction Tensor Factorization\r#\rMF를 3차원으로 확장시킨 모델\nPITF에서는 (user, item, tag) 3개의 필드에 대한 클릭률을 예측하기 위해\n(user, item), (item, tag), (user, tag) 각각에 대해서 서로 다른 latent factor를 정의하여 계산\n⇒ 이를 일반화하여 여러 개의 필드에 대해서 latent factor를 정의한 것이 FFM\nFFM의 특징\r#\r입력 변수를 필드(field)로 나누어, 필드별로 서로 다른 latent factor를 가지도록 factorize한다.\n기존의 FM은 하나의 변수에 대해서 k개로 factorize했으나 FFM은 f개의 필드에 대해 각각 k개로 factorize한다.\nField\n같은 의미를 갖는 변수들의 집합으로 설정\n유저: 성별, 디바이스, 운영체제\n아이템: 광고, 카테고리\n컨텍스트: 어플리케이션, 배너\n모델을 설계할 때 함께 정의\nCTR 예측에 사용되는 피쳐는 이보다 훨씬 다양하다.\n보통 피쳐의 개수만큼 필드를 정의하여 사용할 수 있다.\nFFM 공식\r#\r$$ \\begin{gathered}\\hat{y}(\\mathrm{x})=w_0+\\sum_{i=1}^n w_i x_i+\\sum_{i=1}^n \\sum_{j=i+1}^n\\left\\langle\\mathrm{v}{i, f_j}, \\mathrm{v}{j, f_i}\\right\\rangle x_i x_j \\w_0 \\in \\mathbb{R}, \\quad w_i \\in \\mathbb{R}, \\quad \\mathrm{v}_{i, f} \\in \\mathbb{R}^k\\end{gathered}\n$$\n참고 — FM Formula\r$$ \\begin{gathered}\\hat{y}(\\mathrm{x})=w_0+\\sum_{i=1}^n w_i x_i+\\sum_{i=1}^n \\sum_{j=i+1}^n\\left\\langle\\mathrm{v}_i, \\mathrm{v}_j\\right\\rangle x_i x_j \\w_0 \\in \\mathbb{R}, \\quad w_i \\in \\mathbb{R}, \\quad \\mathrm{v}_i \\in \\mathbb{R}^k\\end{gathered} $$\nFM은 k차원의 파라미터를 $v_i$와 $v_j$가 내적이 된 형태로 상호작용을 표현하는 반면,\nFFM은 $x_i$에 대응되는 파라미터가 $v_i$가 아니라, $v_{i,f_j}$가 된다.\n즉, field $(f_i)$별로 Factorization 파라미터가 정의된다.\nex) 광고 클릭 데이터가 존재하고 사용할 수 있는 feature가 총 세 개(Publisher, Advertiser, Gender)일 때,\nCliked Publisher (P) Advertiser (A) Gender (G) Yes ESPN Nike Male FM\n필드가 존재하지 않는다.\n하나의 변수에 대해 factorization 차원$(k)$ 만큼의 파라미터를 학습한다.\n$$ \\hat{y}(\\mathrm{x}) =w_0+w_{\\mathrm{ESPN}}+w_{\\mathrm{Nike}}+w_{\\text {Male }}+{\\mathrm{v}{\\mathrm{ESPN}} \\cdot \\mathrm{v}{\\mathrm{Nike}}\\ +\\mathrm{v}{\\mathrm{ESPN}} \\cdot \\mathrm{v}{\\text {Male }}+\\mathrm{v}{\\mathrm{Nike}} \\cdot \\mathrm{v}{\\text {Male }}} $$\nFFM\n각각의 feature를 필드 P,A,G로 정의\n하나의 변수에 대해 필드 개수$(f)$와 factorization 차원$(k)$의 곱 $(=fk)$만큼의 파라미터를 학습한다.\n$$ \\hat{y}(\\mathrm{x}) =w_0+w_{\\mathrm{ESPN}}+w_{\\mathrm{Nike}}+w_{\\text {Male }}+{\\mathrm{v}{\\mathrm{ESPN}, \\mathrm{A}} \\cdot \\mathrm{v}{\\mathrm{Nike}, \\mathrm{P}}\\\n+\\mathrm{v}{\\mathrm{ESPN}, \\mathrm{G}} \\cdot \\mathrm{v}{\\text {Male,P }}+\\mathrm{v}{\\mathrm{Nike}, \\mathrm{G}} \\cdot \\mathrm{v}{\\mathrm{Male}, \\mathrm{A}}} $$\nFFM의 필드 구성\r#\rCategorical Feature\r#\rFM\nFFM\nNumerical Feature\r#\r실수도 반드시 특정 필드에 속해야 한다.\ndummy field\nnumeric feature 한 개당 하나의 필드에 할당하고 실수 값을 사용\nfield가 크게 의미를 갖지 않는다.\ndiscretize\nnumeric feature를 n개의 구간으로 나누어 이진 값을 사용하고, n개의 변수를 하나의 필드에 할당한다.\nFM / FFM 성능 비교\r#\rLR에 비해 FM, FFM의 성능이 더 낫다.\n필드를 사용하는 것이 적절하지 않은 데이터셋의 경우 FFM보다 FM이 성능이 더 잘나온다.\n"},{"id":16,"href":"/posts/2023-05-21-FM-Factorization-Machine/","title":"FM: Factorization Machine","section":"Blog","content":" General Predictor에 Latent Factor Model을 추가한 모델.\nBackground\r#\rFactorization Machines\nSVM과 Factorization Model의 장점을 결합한 FM을 처음 소개한 논문\n등장 배경\n딥러닝이 등장하기 이전 SVM이 가장 많이 사용됐다.\n매우 희소한 데이터가 많은 CF 환경에서는 SVM보다 MF 계열의 모델이 더 높은 성능을 내왔다.\nSVM과 MF의 장점을 결합할 수 없을까? ⇒ FM 탄생.\nMF 기반 모델의 한계 ⇒ User-Item 행렬 기반\n즉, 특정 데이터 포맷에 특화되어 있다.\n$X:$ (유저, 아이템) → $Y:$ (rating)으로 이루어진 데이터에 대해서만 적용이 가능하다.\n일반적인 데이터셋에 바로 적용 불가능 User-Item 행렬 외의 정보를 활용하기 어렵다. User-Item 행렬을 범용적인 형태로 변경했을 때의 문제점\nML 모델에 사용되는 데이터 형태를 만들면 high sparsity 문제가 발생한다. 원활한 파라미터 학습이 어렵다. Feature간 상호작용을 반영하기 어렵다. FM 공식\r#\r$$ \\hat{y}(\\mathrm{x})=w_0+\\sum_{i=1}^n w_i x_i\\blue{+\\sum_{i=1}^n \\sum_{j=i+1}^n\\left\\langle\\mathrm{v}_i, \\mathrm{v}_j\\right\\rangle x_i x_j} \\\nw_0 \\in \\mathbb{R}, \\quad w_i \\in \\mathbb{R}, \\quad \\mathrm{v}_i \\in \\mathbb{R}^k $$\n$\\langle \\cdot,\\cdot \\rangle:$ 두 벡터의 스칼라곱(dot product)\n$$ \\left\\langle\\mathrm{v}i, \\mathrm{v}j\\right\\rangle:=\\sum{f=1}^k \\mathrm{v}{i, f} \\cdot \\mathrm{v}_{j, f} $$\nLogistic Regression에 두 Feature의 상호작용을 나타내는 Term이 추가된 형태\nLogistic Regression\n$$ \\hat{y}(\\mathrm{x})=w_0+\\sum_{i=1}^n w_i x_i\\\nw_0 \\in \\mathbb{R}, \\quad w_i \\in \\mathbb{R} $$\nPolynomial Model과 상호작용을 모델링하는 Term이 다르다.\nPolynomial Regression\n$$ \\hat y(x)=\\left(w_0+\\sum_{i=1}^n w_i x_i{+\\sum_{i=1}^n \\sum_{j=i+1}^n w_{i j} x_i x_j}\\right), \\quad w_i, w_{i j} \\in \\mathbb{R} $$\n$x_ix_j$의 상호작용을 하나의 파라미터$(w_{ij})$로 나타낸 Polynomial에 비해, $\\left\\langle\\mathrm{v}_i, \\mathrm{v}_j\\right\\rangle$의 k차원의 Factorization 파라미터로 나타내 더욱 일반화시켰다.\nFM의 활용\r#\rSparse한 데이터셋에서 예측하기\n유저의 영화에 대한 평점 데이터는 대표적인 High Sparsity 데이터\n유저 - 아이템 매트릭스에서 다루던 Sparse Matrix와는 다른 의미\n평점 데이터 = { (유저1, 영화2, 5), (유저3, 영화1, 4), (유저2, 영화3, 1), … }\n일반적인 CF 문제의 입력 데이터와 같음\n위의 평점 데이터를 일반적인 입력 데이터로 바꾸면, 입력 값의 차원이 전체 유저와 아이템 수만큼 증가\nex) 유저 수가 $U$명, 영화의 수가 $M$개일 때\nSparse한 Feature들의 상호작용이 학습되는 방법\n유저 A의 ST에 대한 평점 예측 → $V_A, V_{ST}$가 FM 모델을 통해 학습되기 때문에 상호작용이 반영된다.\n$V_{ST}$ — 유저 B,C의 영화 ST에 대한 평점 데이터를 통해 학습된다.\n유저 B,C는 영화 ST 외에 다른 영화도 평가한다.\n$V_A$ — 유저 B,C가 유저 A와 공유하는 영화 SW의 평점 데이터를 통해 학습한다.\nFM의 장점\nvs. SVM\n매우 sparse한 데이터에 대해서 높은 예측 성능을 보인다.\n선형 복잡도$(O(kn))$를 가지므로 수십 억 개의 학습 데이터에 대해서도 빠르게 학습한다.\n모델의 학습에 필요한 파라미터의 개수도 선형적으로 비례한다.\nvs. Matrix Factorization\n여러 예측 문제(회귀/분류/랭킹)에 모두 활용 가능한 범용적인 지도 학습 모델\n일반적인 실수 변수(real-value feature)를 모델의 입력(input)으로 사용한다.\nMF와 비교했을 때 유저, 아이템 ID 외에 다른 부가 정보들을 모델의 피쳐로 사용할 수 있다.\nFM의 시간 복잡도\r#\r$$ \\begin{aligned}\u0026amp; \\tt\\sum_{i=1}^n \\sum_{j=i+1}^n\\left\\langle\\mathbf{v}i, \\mathbf{v}j\\right\\rangle x_i x_j \\quad\\quad \\quad\\quad\\quad\\quad\\quad\\quad{\\Longrightarrow O(kn^2)} \\= \u0026amp; \\frac{1}{2} \\sum{i=1}^n \\sum{j=1}^n\\left\\langle\\mathbf{v}i, \\mathbf{v}j\\right\\rangle x_i x_j-\\frac{1}{2} \\sum{i=1}^n\\left\\langle\\mathbf{v}i, \\mathbf{v}i\\right\\rangle x_i x_i \\= \u0026amp; \\tt\\frac{1}{2}\\left(\\sum{i=1}^n \\sum{j=1}^n \\sum{f=1}^k v_{i, f} v_{j, f} x_i x_j-\\sum_{i=1}^n \\sum_{f=1}^k v_{i, f} v_{i, f} x_i x_i\\right) \\= \u0026amp; \\tt\\frac{1}{2} \\sum_{f=1}^k\\left(\\left(\\sum_{i=1}^n v_{i, f} x_i\\right)\\left(\\sum_{j=1}^n v_{j, f} x_j\\right)-\\sum_{i=1}^n v_{i, f}^2 x_i^2\\right) \\= \u0026amp; \\tt\\frac{1}{2} \\sum_{f=1}^k\\left(\\left(\\sum_{i=1}^n v_{i, f} x_i\\right)^2-\\sum_{i=1}^n v_{i, f}^2 x_i^2\\right)\\quad\\quad{\\Longrightarrow O(kn)}\\end{aligned} $$\n어떻게 수식을 정리하여 시간복잡도를 줄일 수 있었나?\n2중 반복문을 (1중 반복문)^2의 형태로 치환하여 계산을 줄였다.\n"},{"id":17,"href":"/posts/2023-06-02-Git-Branch/","title":"Git Branch는 무엇이고, 무엇을 위해 사용하는가?","section":"Blog","content":"독립적으로 특정 작업을 진행할 때 사용한다.\n팀으로 여러작업을 동시에 작업할 수 있다.\n여러 Branch를 합치는 방법 — Merge\nmerge\r#\rbranch의 모든 기록 보존, merge에 대한 기록 추가.\n이 방법을 사용하면 merge에 대한 commit이 하나 생성되고 어느 시점에 merge를 진행했는지 쉽게 알 수 있다. branch가 늘어나고 여러 번의 merge가 생기게 되면, 그래프가 복잡해져 **커밋 히스토리(Commit History)**를 파악하기 더욱 어려워질 수 있다. squash and merge\r#\r여러 commit 기록 하나로 합치기, merge기록 남기지 않기.\n지저분한 커밋 이력들을 삭제하면서 master branch로 합칠 때 사용한다.\nmerge할 때 여러 commit들을 하나로 합친다. Squash를 하게 되면 모든 커밋 이력이 하나의 커밋으로 합쳐지며 사라진다. merge에 대한 이력은 남기지 않는다. rebase and merge\r#\r여러 commit 기록 남기기, merge 기록 남기지 않기.\n기존의 커밋 이력을 유지하면서도, 깔끔하게 하나의 흐름으로 관리하고자 할 때 사용한다.\n일반적으로 가장 많이 사용된다.\nmerge에 대한 이력이 남지 않는다.\n즉, 언제 merge가 됐는지 알 수 없다.\n만약 merge 시점에 대한 기록이 필요하다면 커밋으로 직접 명시해주면 된다.\n모든 커밋이력들이 rebase 되어서 추가된다. 즉, fast-forward 된다.\nRebase를 하면 커밋들의 Base가 변경되므로 Commit Hash 또한 변경 될 수 있다.\n이로 인해 Force Push가 필요한 경우가 발생한다.\n내가 branch를 분기한 이후, 기존의 branch가 수정된 경우 내 branch에 기존 branch를 pull해서 conflict 해결하기.\n내가 작성한 커밋을 절대 변경하고 싶지 않은 경우\n내가 작성한 커밋 기록은 유지한채, Merge라는 기능을 통해 합쳐졌다라는 기록을 같이 남기게 된다. merge할 때 rebase and merge하기. ← 더 나은 방법. Conflict가 발생한다면?\r#\r마지막으로 push 하는 사람이 해결해야 한다.\n마지막에 push하는 사람은 conflict 에러가 발생한다.\ngit status로 충돌 위치 확인하기\nA와 B가 협의 후 수정하기\nCVN의 해결방법과 유사하다.\n원격 브랜치 가져오기\r#\rgit remote update 원격 저장소 갱신\n가끔 갱신을 하지 않으면 push하고자 하는 원격 branch를 찾을 수 없다는 오류를 보게된다.\n해당 오류를 처음 만나면 분명 branch있는데 왜 없어! 하게 된다.\ngit branch -r 원격 저장소 branch 리스트 확인\ngit branch -d dev 로컬 저장소 branch 제거하기\ngit checkout -t origin/dev 원격 저장소 branch 가져오기\n-t: 원격 저장소의 branch 이름과 동일한 로컬 branch를 생성\n-f: 문제가 발생하더라도 강제로 진행한다.\nbranch 합치기, 병합하기\r#\rgit checkout -b issue1 branch 생성하고 변경하기\n위 명령어는 아래의 두 가지 명령어를 한 번에 수행한 것이다. git branch issue1 main main branch로부터 issue1 branch 생성하기 git checkout issue1 main branch에서 issue1 branch로 변경하기 — 코드 추가 작업 수행 —\ngit checkout master (작업이 완료되고 난 후) master 브랜치로 이동하기\ngit merge issue1 issue1을 master에 merge (병합)하기\nBranch 전략 — Flows\r#\r가장 최신 커밋이 어디에 존재하느냐에 따라 두 가지 방법으로 나뉜다.\nLocal 중심 — Git Flow Remote 중심 — Github Flow "},{"id":18,"href":"/posts/2023-06-24-KPT-%EC%9D%BC%EC%9D%BC%ED%9A%8C%EA%B3%A0%EB%A1%9D-230326/","title":"KPT20230326","section":"Blog","content":"부스트캠퍼들의 학습정리 기록들을 읽었다.\n덕분에 많은 동기부여가 되어, 나도 회고를 하고자 마음먹었다.\n늦었지만, 지금 당장 시작해야지.\nTIL (Today I Learn)\r#\r노션에 특정 시간에 자동으로 페이지 생성 기능이 있다는 것을 깨달았다. Keep\r#\r회고록을 쓰기 시작한 것! 엉망진창이던 여러 폴더 자료 정리를 한 것. 부스트캠프 시작하고 처음으로…계획을 세운 것!(이런 내가…MBTI J..?) 야식을 참은 것. 배가 고프지만 살이 잘 빠지고 있다. Problem\r#\r내일은…반드시 일찍 자도록 하자. Try\r#\r미리미리 하루를 부지런하게 살고, 하루의 목표치는 적당한 양으로 잡자. "},{"id":19,"href":"/posts/2023-06-24-KPT-%EC%9D%BC%EC%9D%BC%ED%9A%8C%EA%B3%A0%EB%A1%9D-230327/","title":"KPT20230327","section":"Blog","content":"\rTIL (Today I Learn)\r#\rStacking이 무엇이고, 어떤 상황에 사용하는지 추천 시스템이 무엇인지와, 추천시스템을 통해 해결하고자 하는 문제의 본질(The Long tail 현상) 추천시스템의 목적 추천시스템의 평가 지표 AP, MAP CG, DCG, IDCG, NDCG 스코어 생성 방법 UMAP 활용 방법 Keep\r#\r강의를 통해 추천 시스템의 전반적인 틀을 알게 되었다. 여러 추천 시스템 예시들을 접하다보니, 과거에 내가 수행했었던 프로젝트가 결국 추천시스템이라는 것을 깨달았다. 연구실 과제를 수행하며 차원 축소를 진행해야 했는데, 일전에 1분 말하기때 차원축소에 대해 정리했던 것이 도움이 됐다. Problem\r#\r전날 잠을 적게 자서 낮잠을 2시간정도 자버렸다. 낮잠을 잔 후, 이리저리 일정이 있어서 실질적인 공부량이 너무 부족했다. 차원 축소를 진행할 때, Metric을 설정해주어야 했는데, 다양한 Metric을 배웠음에도 불구하고 어떤 Metric을 접목해야 해당 데이터를 가장 잘 나타낼지 파악하기가 어려웠다. Try\r#\r낮잠을 자는 것 까진 괜찮다고 생각하지만, 30분 이상의 낮잠을 자야하는 상황은 피하도록 하자. Metric별 어떤 상황에 쓰이는지를 알아둘 필요가 있다. "},{"id":20,"href":"/posts/2023-06-24-KPT-%EC%9D%BC%EC%9D%BC%ED%9A%8C%EA%B3%A0%EB%A1%9D-230328/","title":"KPT20230328","section":"Blog","content":"\rTIL (Today I Learn)\r#\rgit-flow 설명하기 TF-IDF UMAP 활용 HDBSCAN 활용 Data Clustering 시각화 Pandas 활용 value_count 활용 Dataframe filter 활용 groupby, get_group 활용 Keep\r#\r연구실 과제를 진행하며 차원 축소 알고리즘 UMAP과, 클러스터링 기법인 HDBSCAN을 활용해보았다. 직접 써보니 확실히 기억에 오래 남을 것 같다. Visualization도 직접 활용해보고, Problem\r#\rgit 강의는 듣지 않았다.\n솔직히 강의 진행이 많이 느리다고 느낀다.\n이미 알고 있는 내용이라, 강의를 안듣고 싶지만… 마음 편히 무시하지는 못해서, 시간이나 집중력이 허비되는 느낌이다.\n그래도 많이 중요한 내용이니, 복습했다고 생각하자.\n지금이 새벽 2시이다. 피곤하고…지친다.\nTry\r#\r어서 숙면을 취하자. "},{"id":21,"href":"/posts/2023-06-24-KPT-%EC%9D%BC%EC%9D%BC%ED%9A%8C%EA%B3%A0%EB%A1%9D-230401/","title":"KPT20230401","section":"Blog","content":"주말이지만, 밀린 진도와 공부를 따라잡는 시간으로 열심히 보냈다.\nTIL (Today I Learn)\r#\rMF, SVD를 완벽하게 이해했다.\nWord2Vec 생성 방법을 완전히 이해했다.\nCBOW — 중간 단어 예측\nSG — CBOW 뒤집은 버전\nSGNS — SG를 이진 분류로 바꾼 것.\nMBCF\nNCF\nAE\nDAE\nKeep\r#\r집중을 잘 한 것\n4시 전까지는 만족스럽게 집중하는 시간을 가졌다.\n그 이후는 체력 때문에 집중도가 떨어졌다.\n4시 이후는 집중이 떨어질 수 있다는 것을 감안하고 체력관리를 해야겠다.\nProblem\r#\r늘 그랬듯이, 잠을 늦게 자는 것.\n저녁 8시쯤에 잠이 와서 엄청 불편한 자세로 한시간 반정도 잠들어버렸다. 차라리 집약적으로 공부한 후 일찍 자거나, 아니면 편하게 짧게 자는 게 더 나았을 텐데…\n연락을 못받은 것\n알고보니 전화가 음소거 상태였다.\nTry\r#\r잠을 더 자자. "},{"id":22,"href":"/posts/2023-06-24-KPT-%EC%9D%BC%EC%9D%BC%ED%9A%8C%EA%B3%A0%EB%A1%9D-230623/","title":"KPT20230623","section":"Blog","content":"\rTIL (Today I Learn)\r#\rTIL 작성하는 방법\n이때까지 매일 배우는 것이 없어서, 어떻게 TIL을 작성할 지에 대해 고민했었다.\n꾸준한 사람에게는 변명처럼 들릴 수 있겠지만, 나는 TIL을 매일 적는 것이 어려웠다.\n파악한 가장 핵심적인 이유는, 매일 학습량이 일정하지 않다는 것이다.\n학습량이 적은 날은 작성할 내용이 없고, 따라서 TIL을 작성하는 것이 오히려 죄책감을 불러일으키거나, 내용 없는 글을 작성하고 있다는 기분이 들었다.\n그러다보면, 자연스레 TIL을 쓰지 않게 된다.\n앞으로는 목표 학습량을 채우지 못하면, Digital Garden의 키워드를 복습하고 TIL에 채워넣기로 했다.\n위상 정렬 알고리즘\n위상 정렬의 시간복잡도가 O(V + K)라는 것.\n위상 정렬을 큐로 구현하는 방법\n커리어 프레임워크\nKeep\r#\rTIL을 꾸준히 작성할 것. 목표하는 바를 어떻게 달성할 지 고민한 것 부족한 점을 고민한 것. 운동을 한 것 Problem\r#\r지금(오전 2:02)까지 잠을 자지 않은 것. 백준 문제를 풀지 않은 것. 깃허브에 잔디를 심지 못한 것. 구글 쿠버네티스 강의를 지금까지 미뤄서 결국 매우 급하게 해결해야 하는 상태가 된 것. Try\r#\r오늘보다 일찍 자기.(내일은 1시 반 전에 자자) "},{"id":23,"href":"/posts/2023-06-25-KPT-%EC%9D%BC%EC%9D%BC%ED%9A%8C%EA%B3%A0%EB%A1%9D-230624/","title":"KPT20230624","section":"Blog","content":"\rTIL (Today I Learn)\r#\r하루종일 쿠버네티스 과제하다가, 유튜브 한 편 봤더니 아이러니하게도 더 많은 것을 배웠다.\n기록하는 방법\n극단적으로 요약하기\n키워드 중심으로 메모하기\n내 것으로 소화한 후 메모하기\n내 머릿속에 각인된 것들을 중심으로 메모하기.\n하루 일기쓰는 방법\n하루 1~2시간마다 한 줄정도씩 메모하기\n플래너 작성하기\n오전 2개, 오후 1개, 저녁 2개 목표로 잡기.\n시간 단위로 나누게 되면 안하고 자책하게 된다.\n업무 역량 올리기\n일을 시작하기 5분 전, 무엇에 집중해야 하는지 생각하기.\n1,2,3단계 나누어서 결과를 엮기.\n이것을 내가 왜 하는지, 왜 하고 싶은지 생각해보기.\n내 것으로 이해하고, 각인하고, 주관적으로 행동하기.\nKeep\r#\r얻은 정보에 대해 메모한 것. Problem\r#\r부정적인 요소로 작용했거나 아쉬웠던 점\n공부하기 싫어서 빈둥댄 것.\n어차피 해야하는 공부였음에도, 하기 싫어 빈둥대며 놀지도 않고, 공부하지도 않는 시간이 많았다.\nTry\r#\rProblem에 대한 해결 방식으로 다음에 시도해볼 점\n공부하기 싫을 땐, 목표한 공부를 하나도 안한 채 밤 12시가 되는 상상을 하자. 공부하기 싫을 때 산책 겸 달리기를 하자. 숙면이 충분했는지를 생각해보자. 지나고 생각해보니, 잠이 부족해서 집중력이 떨어졌던 것 같다. "},{"id":24,"href":"/posts/2023-06-28-KPT-%EC%9D%BC%EC%9D%BC%ED%9A%8C%EA%B3%A0%EB%A1%9D-20230628/","title":"KPT20230628","section":"Blog","content":"\rTIL (Today I Learn)\r#\rCF의 단점\nCF의 단점은 모두 Input이 유저-아이템 상호작용 형태에 국한된다는 점에서 비롯된다.\nCBF와 CF는 서로 상호 보완적인 성격을 가지며, CBF를 단독으로 잘 사용하지 않는다.\n마지막 몰입 책을 다시 읽으며, 어떠한 정보를 암기하기 위해서는 해당 정보가 나중에 어떤 상황에서 다시 사용될 것이라는 생각을 가져야 한다는 것을 깨달았다.\n이외의 CDL, Group Aware 추천, SDAE, FME, FPMC, PRME에 대한 개념을 학습했다.\n강의자료를 정독하며 노션에 개념을 정리했지만, 머릿속에 기억되지는 않았다.\n위의 개념들이 어디에 쓰일지를 고민해보아야 머릿속에 남길 수 있을 것 같다.\nKeep\r#\r만족했고, 앞으로 지속하고 싶은 부분 4시간, 5시간정도 몰입하여 공부한 것. 가끔씩 장소를 바꿔주면 집중이 잘 될 것 같다. Problem\r#\r부정적인 요소로 작용했거나 아쉬웠던 점\n나름 노트 정리를 했지만, 머릿속에 남지 않았다.\n새롭게 들어온 개념들이 너무 많기도 했고, 사실 언제 어떻게 쓰이는지에 대한 감이 잡히지 않았다.\nTry\r#\rProblem에 대한 해결 방식으로 다음에 시도해볼 점 CDL, SDAE, FPMC, PRME, FME가 어디 쓰이는지 알아보기. "},{"id":25,"href":"/posts/2023-06-30-KPT-%EC%9D%BC%EC%9D%BC%ED%9A%8C%EA%B3%A0%EB%A1%9D-20230629/","title":"KPT20230629","section":"Blog","content":"\rTIL (Today I Learn)\r#\rAutoregression\nRegression을 자기 자신에게 적용하는 것\n회귀 분석의 관점에서 과거의 데이터를 보고 현재 또는 미래의 결과를 예측하는 모델\n이전부터 Autoregression에 대한 개념 설명을 몇 번 들었으나, 직관적으로 와닿지 않았는데, 이번에 학습하며 이해됐다.\n경사하강법 기반 선형회귀 알고리즘\nInput: X, y, lr, T, Output: beta ——————————————————————————————————————————— # norm: L2-노름을 계산하는 함수 # lr: 학습률, T: 학습횟수 for t in range(T): error = y - X @ beta grad = - transpose(X) @ error beta = beta - lr * grad 오랜만에 AI Math의 내용을 복습했더니 또 매우 새롭다.\n덕분에 내가 많은 것을 잊었다는 사실을 알게 되었다.\n파이썬에서의 @ — 행렬곱 연산자\n이전에 정리한 내용을 복습하는데, @가 뭐지??하고 당황했다.\n생김새를 보아하니 데코레이터는 아닌 듯 보였다.\n찾아보니 @는 행렬곱을 계산하는 연산자이다.\n즉, numpy에서의 matmul과 같은 역할을 한다.\nasterisk로 표현되는 element-wise 곱 연산이 아닌 행렬-행렬간 곱을 계산할때 사용한다.\nKeep\r#\r만족했고, 앞으로 지속하고 싶은 부분\n일전에 말했던 대로, 오늘 추가로 학습한 내용이 없어 Digital Garden의 강의노트를 복습했다.\n복습했더니, 기록할 것이 생겼다.\n이 방법 괜찮은 것 같다.\nProblem\r#\r부정적인 요소로 작용했거나 아쉬웠던 점 페이지 상단에 요약을 작성하고자 마음먹었었는데, 또 잊어버리고 게시했다. Try\r#\rProblem에 대한 해결 방식으로 다음에 시도해볼 점 다음 게시글을 올릴 때 함께 수정해서 업로드하자. "},{"id":26,"href":"/posts/2023-11-28-LSTM/","title":"LSTM: Long Short Term Memory","section":"Blog","content":"RNN의 장기문맥 의존성을 해결하기 위해 탄생한 모델\n선별적 게이트라는 개념으로 선별 기억 능력을 확보한다.\n그림은 이해를 돕기위해 O,X로 표현했지만, 실제로는 게이트는 0~1 사이의 실수값으로 열린 정도를 조절한다.\n게이트의 여닫는 정도는 가중치로 표현되며 가중치는 학습으로 알아낸다.\n가중치\n순환 신경망의 ${U, V, W}$에 4개를 추가하여 ${U, U_i , U_o , W, W_i , W_o , V}$\n$i$ : 입력 게이트\n$o$ : 출력 게이트\n다양한 구조 설계가 가능하다.\nModel Concept\r#\rCell State\r#\rLSTM의 핵심\n모듈 그림에서 수평으로 그어진 윗 선에 해당\n일종의 컨베이어 벨트\n작은 linear interaction만을 적용시키면서 데이터의 흐름은 그대로 유지한다.\n아무런 동작을 추가하지 않는다면, 정보는 전혀 바뀌지 않고 그대로 흐른다.\nCell State에서 gate에 의해 정보가 추가되거나 삭제된다.\nGate\r#\rForget Gate\nInput Gate\nCell State 업데이트\nOutput Gate\n수식 요약\r#\r$$ \\begin{aligned}f_t \u0026amp; =\\sigma_g\\left(W_f x_t+U_f h_{t-1}+b_f\\right) \\i_t \u0026amp; =\\sigma_g\\left(W_i x_t+U_i h_{t-1}+b_i\\right) \\o_t \u0026amp; =\\sigma_g\\left(W_o x_t+U_o h_{t-1}+b_o\\right) \\\\tilde{c}t \u0026amp; =\\sigma_c\\left(W_c x_t+U_c h{t-1}+b_c\\right) \\c_t \u0026amp; =f_t \\odot c_{t-1}+i_t \\odot \\tilde{c}_t \\h_t \u0026amp; =o_t \\odot \\sigma_h\\left(c_t\\right)\\end{aligned} $$\nft = sigmoid(np.dot(xt, Wf) + np.dot(ht_1, Uf) + bf) # forget gate it = sigmoid(np.dot(xt, Wi) + np.dot(ht_1, Ui) + bi) # input gate ot = sigmoid(np.dot(xt, Wo) + np.dot(ht_1, Uo) + bo) # output gate Ct = ft * Ct_1 + it * np.tanh(np.dot(xt, Wc) + np.dot(ht_1, Uc) + bc) ht = ot * np.tanh(Ct) 모델 요약\r#\rInput / Output Shape\r#\rimport torch import torch.nn as nn # Size: [batch_size, seq_len, input_size/num_of_features] input = torch.randn(3, 5, 4) lstm = nn.LSTM(input_size=4, hidden_size=2, batch_first=True) output, h = lstm(input) output.size() # =\u0026gt; torch.Size([3, 5, 2]), batch_size, seq_len, hidden_size LSTM을 활용하여 주식 가격을 예측 — 과거 5일의 종가를 예측하는 경우 Seq_len = 5 Input_size = 1(종가) Batch_size = N LSTM을 활용하여 주식 가격을 예측 — 과거 5일의 시가, 종가, 거래량을 예측하는 경우 Seq_len = 5 Input_size = 3(시가, 종가, 거래량) Batch_size = N LSTM을 활용하여 주식 가격을 예측 — 여러 연속형 변수와 범주형 변수가 포함된 경우 Seq_len = 5 Input_size = embedding size(시가, 종가, 거래량) Batch_size = N Model\r#\r기본으로 제공되는 Feature들을 병합하여 LSTM에 주입한다.\ndef forward(self, input): test, question, tag, _, mask, interaction, _ = input batch_size = interaction.size(0) #Embedding embed_interaction = self.embedding_interaction(interaction) embed_test = self.embedding_test(test) embed_question = self.embedding_question(question) embed_tag = self.embedding_tag(tag) embed = torch.cat([embed_interaction, embed_test, embed_question, embed_tag,], 2) X = self.conb_proj(embed) hidden = self.init_hidden(batch_size) out, hidden = self.lstm(X, hidden) out = out.contiguous().view(batch_size, -1, self.hidden_dim) out = self.fc(out) preds = self.activation(out).view(batch_size, -1) return preds LSTM + Attention\r#\r기존의 LSTM 모델에 Attention Layer을 추가한다.\ndef forward(self, input): test, question, tag, _, mask, interaction, _ = input batch_size = interaction.size(0) #Embedding embed_interaction = self.embedding_interaction(interaction) embed_test = self.embedding_test(test) embed_question = self.embedding_question(question) embed_tag = self.embedding_tag(tag) embed = torch.cat([embed_interaction, embed_test, embed_question, embed_tag,], 2) X = self.conb_proj(embed) hidden = self.init_hidden(batch_size) out, hidden = self.lstm(X, hidden) out = out.contiguous().view(batch_size, -1, self.hidden_dim) **extended_attention_mask = mask.unsqueeze(1).unsqueeze(2) extended_attention_mask = extended_attention_mask.to(dtype=torch.float32) extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0 head_mask = [None] * self.n_layers encoded_layers = self.attn(out, extended_attention_mask, head_mask=head_mask) sequence_output = encoded_layer[-1]** out = self.fc(sequence_output) preds = self.activation(out).view(batch_size, -1) return preds BERT\r#\rdef forward(self, input): test, question, tag, _, mask, interaction, _ = input batch_size = interaction.size(0) #Embedding embed_interaction = self.embedding_interaction(interaction) embed_test = self.embedding_test(test) embed_question = self.embedding_question(question) embed_tag = self.embedding_tag(tag) embed = torch.cat([embed_interaction, embed_test, embed_question, embed_tag,], 2) X = self.conb_proj(embed) **# Bert encoded_layers = self.encoder(inputs_embeds=X, attention_mask=mask) out=encoded_layers[0]** out = out.contiguous().view(batch_size, -1, self.hidden_dim) **** out = self.fc(sequence_output) preds = self.activation(out).view(batch_size, -1) return preds 참고 자료\nLong Short-Term Memory (LSTM) 이해하기\n"},{"id":27,"href":"/posts/2023-06-21-MICE/","title":"MICE : Multiple Imputation Chained Equation","section":"Blog","content":"Multiple Imputation Chained Equation(다중 산입 연립 방정식)\nMICE 접근 방식에는 MI에서 언급된 동일한 개념이 적용된다.\n값들은 각 방식에 따라 산입된 후 완전한 데이터셋에 대한 분석이 진행되고 결과가 합쳐진다. 다만 차이점으로, MI에서는 모든 변수에 대해 동시에 산입되지만, MICE에서는 각 변수의 값이 순차적으로 산입된다.\nProcess\r#\r누락된 데이터의 양이 가장 적은 변수가 가장 먼저 산입된다.\n가장 첫 변수는 mean replacement(평균 대체) 방법으로 채워진다.\n이후, 채워진 변수는 다른 변수를 채울 때 함께 예측 변수로 사용된다.\n회귀로 결측값이 모두 채워진 그럴싸한 분포의 매개변수는 결측값을 재추정하는 데 사용된다.\n이후 여러 사이클 동안 연립 방정식을 반복한다.\n사이클이 완료되면 데이터가 \u0026ldquo;완전한\u0026rdquo; 데이터셋으로 저장된다.\n각 변수는 개별적으로 산입되기 때문에, 각 변수 유형에 적합한 모델들이 사용된다.\nBinary Variable → Logistic regression Model Categorical Variable → Multinomial Logit Model Ordered categorical Variable → Ordered Logit Model R 패키지에 MICE가 포함되어 있다.\nMICE algorithm에는 FCS(Fully Conditional Specification)을 구현했다.\nMICE에 내장된 Imputation 방법\nPmm (any): Predictive mean matching Sample (any): Random sample from observed values Mean (numeric): Unconditional mean imputation norm.nob (numeric): Linear regression ignoring model error Logreg (binary): Logistic regression Polr (ordered): Proportional odds model Polyreg (unordered): Polytomous logistic regression methods(mice)를 사용하면 imputation 할 수 있는 방법론을 쭉 알려준다.\n하지만, 가독성이 좋지 않기 때문에 추천하진 않는다.\n이보단 그냥 ?mice로 검색하여 확인하면 더 자세하게 잘 적혀있다.\nmd.pattern()\r#\r행렬이나 데이터프레임의 형태로 결측데이터의 유형들을 표로 나타낸다.\nmd.pattern(x, plot = TRUE, rotate.names = FALSE)\n표 보는 방법\n가장 왼쪽 열의 숫자: 해당 pattern으로 구성된 데이터의 개수\n첫 번째 행을 보면, 결측치가 없는 데이터가 4133개라는 것을 알 수 있다.\n두 번째 행을 보면, R.DExpemses만 결측치가 발생한 데이터가 11개라는 것을 알 수 있다.\n가장 오른쪽 열의 숫자: 결측치가 발생한 변수(column)의 개수\n최하단의 숫자: 각 변수에서 결측값의 총 개수\nmd.pairs()\r#\r출력 값에는 rr, rm, mr, mm 네 가지 구성 요소가 존재한다.\nm은 Missing됨을 의미하고, r은 response, 존재함을 의미한다.\n"},{"id":28,"href":"/posts/2023-03-29-NBCF-Neighborhood-based-CF/","title":"NBCF: Neighborhood-based CF(이웃 기반 협업 필터링)","section":"Blog","content":"Neighborhood-based CF 혹은 Memory Based CF라고 부르기도 한다.\n사용자 또는 아이템 간의 similarity 값을 계산하고 이를 rating prediction 또는 top-K ranking에 활용하는 방법\nSimilarity를 계산하기 위한 Metric으로 Jaccard, Cosine, Pearson 등을 활용한다.\n장점\n구현이 간단하고 이해하기 쉽다. Similarity를 활용하기 때문에 추천의 이유에 대한 직관적인 설명을 제공한다. 최적화나 훈련 과정이 필요 없다. 단점\nSparsity(희소성) 문제\nNBCF를 적용하려면 적어도 sparsity ratio가 99.5%를 넘지 않는 것이 좋다.\n데이터가 충분하지 않다면 유사도 계산이 부정확해진다. ⇒ 성능 저하\nCold Start\n데이터가 부족하거나 혹은 아예 없는 유저, 아이템의 경우 추천이 불가능하다.\nScalability(확장성) 문제\n유저와 아이템이 늘어날수록 유사도 계산이 늘어난다.\n추론을 위한 많은 양의 Offline 계산이 요구된다.\n유저, 아이템이 많아야 정확한 예측을 하지만 반대로 시간이 오래 걸린다.\n이웃 데이터를 학습한다.\n특정 주변 이웃에 의해 크게 영향을 받을 수 있다.\n공통의 유저 / 아이템을 많이 공유해야만 유사도 값이 정확해진다.\n유사도 값이 정확하지 않은 경우 이웃의 효과를 보기 어렵다.\nUBCF: User-based CF(유저 기반 협업 필터링)\r#\r대상 유저와 유사도가 높은 유저들이 선호하는 아이템을 추천하는 방식\nex) 영화 평점\nUser A가 User B와 선호도가 비슷하므로, User B의 스타워즈 평점은 높을 것이라고 예상한다. 평점 산출 방식\nAbsolute Rating\nAverage — 평균내기\n모든 유저의 평점을 평균내서 평점을 예측한다.\nWeighted Average — 유저의 유사도를 반영하여 평점 예측\n유저 간의 유사도를 반영하여 평점을 예측한다.\n한계\n유저가 평점을 주는 기준이 제각기 다르다.\n따라서, 각 유저별 발생하는 편차를 제대로 반영하지 못하게 된다.\nRelative Rating\n유저의 평점을 그대로 사용하지 않고, 유저의 평균 평점에서의 편차를 사용한다.\n$$ \\begin{gathered}\\operatorname{dev}(u, i)=r(u, i)-\\overline{r_u} \\quad \\text { for known rating } \\\\widehat{\\operatorname{dev}}(u, i)=\\frac{\\sum_{u \\Omega^{\\prime} \\in \\Omega_i} \\operatorname{dev}\\left(u^{\\prime}, i\\right)}{\\left|\\Omega_i\\right|}=\\frac{\\sum_{u^{\\prime} \\in \\Omega_i} r\\left(u^{\\prime}, i\\right)-\\overline{r_{u^{\\prime}}}}{\\left|\\Omega_i\\right|} \\\\hat{r}(u, i)=\\overline{r_u}+\\frac{\\sum_{u \\prime \\in \\Omega_i} r\\left(u^{\\prime}, i\\right)-\\overline{r_{u^{\\prime}}}}{\\left|\\Omega_i\\right|}=\\overline{r_u}+\\widehat{\\operatorname{dev}}(u, i)\\end{gathered} $$\nex) 유저 B의 스타워즈에 대한 예측 평점\n예측 Deviation = 0.23\n$$ {1.6 \\times 0.95 + (-1.6) \\times (0.6) + 0 \\times 0.85\\over0.95 + 0.6 + 0.85} = 0.23 $$\n유저 B의 평점 평균 = 3\n유저 B의 예측 평점 = 3.23\nIBCF: Item-based CF(아이템 기반 협업 필터링)\r#\r타겟 아이템과 유사도가 높은 아이템 중 선호도가 큰 아이템을 추천하는 방식\n장점\n시간에 따라 유사도 변화가 적다.\nUser based CF에 비해 계산량이 적다.\nex) 영화 평점\n헐크와 스타워즈의 유저별 평점 분포가 비슷하므로, 유저 B의 스타워즈 평점이 높을 것이라 예측한다. 평점 산출 방식\nAbsolute Rating\nAverage — 평균내기\n모든 아이템의 평점을 평균내서 평점을 예측한다.\nWeighted Average — 아이템의 유사도를 반영하여 평점 예측\n아이템 간의 유사도를 반영하여 평점을 예측한다.\n이 때, 일부 아이템만 활용하여 평점을 예측하기도 한다.\nRelative Rating\n아이템의 평점을 그대로 사용하지 않고, 아이템의 평균 평점에서의 편차를 이용한다.\nex) 유저 B의 스타워즈에 대한 예측 평점\n코사인 유사도 사용. 2-NN 기준 아이언맨 0.9, 헐크 0.95, 스타워즈 평균 3.0\n예측 Deviation = 1.15\n$$ {0.9 \\times 0.25 + 0.95 \\times2\\over0.9 + 0.95} = 1.15 $$\n아이템 B의 평점 평균 = 3\n유저 B의 예측 평점 = 4.15\nTop-N Recommendation\n대상 유저에 대한 아이템 예측 평점 계산이 완료되면, 평점순으로 정렬하여 상위 N개만 추천하기\n"},{"id":29,"href":"/posts/2023-09-23-Optimizer/","title":"Optimizer란?","section":"Blog","content":" 간단 요약\nLoss의 미분값을 파라미터에 어떻게 반영할 지에 대한 방법\n반영 방법 : loss의 미분 값을 파라미터에 어떻게 반영할 것인가? Learning rate : 한 번에 얼마나 반영할 것인가?\n{: .prompt-info } Background: Gradient Descent(GD)에서의 Issue\r#\r1. Local minima, Saddle point\r#\r{: w=\u0026ldquo;700\u0026rdquo; h=\u0026ldquo;400\u0026rdquo; }\n실제로는 Local Minima보단 안장점(saddle point)이 문제인 경우가 더 많다.\nlocal minima가 되기 위해선 모든 변수 방향에서 loss가 증가해야 하는데, 이는 흔치 않다.\n{: w=\u0026ldquo;400\u0026rdquo; h=\u0026ldquo;250\u0026rdquo; }\n{: w=\u0026ldquo;400\u0026rdquo; h=\u0026ldquo;250\u0026rdquo; }\n대신 위의 상황에서 gradient descent 알고리즘이 평평한 곳에 머물러버리는 문제가 발생할 수 있다.\n꼭 머무르지 않더라도 주변이 평평하기 때문에 매우 더디게 학습이 진행되는 문제점도 있다.\n2. 길 헤매기\r#\rSGD, Mini-batch GD가 굉장히 헤매면서 길을 찾는다.\n헤매는 정도를 줄일 필요가 있다.\n이를 위해 Optimizer가 등장했다.\nOptimizer에서는 SGD에서 크게 두 가지를 개선한다.\n1. 방향\r#\rSGD에서 Optimum을 향해 나아갈 때, 위의 예시처럼 방향을 끊임없이 바꾸며 나아간다.\n이보단, 올바른 방향으로 더 많이 가는 것을 원한다.\n이를 위해 **관성(Momentum)**을 적용한다.\nMomentum\r#\r가중치를 갱신할 때, 이전에 나아갔던 방향도 반영을 해준다.\n단점\n학습률에 따라 minimum point에 수렴하지 못하는 경우가 발생한다.\nNAG : Nesterov Accelerated Gradient\r#\rMomentum의 단점을 개선한 방법.\n관성 방향으로 먼저 이동한 후, gradient를 계산한다.\nMomentum보다 수렴이 더 빠르다.\n2. 거리(학습률)\r#\rAdagard\r#\r현재까지 값이 많이 변한 파라미터에 대해서는 적게 변화시키고, 적게 변한 파라미터는 많이 변화시킨다.\n단점\n$G_t$의 값은 계속 커지는데, 이 값이 무한대에 가깝게 커지게 되면 값이 0이 되어버린다.\n즉, 이동을 멈춰버리게 된다.\nAdadelta\r#\rAdagrad의 단점을 개선한 방법.\n$G_t$가 너무 커지는 것을 방지한다.\nLearning rate가 없어 변형이 불가능하기 때문에, 잘 쓰지 않는다.\nRMSProp\r#\rAdadelta + stepsize.\nAdam\r#\rMomentum + RMSProp\n가장 많이 쓰인다.\n그림으로 보는 다양한 Optimization 기법들\n딥러닝(Deep learning) 살펴보기 2탄\n"},{"id":30,"href":"/posts/2023-09-12-Polynomial-Interpolation/","title":"Polynomial Interpolation(보간 다항식)","section":"Blog","content":"\rLinear Interpolation\r#\r가장 간단한 보간법\n두 점을 이은 직선의 방정식을 근사 함수로 사용한다.\n데이터 점들 사이의 간격이 작을수록 더 좋은 근삿값을 얻는다.\n$$ \\mathrm{g}(x)=\\frac{f\\left(x_{i+1}\\right)-f\\left(x_i\\right)}{x_{i+1}-x_i}\\left(x-x_i\\right)+f\\left(x_i\\right) $$\nPolynomial interpolation\r#\r(n+1)개의 점이 주어진 경우 n차 이하의 유일한 다항식을 구할 수 있다.\nQ. n+1개의 점으로 찾을 수 있는 n차 다항식은 왜 유일한가?\n방데르몽드 행렬\n각 행의 초항이 1인 등비수열로 이루어진 행렬\n$$ V=\\left(\\begin{array}{ccccc}1 \u0026amp; \\alpha_1 \u0026amp; \\alpha_1^2 \u0026amp; \\cdots \u0026amp; \\alpha_1^{n-1} \\1 \u0026amp; \\alpha_2 \u0026amp; \\alpha_2^2 \u0026amp; \\cdots \u0026amp; \\alpha_2^{n-1} \\1 \u0026amp; \\alpha_3 \u0026amp; \\alpha_3^2 \u0026amp; \\cdots \u0026amp; \\alpha_3^{n-1} \\\\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \u0026amp; \\vdots \\1 \u0026amp; \\alpha_m \u0026amp; \\alpha_m^2 \u0026amp; \\cdots \u0026amp; \\alpha_m^{n-1}\\end{array}\\right) $$\n방데르몽드 행렬 $V$에 대해 다음과 같이 일반화할 수 있다.\n$$ \\operatorname{det} V=\\prod_{i\u0026lt;j}\\left(\\alpha_i-\\alpha_j\\right) $$\n따라서, $a_0,a_1,\u0026hellip;,a_n$이 서로 다른 값을 가진다면 $V$는 역행렬이 존재한다.\n가역 행렬의 기본 정리에 의해 $\\tt Vx = b$의 해는 유일하다.\n이제 다항식을 찾아내는 세 가지 방법을 알아보자.\n미정 계수법\r#\r다항식을 찾는 가장 보편적인 방법\n보간 다항식 $p(x) = a_0 + a_1x + a_2x^2 + \u0026hellip; + a_nx^n$에 대해\n주어진 $n+1$개의 점을 $p(x)$에 대입하여 연립 방정식을 생성한다.\n모두 다 대입하면 아래와 같이 방데르몽드 행렬식 형태를 얻을 수 있다.\n$$ \\begin{array}{cc}p\\left(x_0\\right)=f\\left(x_0\\right) \u0026amp; a_0+a_1 x_0+a_2 x_0^2+\\cdots+a_n x_0^n=f\\left(x_0\\right) \\p\\left(x_1\\right)=f\\left(x_1\\right) \u0026amp; a_0+a_1 x_1+a_2 x_1^2+\\cdots+a_n x_1^n=f\\left(x_1\\right) \\\\vdots \u0026amp; \\vdots \\p\\left(x_n\\right)=f\\left(x_n\\right) \u0026amp; a_0+a_1 x_n+a_2 x_n^2+\\cdots+a_n x_n^n+\\left(x_n\\right)\\end{array} $$\n$$ \\left[\\begin{array}{ccccc}1 \u0026amp; x_0 \u0026amp; x_0^2 \u0026amp; \\cdots \u0026amp; x_0^n \\1 \u0026amp; x 1 \u0026amp; x_1^2 \u0026amp; \\cdots \u0026amp; x_1^n \\\u0026amp; \u0026amp; \u0026amp; \\cdots \u0026amp; \\1 \u0026amp; x_n \u0026amp; x_n^2 \u0026amp; \\cdots \u0026amp; x_n^n\\end{array}\\right]\\left[\\begin{array}{l}a 0 \\a 1 \\\\cdots \\a n\\end{array}\\right]=\\left[\\begin{array}{c}f\\left(x_0\\right) \\f\\left(x_1\\right) \\\\cdots \\f\\left(x_n\\right)\\end{array}\\right] $$\n가우스 소거법 등으로 연립 방정식의 해를 구한다.\n단점\n느린 계산 시간 오차 발생 Lagrange Interpolation(라그랑주 보간법)\r#\r연립 방정식을 풀지 않고 다항식을 결정하는 방법\n특정 숫자를 대입하면 0이나 1이 되는 항을 만든다.\n$(x-a)$를 곱해주면 $x$에 a값을 대입할 때 0이 된다. $(x-a)$를 $(b-a)$로 나누면, $x$에 $b$를 대입했을 때 1이 된다. 1차 함수\n두 점$(x_0, y_0), (x_1, y_1)$이 주어진 경우\n$$ y=\\left(\\frac{x-x_1}{x_0-x_1}\\right) y_0+\\left(\\frac{x-x_0}{x_1-x_0}\\right) y_1 $$\n위 식에 $x_0$을 대입하면 $y_0$이 나오고, $x_1$을 대입하면 $y_1$이 나온다.\n해당 식은 직관적으로 $(x_0,0),(x_1,y_1)$을 지나는 직선의 기울기와 $(x_0,y_0),(x_1,0)$을 지나는 직선의 기울기의 합으로 이해할 수 있다.\n2차 함수\n세 점$(x_0, y_0), (x_1, y_1), (x_2, y_2)$이 주어진 경우\n$$ y=\\left(\\frac{\\left(x-x_1\\right)\\left(x-x_2\\right)}{\\left(x_0-x_1\\right)\\left(x_0-x_2\\right)}\\right) y_0+\\left(\\frac{\\left(x-x_2\\right)\\left(x-x_0\\right)}{\\left(x_1-x_2\\right)\\left(x_1-x_0\\right)}\\right) y_1\\ +\\left(\\frac{\\left(x-x_0\\right)\\left(x-x_1\\right)}{\\left(x_2-x_0\\right)\\left(x_2-x_1\\right)}\\right) y_2 $$\n마찬가지로, $(x_i,y_i)$를 지나면서 $(x_j,0)$을 지나는 이차 함수의 기울기의 합으로 이해할 수 있다.\n3차 함수\n네 점이 주어진 경우\n$$ y=\\left(\\frac{\\left(x-x_1\\right)\\left(x-x_2\\right)\\left(x-x_3\\right)}{\\left(x_0-x_1\\right)\\left(x_0-x_2\\right)\\left(x_0-x_3\\right)}\\right) y_0\\ +\\left(\\frac{\\left(x-x_2\\right)\\left(x-x_3\\right)\\left(x-x_0\\right)}{\\left(x_1-x_2\\right)\\left(x_1-x_3\\right)\\left(x_1-x_0\\right)}\\right) y_1\\ +\\left(\\frac{\\left(x-x_0\\right)\\left(x-x_1\\right)\\left(x-x_3\\right)}{\\left(x_2-x_0\\right)\\left(x_2-x_1\\right)\\left(x_2-x_3\\right)}\\right) y_2\\ +\\left(\\frac{\\left(x-x_0\\right)\\left(x-x_1\\right)\\left(x-x_2\\right)}{\\left(x_3-x_0\\right)\\left(x_3-x_1\\right)\\left(x_3-x_2\\right)}\\right) y_3 $$\n일반화\n$$ L_i(x)=\\prod_{\\substack{j=0 \\ j \\neq i}}^n \\frac{x-x_j}{x_i-x_j} $$\n위의 식은 곧 $x_i$를 넣었을 때 $y_i$가 나온다는 것을 의미한다.\n$$ \\begin{matrix}P_n(x)\u0026amp;=\u0026amp;L_0(x) f\\left(x_0\\right)+L_1(x) f\\left(x_1\\right)+\\cdots L_n(x) f\\left(x_n\\right)\\\\ \u0026amp;=\u0026amp;\\sum_{i=0}^n L_{i(x)} f\\left(x_i\\right) \\end{matrix} $$\nQ. 단일 함수를 구할 수 있는가?\n$P_n\\left(x_i\\right)=y_i$를 만족하므로 $\\mathrm{n}+1$개의 점 $\\left(x_i, y_i\\right)$을 지나는 유일한 $\\mathrm{n}$차 다항식이다.\nQ. 연산량이 기존 방법과 비교했을 때 늘어나는가, 줄어드는가?\n단점\n차수가 커지면 참 값을 기대할 수 없을 정도의 오차가 발생한다.\n데이터의 수가 증가할 때, 바로 직전의 결과를 사용하지 못한다.\n점이 추가되면 식을 처음부터 다시 계산해야 한다.\n하나의 보간을 위해 필요한 계산량이 많다.\n그렇다면, 식을 처음부터 다시 계산하지 않는 방법은 없을까?\n결국 라그랑주 보간법은 각 점을 지나는 함수의 기울기를 합산하는 방식이기 때문에, 기울기가 중복으로 계산되는 지점을 제거하여 연산량을 줄일 수 있다. 이를 위해 Divided Difference이 쓰인다.\nNewton’s divided differences interpolation\r#\r라그랑주 보간법의 모든 단점을 해결하는 방법\n점 두 개로 일차 함수를 먼저 그린 후, 점을 추가해나가며 다항식의 차수를 점점 확장해나가는 방식 연립 일차 방정식을 사용하지 않는다. 뉴턴 형을 활용한다. Divided Differences(분할 차분법)\r#\r간단 요약\n분할 구간에서 함수값들의 차이\n기울기에 대한 이산적인 추정치로 사용할 수 있다.\n뉴턴 형이 주어졌을 때, 상수 항들을 어떻게 계산해야 할까?\n뉴턴 형\n서로 다른 점 $x_0, \u0026hellip;, x_n$에 대해 x값에 따라 상수 항들을 순서대로 구할 수 있는 형태\n$$ \\begin{matrix}P_n(x)=a_0+a_1\\left(x-x_0\\right) +a_2\\left(x-x_0\\right)\\left(x-x_1\\right) +\\\\ldots +a_n\\left(x-x_0\\right)\\left(x-x_1\\right) \\ldots\\left(x-x_{n-1}\\right)\\end{matrix} $$\n식이 복잡하게 생겼다. $P_n(x) = f(x)$라 정의하고, 식을 상수 항 기준으로 정리해보자.\n$a_0, a_1$ 도출 과정\r#\r$$ a_0 = f\\left(x_0\\right)\\ f(x_1) = a_0 + a_1(x_1-x_0), \\ \\therefore a_1 = {f\\left(x_1\\right) - f(x_0)\\over x_1-x_0} $$\n해당 식의 형태를 $f[x_0,x_1]$로 치환하자.\n이는 first order Divided Difference라고 부른다.\nfirst order Divided Difference\r#\r$$ f\\left[x_0, x_1\\right]=\\frac{f\\left(x_1\\right)-f\\left(x_0\\right)}{x_1-x_0} $$\n한글로 번역하면 1차 분할 차분인데, 이는 위의 수식이 1차 미분에 대한 이산적인 추정치로 쓰일 수 있기 때문이다.\n만약 $f(x)$가 구간 $[x_0,x_1]$에서 미분 가능하다면, 평균값 정리에 의해$f\\left[x_0, x_1\\right]=f^{\\prime}(c)$임을 보장한다.\n$a_2$ 도출 과정\r#\r$$ \\begin{matrix} f(x_2) \u0026amp;=\u0026amp; a_0 + a_1(x_2 - x_0) + a_2(x_2-x_0)(x_2-x_1)\\ \u0026amp;=\u0026amp; f(x_0) + (x_2 - x_0)(a_1 + a_2(x_2 - x_1)),\\ f(x_2) - f(x_0) \u0026amp;=\u0026amp; (x_2-x_0)(a_1 + a_2(x_2 - x_1)) \\end{matrix} $$\n이고, 이를 좀 더 정리하면\n$$ \\frac{f(x_2)-f(x_0)}{x_2-x_0} = a_1 + a_2(x_2 - x_1) $$\n이 된다.\n여기서, $a_1$과 $a_2$에서 반복되는 형태를 $f[x_a,x_b]$로 치환하자.\n$$ f[x_0,x_2] = f[x_0,x_1] + a_2(x_2 - x_1)\\ \\frac{f[x_0,x_2] - f[x_0,x_1]}{x_2 - x_1} = a_2\\ $$\n위 식은 $f[x_0,x_1,x_2]$로 치환하며, Second order Divided Difference라고 부른다.\nHigh order Divided Difference\r#\r$$ f\\left[x_0, x_1, x_2\\right]=\\frac{f\\left[x_1, x_2\\right]-f\\left[x_0, x_1\\right]}{x_2-x_0} $$\n$$ f\\left[x_0, x_1, x_2, x_3\\right]=\\frac{f\\left[x_1, x_2, x_3\\right]-f\\left[x_0, x_1, x_2\\right]}{x_3-x_0} $$\n$$ f\\left[x_0, \\ldots, x_n\\right]=\\frac{f\\left[x_1, \\ldots, x_n\\right]-f\\left[x_0, \\ldots, x_{n-1}\\right]}{x_n-x_0} $$\n이와 같은 형태로 나머지 $a_n$에 대해서도 정리할 수 있고, 최종적으로 기존의 뉴턴 형은 다음과 같은 형태가 된다.\n$$ \\begin{aligned}\u0026amp; P_1(x)=f\\left(x_0\\right)+\\left(x-x_0\\right) f\\left[x_0, x_1\\right] \\\u0026amp; \\begin{aligned}P_2(x)=f\\left(x_0\\right) \u0026amp; +\\left(x-x_0\\right) f\\left[x_0, x_1\\right] \\\u0026amp; +\\left(x-x_0\\right)\\left(x-x_1\\right) f\\left[x_0, x_1, x_2\\right]\\end{aligned}\\ \u0026amp;\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\vdots\\\u0026amp; \\begin{aligned}P_n(x)=f\\left(x_0\\right) \u0026amp; +\\left(x-x_0\\right) f\\left[x_0, x_1\\right]+\\cdots \\\u0026amp; +\\left(x-x_0\\right)\\left(x-x_1\\right) \\cdots\\left(x-x_{n-1}\\right) f\\left[x_0, x_1, \\ldots, x_n\\right]\\end{aligned}\\end{aligned} $$\n여기에서 중요한 점은, 기호화를 함으로써 값을 재활용할 수 있게 되었다는 것이다.\n또한, 기존의 값을 활용하여 다음 값을 구할 수 있게 되었다.\n최종적으로 뉴턴 공식을 일반화하여 정리하면 다음과 같은 형태가 된다.\n$$ \\begin{aligned}P_n(x) \u0026amp; =f\\left[x_0\\right]+f\\left[x_0, x_1\\right]\\left(x-x_0\\right)+\\cdots\\ \u0026amp;\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ +f\\left[x_0, \\cdots, x_n\\right]\\left(x-x_0\\right) \\cdots\\left(x-x_{n-1}\\right) \\\u0026amp; =f\\left[x_0\\right]+\\sum_{k=1}^n f\\left[x_0, \\cdots, x_k\\right]\\left(x-x_0\\right) \\cdots\\left(x-x_{k-1}\\right) \\\u0026amp; =f\\left[x_0\\right]+\\sum_{k=1}^n f\\left[x_0, \\cdots, x_k\\right] \\prod_{i=0}^{k-1}\\left(x-x_i\\right)\\end{aligned} $$\n이를 점화식의 형태로 정리하면 다음과 같다.\n$$ p_{n+1}(x)=p_n(x)+f[x_0, x_1, \\cdots, x_n, x_{{n+1}}] \\prod_{j=0}^n(x-x_j) $$\n2. Error in polynomial interpolation\r#\r보간 다항식은 결국 실제 함수에 대한 추정이기 때문에, 오차가 존재한다.\n라그랑주 보간법의 오차를 계산해보자.\n앞에서 $P_n(x)$를 다음과 같이 정리했다.\n$$ \\begin{matrix}P_n(x)\u0026amp;=\u0026amp;L_0(x) f\\left(x_0\\right)+L_1(x) f\\left(x_1\\right)+\\cdots L_n(x) f\\left(x_n\\right)\\ \u0026amp;=\u0026amp;\\sum_{i=0}^n L_{i(x)} f\\left(x_i\\right) \\end{matrix} $$\n$f(x):$ 구간 $[a,b]$에서 정의된 함수(실제 함수) $p_n(x): n+1$ $n+1$$f(x)$의 보간 다항식 이라 했을 때, 다음이 성립한다.\n$$ f(x)=P_n(x) + \\frac{\\left(x-x_0\\right)\\left(x-x_1\\right) \\cdots\\left(x-x_n\\right)}{(n+1) !} f^{(n+1)}\\left(c_x\\right) $$\n$c_x : [a,b]$ 구간 내 임의의 점\n증명 과정\n실제 함수$f(x)$와 보간 다항식 $P_n(x)$의 차이에 대한 함수를 $R_n(x)$라 하자. $(x \\neq x_k)$\n즉, $f(x) = P_n(x) + R_n(x)$가 성립하는 상황에서,\n$R_n(x)$는 $x_k$마다 0이 되기 때문에 다음과 같이 정의할 수 있다.\n$$ R_n(x)=C \\prod_{k=0}^n\\left(x-x_k\\right) $$\n$C$는 상수를 의미한다. 새로운 함수 $F(x)$를\n$$ F(x) = f(x) - P_n(x) - R_n(x) $$\n라고 할 때,\n**롤의 정리(Rolle\u0026rsquo;s Theorem)**에 의해 $\\mathrm{n}$개 점에서 함수가 0이면, $\\mathrm{n}-1$차 미분의 값이 0인 점이 존재한다.\n$\\mathrm{g}(\\mathrm{t})$ 는 $x, x_0, x_1, \\ldots, x_n$ 의 구간으로 $\\mathrm{n}+2$개의 함수가 0 인 점이 존재하므로, $\\mathrm{n}+1$ 차 미분이 0 인 점 $c_x$가 존재한다.\n$$ f^{n+1}(c_x)-P^{n+1}(c_x)-[f(x)-P(x)] \\frac{d^{n+1}}{d t^{n+1}}\\left[\\Pi_{i=0}^n \\frac{t-x_i}{x-x_i}\\right]_{t=c_x} $$\n$\\mathrm{P}$ 는 최대 $\\mathrm{n}$차식이므로 $P^{n+1}=0$ $g^{n+1}(c_x)=0=f^{n+1}(c_x)-0-f(x)-P(x) ! \\Pi_{i=0}^n \\frac{1}{x-x_i}$\n$\\left(t-x_i\\right)$ 는 $\\mathrm{n}+1$ 차항이므로 $\\mathrm{n}+1$번 미분하면 $(\\mathrm{n}+1)!$ 위 식을 $\\mathrm{f}(\\mathrm{x})$ 에 대해 정리하면 다음과 같다.\n$$ f(x)=P(x)+\\frac{f^{n+1}(c_x)}{(n+1) !}\\left(x-x_0\\right)\\left(x-x_1\\right) \\ldots\\left(x-x_n\\right) $$\n결론적으로, 오차(실제 함수 - 보간 다항식)는 다음과 같이 정의된다.\n$$ e_n(x)=f(x)-P_n(x) $$\n$$ f(x)-P(x)=\\frac{f^{n+1}(c_x)}{(n+1) !}\\left(x-x_0\\right)\\left(x-x_1\\right) \\ldots\\left(x-x_n\\right) $$\n최대 오차는 $\\max |\\frac{f^{n+1}(c_x)}{(n+1) !}| \\cdot \\max |\\left(x-x_0\\right)\\left(x-x_1\\right) \\ldots\\left(x-x_n\\right)|$ $f(x):$ 구간 $[a,b]$에서 정의된 함수(실제 함수)\n$p_n(x): n+1$ $n+1$$f(x)$의 보간 다항식\n이라 했을 때, 오차(실제 함수 - 보간 다항식)는 다음과 같이 정의된다.\n$$ e_n(x)=f(x)-p_n(x) $$\n따라서 다음이 성립한다.\n$$ \\begin{aligned} \u0026amp; p_{n+1}\\left(x_i\\right)=f\\left(x_i\\right), \\quad i=0,1,2, \\cdots, n \\ \u0026amp; p_{n+1}(\\bar{x})=f(\\bar{x}) \\end{aligned} $$\n뉴턴 공식으로 다시 표현하면\n$$ p_{n+1}(x)=p_n(x)+f\\left[x_0, x_1, \\cdots, x_n, \\bar{x}\\right] \\prod_{j=0}^n(x-x_j) $$\n과 같고, 이 때의 $f(x)$는 다음과 같다.\n$$ f(\\bar{x})=p_{n+1}+f\\left[x_0, x_1, \\cdots, x_n, \\bar{x}\\right) \\prod_{j=0}^n\\left(\\bar{x}-x_j\\right) $$\n아래에서 표현된 식들로 오차에 대한 식을 다시 정리해보면\n$$ e_n(\\bar{x})=f\\left[x_0, x_1, \\cdots, x_n, \\bar{x}\\right] \\prod_{j=0}^n\\left(\\bar{x}-x_j\\right) $$\n위처럼 나타낼 수 있다.\n참고 자료\n[수치해석] 6. Lagrange Interpolation\n다항 함수 보간(Polynomial Interpolation)\n수치해석 및 실습 - 6 분할 차분표와 보간표\n6차시 - 분할차분표와 보간법(1)\n그렇다면 과연 뉴턴 보간법은 단점이 없을까? 그렇지 않다.\n3. Spline Interpolation\r#\r뉴턴 보간법과 라그랑주 보간법은 계단 함수와 같은 급격한 불연속을 잘 표현하지 못한다.\nRunge 현상\nRunge 함수는 Polynomial로 적합이 잘 되지 않는 함수로 알려져 있다.\n$$ f(x)=\\frac{1}{1+25 x^2} $$\nGibbs 현상 불연속 함수를 근사할 때 불연속 값 근처에서 나타나는 불일치 현상 Piecewise Polynomials Interpolation\r#\r여러 개의 데이터를 하나의 추정 함수로 표현하지 않고, 구간 별로 추정 함수를 구하는 것\n사진은 Interpolation이 아니라 Regression에 해당하지만, Piecewise Polynomial에 대한 이해를 돕기 위해 가져왔다.\n다만, 사진처럼 knot에서 불연속이기 때문에, 합리적이지 않은 추정 함수가 나올 수 있다.\nContinuous Piecewise Polynomials Interpolation\r#\rPiecewise에 연속이라는 제약 조건을 추가했다.\n하지만 여전히 만족스럽지 않다.\nSpline\r#\r각 지점(knots)에서 자기 자신과 1차 미분 함수부터 $d-1$차 미분 함수까지 모두 연속이다. knot에서 함수의 계수가 변하므로 knot가 많을 수록 더 유연하게 된다. 점과 점 사이를 그저 연결하면 Linear Spline이 되기 때문에, 선형 스플라인은 잘 활용하지 않는다.\n2차 Spline부터 알아보자.\nQuadratic Spline Interpolation\r#\rn+1개의 점을 연결하는 n개의 2차 다항식을 추정하고자 한다.\n각 2차 다항식마다 $ax^2 + bx + c$와 같이 3개의 미지수가 존재하기 때문에, 모든 다항식을 추정하기 위해서 $3n$개의 조건이 필요하다.\n이러한 $3n$개의 조건은 적절한 제약을 추가하여 얻을 수 있다.\n첫 번째 함수와 맨 마지막 함수는 각각 첫 번째 점과 마지막 점을 지나야 한다.\n이로부터 2개의 조건을 얻을 수 있다.\n$\\begin{aligned}\u0026amp; f\\left(x_0\\right)=a_1 x_0^2+b_1 x_0+c_1 \\\u0026amp; f\\left(x_n\\right)=a_n x_n^2+b_n x_n+c_n\\end{aligned}$\n이제 나머지 n개의 조건을 얻으면 된다.\n양 끝을 제외한 n-1개의 점에서 함수가 연속해야 한다.\n즉, 각 내부의 점에서 n개의 함수는 양 끝 점을 지나야 한다.\n이로부터 $2n-2$개의 조건을 얻을 수 있다.\n$i=2\\dots n$일 때, $f\\left(x_{i-1}\\right)=a_{i-1} x_{i-1}^2+b_{i-1} x_{i-1}+c_{i-1}:$ 주어진 $i-1$번째 데이터의 왼쪽 함수 $f\\left(x_{i-1}\\right)=a_i x_{i-1}^2+b_i x_{i-1}+c_i:$ 주어진 $i-1$ 번째 데이터의 오른쪽 함수\n모든 점에서 함수가 매끄러워야 한다. 즉, 모든 knots에서 미분 가능해야 한다.\n$i=2\\dots n$일 때, $f^{\\prime}\\left(x_{i-1}\\right)=2 a_{i-1} x_{i-1}+b_{i-1}$ : 주어진 $i-1$ 번째 데이터의 왼쪽 1차 도함수 $f^{\\prime}\\left(x_{i-1}\\right)=2 a_i x_{i-1}+b_i$ : 주어진 $i-1$ 번째 데이터의 왼쪽 1차 도함수\n이를 통해 $n-1$개의 조건을 얻을 수 있다.\n이제 단 하나의 조건만 있으면 된다.\n첫 번째 함수의 이계 도함수는 0이다. 즉, 첫 번째 함수는 직선이다.\n$f_1\u0026rsquo;\u0026rsquo;(x_0) = a_1 = 0$\n이렇게 총 $3n$개의 조건을 얻었으므로, $n$개의 2차 다항식을 추정할 수 있다.\nCubic Spline Interpolation\r#\r2차 Spline 보간법과 마찬가지 이유로 이번에는 $4n$개의 조건이 필요하다.\n첫 번째와 마지막 함수는 각 양 끝 점을 지난다. → $2$ 연속 → $2n - 2$ 미분 가능(1계 도함수 연속) → $n-1$ 2계 도함수 연속 → $n-1$ 여기까지 계산하면 총 $4n - 2$로 2개의 조건이 부족해 유일 해를 구할 수 없다.\n따라서 다음과 같은 임의의 조건을 추가하여 유일 해를 채울 수 있다.\n첫 번째 함수와 마지막 함수의 2계 도함수는 0이어야 한다. → $2$ 이러한 다섯 개의 조건으로 보간된 곡선을 Natural Cubic Spline이라고 한다.\n4차 이상의 고차 스플라인은 내재된 불안정성 때문에 잘 사용하지 않기 때문에, Cubic Spline을 가장 많이 활용한다.\n참고 자료\r#\r회귀 스플라인 (Regression Spline)에 대한 이해\n[interpolation] - Spline method\nSplines\n스플라인 보간법 - 점을 부드럽게 잇기\n[ISL] 7장 -비선형모델(Local regression, Smoothing splines, GAM) 이해하기 · Go\u0026rsquo;s BLOG\n"},{"id":31,"href":"/posts/2023-06-29-Pytorch-overview/","title":"PyTorch 개요","section":"Blog","content":" Naver BoostCamp AI Tech에서 학습한 내용을 재구성했습니다.\n해당 게시글은 지속적으로 업데이트할 예정입니다.\n{: .prompt-info }\n구현 개요(PyTorch)\r#\r1. 데이터 준비\r#\rTensor PyTorch Datasets \u0026amp; DataLoaders 2. 모델 정의 (\rtorch.nn.Module)\r#\rPyTorch 모델 불러오기\nInput size, Output size 정의 nn.Parameter Forward 연산 정의 Backward 연산 정의 3. 하이퍼 파라미터 지정 Hyperparameter Tuning\r#\r4. 모델 평가 기준 및 Optimizer 설정\r#\r모델 평가 기준 : loss를 어떻게 계산할 것인가? 손실 함수(Loss Function) Optimizer 설정 5. 모델 학습\r#\r1 epoch에 일어나는 일 PyTorch Multi-GPU 학습 6. 모델 성능 평가\r#\rMonitoring tools for PyTorch\n7. 추론\r#\rAutoGrad 튜토리얼 Tensor와 AutoGrad 튜토리얼 Pytorch로 Linear Regression하기 Pytorch로 Logistic Regression하기 한 epoch에서 이뤄지는 모델 학습 과정을 정리해보고 성능을 올리기 위해서 어떤 부분을 먼저 고려하면 좋을지 논의해보기 데이터 개선 모델 개선 loss 개선 optimizer 개선 DL 모델 구현 예제\nPyTorch Troubleshooting\n"},{"id":32,"href":"/posts/2023-09-21-PyTorch-%EB%AA%A8%EB%8D%B8-%EB%B6%88%EB%9F%AC%EC%98%A4%EA%B8%B0/","title":"PyTorch 모델 저장하고 불러오기","section":"Blog","content":"\rmodel.save()\r#\r학습의 결과를 저장하기 위한 함수\n모델 형태(architecture)와 파라미터를 저장\n모델 학습 중간 과정의 저장을 통해 최선의 결과 모델을 선택\n만들어진 모델을 외부 연구자와 공유하여 학습 재연성 향상\n# Print model\u0026#39;s state_dict print(\u0026#34;Model\u0026#39;s state_dict:\u0026#34;) # state dict: 모델의 파라미터를 표시 for param_tensor in model.state_dict(): print(param_tensor, \u0026#34;\\t\u0026#34;, model.state_dict()[param_tensor].size()) ## 방법 1. # 모델의 파라미터만 저장하기 **torch.save**(model.**state_dict()**, os.path.join(MODEL_PATH, \u0026#34;model.pt\u0026#34;)) # 모델은.pt 파일로 저장한다. # dict type으로 저장된다. new_model = TheModelClass() # 모델의 Architecture가 동일한 경우 파라미터만 저장하고 불러온다. new_model.**load_state_dict**(torch.load(os.path.join(MODEL_PATH, \u0026#34;model.pt\u0026#34;))) ## 방법 2. # 모델의 architecture와 함께 저장한다. torch.**save**(model, os.path.join(MODEL_PATH, \u0026#34;model.pt\u0026#34;)) model = torch.**load**(os.path.join(MODEL_PATH, \u0026#34;model.pt\u0026#34;)) # 모델의 architecture와 함께 load한다. # 사실 모델 자체를 공유하는 경우 코드로 공유하는 방법이 있기 때문에, # 일반적으로 위의 방식이 더 많이 쓰인다. checkpoints\r#\r학습의 중간 결과를 저장하여 최선의 결과를 선택\nearlystopping 기법 사용시 이전 학습의 결과물을 저장한다.\nloss와 metric 값을 지속적으로 확인 저장\n일반적으로, epoch, loss, metric을 함께 저장하여 확인한다.\ncolab에서 지속적인 학습을 위해서는 반드시 필요하다.\ntorch.save({ # 모델의 정보는 epoch와 함께 저장 \u0026#39;epoch\u0026#39;: e, \u0026#39;model_state_dict\u0026#39;: model.state_dict(), \u0026#39;optimizer_state_dict\u0026#39;: optimizer.state_dict(), \u0026#39;loss\u0026#39;: epoch_loss, }, f\u0026#34;saved/checkpoint_model_{e}*{epoch_loss/len(dataloader)}*{epoch_acc/len(dataloader)}.pt\u0026#34;) checkpoint = torch.load(PATH) model.load_state_dict(checkpoint[\u0026#39;model_state_dict\u0026#39;]) optimizer.load_state_dict(checkpoint[\u0026#39;optimizer_state_dict\u0026#39;]) epoch = checkpoint[\u0026#39;epoch\u0026#39;] loss = checkpoint[\u0026#39;loss\u0026#39;] Pretrained Learning\r#\rTransfer Learning\nComputer Vision 모델 레포지토리 Segmentation 모델 레포지토리 Transfer Learning vs Fine-tuning 관련 내용 Andrew Ng 교수님의 Transfer Learning 영문강의 (YouTube) "},{"id":33,"href":"/posts/2023-09-21-PyTorch-%EB%AA%A8%EB%8D%B8-%EC%A0%95%EC%9D%98%ED%95%98%EA%B8%B0/","title":"PyTorch 모델 정의하기 - nn.Module","section":"Blog","content":" 간단 요약\n반복되는 Layer을 만들기 위한 Torch의 가장 기본적인 신경망 모듈\n매개변수를 캡슐화하는 간편한 방법\nGPU로 이동, 내보내기(exporting), 불러오기(loading) 등의 작업을 위한 헬퍼(helper)를 제공한다.\n{: .prompt-info }\nDL 모델은 모두 Layer의 반복이며, 블록 반복의 연속이다.\nModule에서 정의하는 것\nInput\nOutput\nForward\n(Backward)\n이 때, Backward는 자동 미분이 되기 때문에, 해당되는 weight의 값들을 내보내준다.\n즉, weight가 학습의 대상이 되고, 이를 parameter(tensor)로 정의한다.\n일반적으로는 직접 지정해줄 필요가 없다.\nexample\r#\rimport torch from torch.autograd import Variable class LinearRegression(torch.nn.Module): def __init__(self, inputSize, outputSize): super(LinearRegression, self).__init__() # pytorch에서 제공하는 xw + b 모듈 self.linear = torch.nn.Linear(inputSize, outputSize) def forward(self, x): out = self.linear(x) return out "},{"id":34,"href":"/posts/2023-09-21-PyTorch-nn-Parameter/","title":"PyTorch에서 weight를 저장하는 객체 - nn.Parameter","section":"Blog","content":" 간단 요약\n학습의 대상이 되는 Weight를 정의한다.\nTensor 객체의 상속 객체 {: .prompt-info }\nTensor 객체와 매우 비슷하다.\nnn.Module의 attribute가 될 때는 required_grad = True로 자동으로 지정되어 AutoGrad의 대상이 된다.\n대부분의 Layer에는 weights 값들이 지정되어 있기 때문에, 직접 지정할 일은 드물다. 그래도 직접 지정하는 법을 알아보자.\nnn.Module로 만든 $\\tt xw +b$라는 선형 모델을 살펴본다.\n$\\tt xw +b$\r#\rclass MyLinear(nn.Module): def __init__ (self, in_features, out_features, bias=True): super(). init () **self.in_features = in_features self.out_features = out_features** **self.weights = nn.Parameter(torch.randn(in_features, out_features)) self.bias = nn.Parameter(torch.randn(out_features))** def forward(self, x : Tensor): return x @ self.weights + self.bias # xw + b의 형태로 output이 나온다. ex — Feature가 7개 있고, 배치가 3인 경우\n데이터는 $3 \\times 7$의 형태가 된다.\n7개의 feature를 넣어서\nin_features = 7\n5개의 클래스 중 하나로 예측하고자 한다면\nout_features = 5\n$7 \\times 5$ 형태의 weight 값이 필요하다.\nnn.Parameter(torch.randn(7, 5)\n이후, bias 값도 선언해준다.\nnn.Parameter(torch.randn(5))\n이후, forward에서 $\\tt xw +b$을 return해준다.\ndef forward(self, x : Tensor):\rreturn x @ self.weights + self.bias\n즉, 모델의 예측 값($\\hat y$)을 뱉어낸다.\n이후, backward()에서 실제 값과 예측 값의 차이(loss)에 대해 미분을 수행한다.\n"},{"id":35,"href":"/posts/2023-06-13-Backward/","title":"PyTorch의 Backward에 대해 알아보자.","section":"Blog","content":" ✔️ 간단 요약\nforward함수를 정의하면 자동으로 정의된다.\n동작 과정\ntensor(loss에 해당)가 포함된 식을 미분한다. 미분 값을 tensor에 저장한다.\n{: .prompt-info } Autograd, loss, optimizer, nn.Module tensor(loss에 해당)가 포함된 식을 미분한다.\nTensor 객체의 backward 함수에는 default로 Autograd 설정이 되어 있기 때문에, 미분 수식을 따로 작성하지 않아도 자동으로 미분이 가능하다.\n기본 예제\nw = torch.tensor(2.0, requires_grad=True) y = w**2 z = 10*y + 25 z.backward() w.grad() # output : tensor(40.) $$ w = 2\\ y = w^2\\ z = 10\\times y + 25\\ z = 10 \\times w^2 + 25\\ {dz\\over dw} = 20 \\times w = 40 $$\n미분 값이 여러 개인 경우\na = torch.tensor([2.,3.], requires_grad=True) b = torch.tensor([6.,4.], requires_grad=True) Q = 3 * a ** 3 - b ** 2 # 미분값이 두 개가 나와야하기 때문에, # gradient 값의 크기를 잡아준다. external_grad = torch.tensor([1., 1.]) Q.backward(gradient=external_grad) a.grad b.grad # output: tensor([36.,81.]) # output: tensor([-12.,-8.]) $$ \\begin{aligned} \u0026amp;Q = 3a^3 - b^2\\ \u0026amp; \\frac{\\partial Q}{\\partial a}=9 a^2 \\ \u0026amp; \\frac{\\partial Q}{\\partial b}=-2 b \\end{aligned} $$\n미분 값을 tensor에 저장한다.\ntensor를 선언할 때 require_grad=True로 설정하면 tensor에 grad_fn 정보가 저장된다.\ne.g. tensor(6.2564e-05, grad_fn=\u0026lt;MseLossBackward0\u0026gt;)\n또한, tensor.grad()를 통해 미분 값을 확인할 수 있다.\ngrad_fn에는 텐서가 어떤 연산을 했는 연산 정보를 담고 있고, 이 정보는 역전파에 사용된다.\nPyTorch Gradient 관련 설명 (Autograd)\n실제 backward는 Module 단계에서 직접 지정이 가능하다.\nModule에서 backward와 optimizer를 오버라이딩 해주면 된다.\n사용자가 직접 미분 수식을 써야 하는 부담이 있다.\n쓸 일은 없지만, 순서를 이해할 필요는 있다.\n예제 — Logistic Regression\r#\rclass LR(nn.Module): def init (self, dim, lr=torch.scalar_tensor(0.01)): super(LR, self). init () # intialize parameters self.w = torch.zeros(dim, 1, dtype=torch.float).to(device) self.b = torch.scalar_tensor(0).to(device) self.grads = {\u0026#34;dw\u0026#34;: torch.zeros(dim, 1, dtype=torch.float).to(device), \u0026#34;db\u0026#34;: torch.scalar_tensor(0).to(device)} self.lr = lr.to(device) $$ h_\\theta(x)=\\frac{1}{1+e^{-\\theta^T \\mathbf{x}}} $$\ndef forward(self, x): ## compute forward z = torch.mm(self.w.T, x) a = self.sigmoid(z) return a def sigmoid(self, z): return 1/ (1 + torch.exp(-z)) def backward(self, x, yhat, y): ## compute backward self.grads[\u0026#34;dw\u0026#34;] = (1/x.shape[1]) * torch.mm(x, (yhat - y).T) self.grads[\u0026#34;db\u0026#34;] = (1/x.shape[1]) * torch.sum(yhat - y) $$ \\begin{aligned}\u0026amp;\\frac{\\partial}{\\partial \\theta_j} J(\\theta)=\\frac{1}{m} \\sum_{i=1}^m\\left(h_\\theta\\left(x^i\\right)-y^i\\right) x_j^i\\end{aligned} $$\ndef optimize(self): ## optimization step self.w = self.w - self.lr * self.grads[\u0026#34;dw\u0026#34;] self.b = self.b - self.lr * self.grads[\u0026#34;db\u0026#34;] 기존의 $\\theta$, 즉, $\\tt w$ 값에 미분값 만큼의 업데이트를 수행해주는 함수.\n$$ \\begin{aligned}\\theta_j \u0026amp; :=\\theta_j-\\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta) \\\u0026amp; :=\\theta_j-\\alpha \\sum_{i=1}^m\\left(h_\\theta\\left(x^i\\right)-y^i\\right) x_j^i\\end{aligned} $$\n전체 코드\nclass LR(nn.Module): def init (self, dim, lr=torch.scalar_tensor(0.01)): super(LR, self). init () # intialize parameters self.w = torch.zeros(dim, 1, dtype=torch.float).to(device) self.b = torch.scalar_tensor(0).to(device) self.grads = {\u0026#34;dw\u0026#34;: torch.zeros(dim, 1, dtype=torch.float).to(device), \u0026#34;db\u0026#34;: torch.scalar_tensor(0).to(device)} self.lr = lr.to(device) def forward(self, x): ## compute forward z = torch.mm(self.w.T, x) a = self.sigmoid(z) return a def sigmoid(self, z): return 1/ (1 + torch.exp(-z)) def backward(self, x, yhat, y): ## compute backward self.grads[\u0026#34;dw\u0026#34;] = (1/x.shape[1]) * torch.mm(x, (yhat - y).T) self.grads[\u0026#34;db\u0026#34;] = (1/x.shape[1]) * torch.sum(yhat - y) def optimize(self): ## optimization step self.w = self.w - self.lr * self.grads[\u0026#34;dw\u0026#34;] self.b = self.b - self.lr * self.grads[\u0026#34;db\u0026#34;] "},{"id":36,"href":"/posts/2023-11-16-TF-IDF-Implement/","title":"Ranked Retreival 모델 구현(TF-IDF)","section":"Blog","content":"우선, 시작하기에 앞서 corpus 구성을 확인했다.\n한글로 작성되었으며, 제목과 문서 내용으로 구성되어있는 것을 확인했다.\n일단 데이터를 처리하기 위해 코드에서 파일을 열어야 하는데, 문서가 한글파일로 제공되었기 때문에 한글 문서를 txt 문서로 변환해주었다.\n{: w=\u0026ldquo;200\u0026rdquo; h=\u0026ldquo;100\u0026rdquo; }\n언어는 파이썬을 선택했다.\n처음 프로젝트를 시작했을 때, 나는 colab 환경에서 파이썬 코드를 실행시키고자 했으므로 Google Drive에 corpus 파일을 업로드하고, 코드 작성을 시작했다.\n수업 내용에서는 영어를 기준으로 다뤄왔었는데 한글을 토큰화하는 방법이 떠오르지 않았다.\n다행스럽게도 한글 형태소 분석 라이브러리 Konlpy가 있어서 이를 활용하고자 했다.\n하지만 해당 Konlpy 라이브러리가 자바를 기반으로 짜여졌고, 파이썬으로 wrapping한 채로 사용하는 방식이었다.\n해당 라이브러리를 사용하기 위해서는 라이브러리에서 지원하는 파이썬 버전과 자바 버전이 일치해야 했다.\n코랩 환경에서 해당 라이브러리를 사용하기 위해 수많은 블로그를 탐색하고, 깃허브 라이브러리 페이지를 방문하여 issue를 살펴봤었지만 해당 문제는 쉽사리 해결되지 않았다.\n그래서 거의 포기하고 직접 문서의 조사를 제거하여 활용하고자 마음 먹고 작업을 수행했다.\n하지만 결국 이 과정은 학습에 도움이 되지 않는다고 판단해 colab 환경을 pycharm 환경으로 바꿔서 다시 한번 해보자고 마음먹었고, 시행착오 끝에 라이브러리를 사용할 수 있게 되었다.\n라이브러리 활용을 포기하고 직접 문서의 단어를 추출하고 있었다.\nGoogle Colaboratory\n한글 단어를 직접 추출하던 코드다. 나의 고통의 흔적이 보인다.\n라이브러리 실행을 성공시킨 마지막 명령어.\nJPype1.1.2와 JPype3-1, Python 3.6, Python 3.7, Python 3.10의 조합을 활용해보았고, 실행되지 않았다.\n하지만 결국 위 사진에서 보이듯이, JPype1의 1.4.0 버전과 python 3.9.5 버전을 활용하여 성공했다.\n아래는 내가 문제를 해결하는 데 도움을 받은 글이다.\nhttps://blog.naver.com/myincizor/221624979283\nhttps://ingu627.github.io/tips/install_konlpy/\n검색엔진 코드 작성\n이후 검색엔진의 코드를 작성하는 것은 어렵지 않았는데, 다만 강의 내용을 완벽히 이해하고 있어야 코드를 수월하게 짤 수 있는 것 같다.\n수업에서 배운 대로 tf-idf Weighting을 기준으로 문서의 순서를 매기고, 쿼리를 입력받았을 때 Score가 높은 순서대로 결과를 보여주고자 했다.\n이를 구현 순서대로 나열하면 다음과 같다.\n1. corpus 파일 읽기: open()함수 활용\r#\rfile = open(\u0026#34;corpus.txt\u0026#34;, \u0026#39;r\u0026#39;, encoding=\u0026#39;UTF8\u0026#39;) corpus = file.readlines() corpus = [line[:-1] for line in corpus if line != \u0026#34;\\n\u0026#34;] corpus 2. corpus를 dictionary에 {key: 제목, value: 문서내용 }으로 저장하기.\r#\r해당 부분은 문자열 패턴을 추출하고 검사하는 re 라이브러리를 활용하여 비교적 쉽게 수행할 수 있다.\n해당 지점을 수행하며 기타 오탈자의 존재를 파악했으며 (ex: \u0026lt;title\u0026gt;~~~\u0026lt;title\u0026gt;)\n특이 사항으로 하나의 제목으로 두 개의 문서 내용을 가진 경우가 있었다.\n해당 부분을 처리해주기 위해 dictionary에서 value를 바로 문서 내용으로 하지 않고, 리스트로 만들어서 extend()함수를 통해 두 문서 내용을 이어 붙였다.\nfor line in corpus: if re.match(\u0026#34;\u0026lt;title\u0026gt;\u0026#34;, line): line = re.sub(\u0026#39;\u0026lt;title\u0026gt;\\d+. |\u0026lt;/title\u0026gt;|\u0026lt;title\u0026gt;|\\d+.\u0026#39;, \u0026#39;\u0026#39;, line) # line = line.replace(\u0026#39;\u0026lt;title\u0026gt;\u0026#39;, \u0026#39;\u0026#39;).replace(\u0026#39;\u0026lt;/title\u0026gt;\u0026#39;,\u0026#39;\u0026#39;) key = line # print(key) dic[key] = [] # value에 해당하는 리스트를 만들어주기. continue else: line = re.sub(\u0026#39;\\xa0\u0026#39;, \u0026#39; \u0026#39;, line) # print(line) dic[key].append(line) # value 리스트에 문서 내용 담기. for doc in dic.values(): if len(doc) != 1: doc[0] += doc[1] doc.pop() 3. 문서별 term frequency 구하기\r#\r문서에 포함되는 단어들의 term frequency를 구해야 했다.\n우선 단어의 빈도는 okt 라이브러리를 활용해서 쉽게 구할 수 있었다.\nfor doc in dic.values(): doc_term = dict(Counter(okt.nouns(doc[0]))) 이후, 해당 raw term frequency들을 log frequency weighting으로 바꿔주기 위해 함수를 선언했다.\n$$ w_{t, d}=\\left{\\begin{array}{cc}1+\\log {10} \\mathrm{tf}{t, d}, \u0026amp; \\text { if } \\mathrm{tf}_{t, d}\u0026gt;0 \\0, \u0026amp; \\text { otherwise }\\end{array}\\right. $$\n단어의 빈도가 크지 않기 때문에, 나는 log의 base를 2로 설정했다.\ndef lf_weighting(x): if x: return round(1 + math.log(x, **2**), 4) # 소수점 넷째에서 반올림을 수행했다. else: return 0 이후 map 함수를 활용하여 모든 tf 값들을 lf_weighting 값으로 변경해주었다.\nfor doc in dic.values(): doc_term = dict(Counter(okt.nouns(doc[0]))) tf_raw = list(doc_term.values()) tf = list(map(lf_weighting, tf_raw)) 4. 단어의 idf 구하기\r#\r문서에 포함되는 단어들이 문서를 구분하는 데 얼마나 영향력이 있는지 판별하기 위해 idf를 계산해야 한다.\n아래 내용은 내 강의 노트의 일부분을 가져왔다.\n📌 idf weight\n$df_{term}$는 term를 포함하는 문서의 빈도이다.\n우리는 df가 작은 term의 점수를 더 높게 주고 싶기 때문에, df을 뒤집어서 분모로 사용하자.\nidf(inverse document frequency)\n$idf_t=log_{10}(N/df_t)$\nN = 전체 document 수\nidf값을 완화 시키기 위해 log를 취해준다.\nlog의 base가 꼭 10일 필요는 없다.\n우선 lf_weight와 마찬가지로 idf를 계산하기 위한 함수를 선언해주었다.\ndef idf_cal(x): return round(math.log(N / x, 2), 4) 단어의 idf를 구하기 위해, 단어가 전체 문서 중 몇 개의 문서에 포함 되는지 알아야 하는데, 해당 부분은 다음과 같은 과정으로 수행됐다.\ncorpus 전체 내용에서 okt를 통해 단어를 추출하고, 중복 단어를 제거하여 단어 목록을 만든다.\nwords = [] for doc in dic.values(): doc_term = dict(Counter(okt.nouns(doc[0]))) words.extend(list(doc_term)) df = {} words = set(words) # print(words) 단어 목록에서 단어마다 몇 개의 문서에 포함 되는지 확인한다.\nfor w in words: count = 0 for doc in dic.values(): if w in doc[0]: count += 1 df[w] = count df = dict(sorted(df.items(), key=lambda x: x[1], reverse=True)) 단어마다 포함되는 문서의 개수를 dictionary에 저장한 후, 해당 값을 idf로 변환한다.\ndf_raw = list(df.values()) idf = list(map(idf_cal, df_raw)) 나중에 단어의 idf를 탐색하기 위해 idf list를 dictionary 형태{key: word, value: idf}로 저장한다.\ni = 0 for key in df: df[key] = idf[i] i += 1 word_idf = dict(sorted(df.items(), key=lambda x: x[1], reverse=True)) 5. 문서의 tf-idf Weight 계산하기.\r#\r📌 tf-idf weighting\nterm의 tf-idf 가중치는 tf 가중치와 idf 가중치의 곱이다.\n$$ W_{t,d}=(1+log_{10}tf_{t,d}) \\times log_{10}(N/df_t) $$\nIR에서 가장 핵심적인 가중치 공식이다.\ntf.idf나 tf x idf라고 부르기도 한다.\n가중치는 collection에서 term의 발생 빈도에 따라 증가한다.\n가중치는 컬렉션 내에 term이 희귀할수록 증가한다.\n이제 거의 다 왔다. 그저 문서 각각에 포함된 단어별 tf 값에, 해당 단어를 word-idf 사전에 검색하여 값을 곱해주기만 하면 된다.\nfor doc in dic.values(): for word in doc[1].keys(): doc[1][word] = round(word_idf[word] * doc[1][word], 4) # print(doc[1]) 이제 인덱싱은 완료되었으니, Query를 입력 받고 score를 계산하기만 하면 된다.\n6. query 입력 창 구현하기\r#\rwhile (1): query = input(\u0026#34;Enter Your Query:\u0026#34;) print(\u0026#34;query: \u0026#34; + query) query_term = okt.nouns(query) print(query_term) 7. Score 계산하기\r#\r$$ \\operatorname{Score}(q, d)=\\sum_{t \\in q\\urcorner d} t f . i d f_{t, d} $$\n위 수식은 q(query)와 d(document)에서 공통되는 term을 가진 document의 score만 계산한다는 의미이다.\nscore 계산은 위 수식처럼, 쿼리에 포함되는 단어 중 문서에 포함된 단어의 tf-idf를 더하면 된다.\nfor doc in dic.values(): score = 0 for q in query_term: for word in doc[1].keys(): if word == q: score += doc[1][word] if len(doc) == 2: doc.append(score) else: doc[2] = score 8. 문서의 Score가 높은 순서대로 보여주기\r#\rfin_dic = sorted(dic.items(), key=lambda x: x[1][2], reverse=True) i = 0 for result in fin_dic: if i \u0026gt;= OUT: break i += 1 if result[1][2]: print(i, result) else: print(i, \u0026#34;검색 결과가 없습니다.\u0026#34;) "},{"id":37,"href":"/posts/2023-05-22-SG/","title":"SG: Skip-Gram","section":"Blog","content":" Word2Vec을 학습하는 방법 중 하나.\nCBOW가 뒤집어진 모델\nCBOW와 입력층과 출력층이 반대로 구성되어 있다.\n벡터의 평균을 구하는 과정이 없다.\nCBOW보다 성능이 좋다고 알려져있다.\n참고로 이 때의 성능은 학습 과정의 Loss가 아니라 임베딩 벡터의 표현력을 의미한다.\nCBOW와 마찬가지로 Multi-Classification Model에 해당한다.\n"},{"id":38,"href":"/posts/2023-05-22-SGNS/","title":"SGNS: Skip-Gram with Negative Sampling","section":"Blog","content":"SG를 이진 분류 문제로 바꾼 모델\nNegative Sampling\r#\r주변 단어가 아닌 단어를 Label 0으로 Sample에 포함시키는 것\nNegative Sampling의 개수는 하이퍼파라미터에 해당한다.\n학습 데이터가 적은 경우 5-20, 충분히 큰 경우 2-5가 적당하다. positive sample 하나당 k개 샘플링 중심 단어와 주변 단어가 각각 임베딩 벡터를 따로 가진다.\nSGNS에서 embedding을 두 개로 나누어 사용하는 이유 만약 input/output 혹은 word/context representation을 동일한 값으로 사용한다고 하면,\n특정 단어, 가령 \u0026ldquo;dog\u0026quot;에 대해 P(dog|dog)가 현실적으로는 불가하지만 (한 문장에 \u0026ldquo;dog dog\u0026quot;를 연속으로 쓸 일은 없으니..) word2vec 모델 상으로는 높은 값을 뱉어낼 수 밖에 없습니다.\n이러한 언어의 특수성을 통해 유추해보건대, 문장 내에서는 하나의 단어가 중심 단어의 역할을 할 때와 주변(맥락) 단어의 역할을 할 때에 서로 다른 표현력(representation power)을 가지는 것이 아닐까 싶습니다.\n해당 stackoverflow 답변에서 혹자는 “\u0026lsquo;문장 내 단어 간 유사도/거리\u0026rsquo;를 측정할 때 하나의 벡터 공간만을 사용하게 되면 결국 그냥 두 단어 임베딩 간의 유사도/거리를 측정하는 것과 별반 다르지 않기 때문에 문장의 문맥을 담을 수 없다”는 식으로 설명하는데, 이 또한 비슷한 맥락이라고 볼 수 있을 것 같습니다.\n학습 과정\r#\r중심 단어를 기준으로 주변 단어들과의 내적 연산 수행\n실수 내적값에 sigmoid을 취하여 예측값을 구한다.\n예측값과 레이블(0,1)의 오차를 구한다.\n역전파(backpropagation)를 통해 각 임베딩이 갱신되며 모델이 수렴한다.\n이 때, 최종적으로 생성된 워드 임베딩이 2개이므로 선택적으로 하나만 사용하거나 평균내어 사용한다.\n"},{"id":39,"href":"/posts/2023-05-28-SVD-Singular-Value-Decomposition%ED%8A%B9%EC%9D%B4%EA%B0%92-%EB%B6%84%ED%95%B4/","title":"SVD: Singular Value Decomposition(특이값 분해)","section":"Blog","content":" 간단 요약\n2차원 행렬을 두 개의 잠재요인 행렬과 하나의 대각행렬로 분해하는 기법 {: .prompt-info } eigen vector, eigen value\n2차원 행렬 분해 기법 유저 잠재요인 행렬 ⇒ 유저 임베딩 잠재요인 대각행렬 ⇒ 임베딩의 중요도 아이템 잠재요인 행렬 ⇒ 아이템 임베딩 차원축소 기법 행렬을 대각화하는 방법 모든 m x n 행렬에 대해 적용 가능 Rating Matrix $R$ 에 대해 유저와 아이템의 잠재 요인을 포함할 수 있는 행렬로 분해한다.\nFull SVD\r#\r기존 행렬을 온전하게 3개의 행렬로 분해한다.\n$$ \\tt Full\\ \\ SVD :R = U\\Sigma V^T $$\n$U$: 유저와 Latent Factor의 관계\n$U$의 열벡터는 $R$의 left singular vector\n$V$: 아이템과 Latent Factor의 관계\n$V$의 열벡터는 $R$의 right singular vector\n$\\Sigma$: Latent Factor의 중요도\n$RR^T$을 고유값 분해해서 얻은 직사각 대각 행렬\n대각 원소들은 $R$의 singular value(특이치)\nTruncated SVD\r#\r$\\Sigma$를 일부만 사용한다.\n$$ \\tt Truncated \\ \\ SVD: R \\approx \\widehat{U} \\Sigma_k \\widehat{V^T}=\\hat{R} $$\n$\\Sigma$는 중요도로 정렬되어 있기 때문에, 상위 k개만 활용하여 기존의 행렬을 거의 유사하게 나타낼 수 있다.\n즉, 몇 개의 특이치만을 가지고도 유용한 정보를 유지한다.\n분해된 행렬이 부분 복원되면서 가장 중요한 정보로 요약된다.\n$\\widehat R$은 축소된 $\\widehat U, \\widehat {V^T}, \\Sigma_k$에 의해 계산된다.\n각각의 K개의 Latent Factor는 유추할 수 있을 뿐, 정확히 무엇을 의미하는지 알 수 없다.\nSVD의 한계\r#\r분해(Decomposition)하려는 행렬에 결측치가 없어야 한다.\nUser-Item 행렬의 경우 모든 값이 채워져야 한다.\nSparsity가 높은 데이터의 경우 결측치가 매우 많다.\n실제 데이터는 대부분 Sparse Matrix\nImputation 후 SVD를 수행 → Computation 비용 증가\nImputation은 데이터의 양을 상당히 증가시키기 때문\nImputation에 의해 데이터 왜곡 발생 시 성능 저하\n행렬의 entry가 매우 적을 때 SVD를 적용하면 과적합 되기 쉽다.\n참고하면 좋은 자료 \u0026ndash; SVD의 의미\n"},{"id":40,"href":"/posts/2023-11-01-Taylor-Polynomials/","title":"Taylor polynomials","section":"Blog","content":"\r테일러 근사\r#\r복잡한 형태의 미분 가능한 함수 $f(x)$를 다항식의 합으로 근사하는 것\n$a$를 포함하는 구간에서 함수 $f$가 무한 미분이 가능 할 때\n$$ \\begin{aligned}f(x) \u0026amp; =\\sum_{n=0}^{\\infty} \\frac{f^{(n)}(a)}{n !}(x-a)^n \\\u0026amp; =f(a)+\\frac{f^{\\prime}(a)}{1 !}(x-a)+\\frac{f^{\\prime \\prime}(a)}{2 !}(x-a)^2+\\frac{f^{\\prime \\prime \\prime}(a)}{3 !}(x-a)^3+\\ldots\\end{aligned} $$\n를 테일러 급수라고 한다.\n$f(x)$를 임의의 수 $a$에 대해 정리하는 과정이라 이해하면 편하다.\n수식이 이렇게 생긴 이유\n$f(x)$를 $a$에 대해 정리하고 싶어 식을 $f(x) = t_n(x-a)^n + t_{n-1}(x-a)^{n-1 }+\\dots + t_1(x-a)^1$와 같이 정의했을 때,\n$f^{(n)}$은 $f(x)$를 n번 미분하면서 나머지 모든 항이 날아가고 n차항만 남게 된다.\n또한, 미분 과정에서 차수는 계수에 곱해진다.\n$f^{(n)}(1) = t_1 \\times n!$\n우리는 원래 식의 계수인 $t_n,\u0026hellip;,t_1$을 원하기 때문에, $n!$으로 다시 나눠준다.\n예제를 통해 다시 한 번 살펴보자.\n$f(x) = 7x^3 - 18x^2 + 20x - 1$라고 할 때, $x=1$에 대해 테일러 급수를 적용해보자.\n$x=1$에서의 함수값, 미분값, 이차 미분 값 등을 구해보면\n$f(1) = 8$ $f\u0026rsquo;(1) = 5$ $f\u0026rsquo;\u0026rsquo;(1) = 6$ $f\u0026rsquo;\u0026rsquo;\u0026rsquo;(1) = 42$ 과 같다.\n각 미분값에 $\\tt(미분 차수)!$으로 나눠주면 우리가 원하는 계수를 구할 수 있다.\n$$ f(x) = 7(x-1)^3 + 3(x-1)^2 + 5(x-1) + 8 $$\n$f(x)$는 위처럼 생겼는데, 해당 식에 다시 미분을 해보면 그대로 일치하는 것을 확인할 수 있다.\n곡선은 무엇에 의해 정의될까?\n탄젠트(미분), 곡률(2차 미분), torsion(비틀림, 3차 미분)\n즉, 곡선을 제대로 근사하기 위해선 적어도 3차 미분까지 근사를 해야 한다.\n수학적으로는 무한하게 미분 가능하다고 정의하지만, 수치 해석에서는 절단 오차 개념을 도입하여 적정 수준까지만 항을 정의한다.\n테일러 급수를 활용하여 특수한 값 $a$의 $f(a), f\u0026rsquo;(a), f\u0026rsquo;\u0026rsquo;(a), \\dots$를 활용하여 $a$ 주변의 값을 근사한다.\n테일러 급수는 $x$가 $a$에서 멀어질수록 오차가 커진다.\n이렇게, $a$지점에서 근사한 $n$차 테일러 다항식을 $p_n(x ; a)$로 표기한다.\n테일러 근사의 오차\r#\r$f(x)$에 대한 테일러 근사를 효율적으로 사용하려면 정확도를 계산하는 과정이 필요하다.\n테일러 급수로 $n$차까지 근사한 식 $p_n(x)$과 원본 식$f(x)$의 오차를 구해보자.\n$$ R_n(x) = f(x) - p_n(x) $$\n원본 식은 무한대로 미분이 가능할 수도 있지만, 만약 $n+1$차까지만 미분이 가능하다면?\n원본 식과 근사식의 오차는\n$$ R_n(x) = {f^{(n+1)}(a)\\over(n+1)!}(x-a)^{n+1} $$\n가 되고, $R_n(x)$는\n코시의 평균값 정리에 의해\n$$ {f^{(n+1)}(a)\\over(n+1)!}(x-a)^{n+1}\u0026lt;R_n(cx) \u0026lt; {f^{(n+1)}(x)\\over(n+1)!}(x-a)^{n+1} $$\n을 만족한다.\nPolynomial form\r#\rPower form\r#\r선형 결합 형태\n$$ p_n=a_0+a_1 x+a_2 x^2+\\cdots+a_n x^n=\\sum_{k=0}^n a_k x^k $$\nShifted Power form\r#\r$c$가 중심이 되는 다항식\n$$ p_n=b_0+b_1(x-c)+b_2(x-c)^2+\\cdots+b_n(x-c)^n $$\nTaylor form(Taylor Polynomial)\r#\rshifted power form에서의 계수가 $b_k=\\frac{p_n^{(k)}(c)}{k !}$인 경우\n$$ p_n(x)=p_n(c)+(x-c) p_n^{\\prime}(c)+\\frac{(x-c)^2}{2 !} p_n^{\\prime \\prime}(c)+\\cdots+\\frac{(x-c)^n}{n!} p_n^{(n)}(c) $$\nNewton form\r#\r중심이 $c_1,c_2,\u0026hellip;,c_n$인 경우\n$$ \\begin{matrix}p_n\u0026amp;=\u0026amp;d_0+d_1\\left(x-c_1\\right)+d_2\\left(x-c_1\\right)\\left(x-c_2\\right)\\\u0026amp;\u0026amp;+\\cdots+d_n\\left(x-c_1\\right) \\ldots\\left(x-c_n\\right)\\\\ \u0026amp;=\u0026amp;d_0+\\sum_{k=1}^n d_k \\prod_{j=1}^k\\left(x-c_j\\right) \\end{matrix} $$\nnewton form에서 $c_1=\\cdots=c_n=c$로 설정하면 shifted power form이 되고, $c_1=\\cdots=c_n=0$이면 power form이 된다.\nNested form(Honer’s method)\r#\r$$ \\begin{aligned}p(x) \u0026amp; =a_0+a_1 x+a_2 x^2+a_3 x^3+\\cdots+a_n x^n \\\u0026amp; =a_0+x\\left(a_1+x\\left(a_2+x\\left(a_3+\\cdots+x\\left(a_{n-1}+x a_n\\right) \\cdots\\right)\\right)\\right)\\end{aligned} $$\nPolynomial evaluation\r#\r수치 해석은 함수를 정확하게 근사해내는 목적이 있다.\n이를 위해 테일러 급수를 활용한다.\n테일러 급수를 통해 함수의 모양을 비슷하게 따르더라도, 값이 동일한지를 체크하기 위해 반드시 오차값을 구해야 한다.\n우리가 사용하는 대부분의 기계는 Taylor 분석을 통한 근사로 만들어진다.\n근사의 속도를 측정하는 방법\n나머지 정리 조립 제법 프로그래머 관점으로 다항식을 평가하자.\n수식 계산에서 곱셈 연산이 꽤 무겁기 때문에, 곱셈 횟수를 최대한 줄여야 한다.\n$p(x) = a_0 + a_1x + a_2x^2 + \u0026hellip; + a_nx^n$에서 $a_0,a_1,\u0026hellip;,a_n$과 $x$가 주어지는 경우 다항식을 계산하기 위해 몇 번의 곱셈이 필요한가?\nex) $p(x) = 3 - 4x -5x^2 - 6x^3 + 7x^4 - 8x^5$\r#\r위의 5차 다항식을 직관적으로 계산하면 총 15번의 곱셈이 필요하다.\n$4\\times x$ ⇒ 1\n$5\\times x\\times x$ ⇒ 2\n$\\cdots$\n총 곱셈의 개수: ${n(n+1)\\over 2}$ ⇒ $O(n^2)$\n어떻게 다항식을 더 효율적으로 평가할 수 있을까? ⇒ 중복 계산을 최소화하자.\n$x^3$을 계산할 때, $x\\times x\\times x$로 계산하는 것이 아니라, 기존에 계산된 $x^2$를 활용하여 $x\\times x^2$를 계산하게 되면 곱셈 개수를 줄일 수 있다.\n$4 \\times x$ ⇒ 1\n$5\\times x\\times x$ ⇒ 2\n$6 \\times x \\times x^2$ ⇒ 2\n$\\cdots$\n총 곱셈의 개수: $2n -1$ ⇒ $O(n)$\n메모이제이션을 적용하면 $O(N)$이 된다.\n메모이제이션을 적용했을 때의 단점으로는, 순서가 발생하기 때문에 병렬 계산이 안된다.\nload balancing을 없애며 병렬 계산을 하는 것이 가장 중요하다.\n호너의 법칙을 활용하면 총 곱셈의 개수가 **$n$**으로 줄어든다.\n"},{"id":41,"href":"/posts/2023-09-19-Tensor/","title":"Tensor에 대해 알아보자.","section":"Blog","content":" 간단 요약\nautograd 연산을 지원하는 다차원 배열\ntensor에 대한 미분값을 가진다.\nreshape보다 view를 쓰는 것이 좋다. squeeze와 unsqueeze의 차이 mm, dot, matmul 차이\n{: .prompt-info } 신경망의 가중치(매개변수)를 텐서로 표현한다.\n다차원 Arrays를 표현하는 PyTorch 클래스\nnumpy의 ndarray와 호환된다.\nTensorFlow의 Tensor와도 동일\nTensor을 생성하는 함수도 거의 동일\nnumpy — ndarray\nimport numpy as np n_array = np.arange(10).reshape(2,5) print(n_array) print(\u0026#34;n_dim :\u0026#34;, n_array.ndim, \u0026#34;shape :\u0026#34;, n_array.shape) pytorch — tensor\nimport torch t_array = torch.FloatTensor(n_array) print(t_array) print(\u0026#34;n_dim :\u0026#34;, t_array.ndim, \u0026#34;shape :\u0026#34;, t_array.shape) list나 ndarray를 Tensor로 변환할 수 있다.\n데이터 타입은 numpy와 동일하다.\nGPU에 올려 사용이 가능하다.\nx_data.device # device(type=\u0026#39;cpu\u0026#39;) if torch.cuda.is_available(): x_data_cuda = x_data.to(\u0026#39;cuda\u0026#39;) x_data_cuda.device # device(type=\u0026#39;cuda\u0026#39;, index=0) view, squeeze, unsqueeze 등으로 tensor 조정이 가능하다.\nview: reshape와 동일하게 tensor의 shape를 변환한다.\nview와 reshape의 차이: contiguity(접근) 보장 여부\nview의 경우 클래스로의 접근을 계속 보장해주지만, reshape는 접근을 보장해주지 않는다.\n만약 접근을 보장할 수 없는 경우 copy를 해버린다.\nsqueeze: 차원의 개수가 1인 차원을 삭제한다. (압축)\nimport torch x = torch.rand(1, 1, 20, 128) x = x.squeeze() # [1, 1, 20, 128] -\u0026gt; [20, 128] x2 = torch.rand(1, 1, 20, 128) x2 = x2.squeeze(dim=1) # [1, 1, 20, 128] -\u0026gt; [1, 20, 128] unsqueeze: 차원의 개수가 1인 차원을 추가한다.\n추가할 위치를 지정해주어야 한다.\nimport torch x = torch.rand(3, 20, 128) x = x.unsqueeze(dim=1) #[3, 20, 128] -\u0026gt; [3, 1, 20, 128] 다른 기본적인 연산은 Tensor와 Numpy가 거의 동일하다.\ndot, mm, matmul 차이\r#\rdot : 내적 연산.\nmm : 행렬 곱셈 (벡터 연산 지원 x).\n행렬곱셈 연산이 Tensor에서는 dot 대신 mm(matrix multiplication)으로 표기된다.\nmatmul : 알아서 broadcasting을 지원해준다.\n쉽게 연산해준다는 장점이 있지만, 오히려 결과를 헷갈리게 만드는 단점이 있다.\nTensor의 구조\r#\r1차원: iris 샘플 하나 2차원: iris 샘플 여러 개, 명암 영상 한 장 3차원: 명암 영상 여러 장, 컬러 영상 한 장 4차원: 컬러 영상 여러 장, 컬러 동영상 하나 5차원: 컬러 동영상 여러 개 "},{"id":42,"href":"/posts/2023-05-26-WDN-Wide-Deep-Network/","title":"WDN: Wide \u0026 Deep Network","section":"Blog","content":"Wide \u0026amp; Deep Learning for Recommender Systems\n선형적인 모델(Wide)과 비선형적인 모델(Deep)을 결합하여 기존 모델들의 장점을 모두 취하고자 한 논문\n등장 배경\r#\r추천시스템에서 해결해야 할 두 가지 과제\nMemorization — 학습데이터에 자주 등장하는 패턴은 모델이 암기해야 한다.\n함께 빈번히 등장하는 아이템 혹은 특성(feature) 관계를 과거 데이터로부터 학습하는 것\nLogistic Regression과 같은 선형 모델\n대규모 추천 시스템 및 검색 엔진에서 사용해왔다. 확장 및 해석이 용이하다. 학습 데이터에 없는 feature 조합에 취약하다. Generalization — 학습데이터에 발생하지 않는 패턴을 적절하게 표현해야 한다.\n드물게 발생하거나 전혀 발생한 적 없는 아이템/특성 조합을 기존 관계로부터 발견하는 것\nFM, DNN과 같은 임베딩 기반 모델\n일반화가 가능하다. 고차원의 Sparse 데이터로 임베딩을 만들기가 어렵다. 이 둘을 결합하여 사용자의 검색 쿼리에 맞는 앱을 추천하는 모델을 제안한다.\n모델 구조\r#\rWide(Memorization Model)\r#\r선형 모델과 거의 비슷한 모델\nGeneralized Linear Model\n$\\tt y = w^Tx + b$\n${\\tt w = [w_1,\u0026hellip;,w_n]}$ $\\tt x = [x_1,\u0026hellip;,x_n]$ $b \\in \\R$ 이와 같은 구조만으로는 두 변수의 관계를 파악할 수 없다.\nCross-Product Transformation\n서로다른 두 변수의 관계를 학습하기 위해 Cross-Product Term을 추가해준다.\n$$ \\tt \\phi_k(x) = \\Pi^d_{i=1}x_i^{c_{ki}}, \\quad c_{ki} \\in {0,1} $$\n이 때, 가능한 모든 변수들 간의 내적을 표현하면 학습해야 할 파라미터가 너무 많아지게 된다.\n따라서, 해당 모델에서는 주요 feature 2개에 대한 second-order Cross Product만 사용한다.\n위의 모델링은 Polynomial Logistic Regression과 거의 동일하다.\n$$ \\hat y(x)=\\left(w_0+\\sum_{i=1}^n w_i x_i{+\\sum_{i=1}^n \\sum_{j=i+1}^n w_{i j} x_i x_j}\\right), \\quad w_i, w_{i j} \\in \\mathbb{R} $$\n이 모델로는 $n^2$만큼 학습 파라미터가 늘어나게 된다.\n즉, Wide Component만으로는 표현할 수 있는 상호작용의 한계가 명확하다.\nDeep(Generalization Model)\r#\r단순한 구조.\nFeed-Forward Neural Network\n3 layer로 구성되었으며, ReLU 함수를 사용\n연속형 변수는 그대로 사용하고, 카테고리형 변수는 피쳐 임베딩 후 사용\n전체 구조 및 손실 함수\r#\r$$ P(Y=1|x) = \\tt\\sigma(w^T_{wide}[x,\\phi(x)] + w^T_{deep}a^{(lf)} + b) $$\n$\\tt x:$ 주어진 n개의 변수\n$\\tt \\phi(x):$ n개 변수간의 상호작용(Cross-Product)\n위에서 언급한 것처럼, [사용자가 과거에 설치한 앱]과 [사용자가 현재 CTR을 예측할 앱]의 상호작용만 반영한다.\n모델 성능\r#\rBaseline인 Wide 모델과 Deep 모델은 각각 Offline, Online에서 서로 다른 양상을 보이지만, 두 개 모델을 결합하여 만든 Wide \u0026amp; Deep 모델은 모두 좋은 성능을 보였다.\n"},{"id":43,"href":"/posts/2023-09-23-%EC%88%98%EC%B9%98-%EB%AF%B8%EB%B6%84/","title":"경사 하강법에 오차 역전파가 없다면 무슨 일이 일어날까?","section":"Blog","content":" 손실 함수, Gradient Descent, Back Propagation\n수치 미분\r#\r한 점에서의 기울기. 변화량을 의미한다.\n경사 하강법을 사용하기 위해서는 미분값이 필요하다.\n$$ {df(x)\\over dx} = \\lim_{h \\to 0} {f(x+h) - f(x)\\over h} $$\n수치 미분이 경사 하강법에 사용되는 방법\r#\r경사 하강법에서는 $f(x)$가 손실 함수이고, x가 현재의 가중치나 편향이 된다.\n손실 함수는 대상 값과 예측 값의 오차를 의미하므로,\n손실 함수에 대한 미분 값을 구한 후, 오차를 줄이는 방향으로 가중치와 편향을 수정할 수 있다. 쉽게 납득이 가능한 과정을 굳이 숫자까지 붙여가며 나눈 이유가 있다.\n이 과정에서는 치명적인 문제가 존재한다.\n위의 미분 값 공식을 자세히 살펴보자.\n경사 하강법에서는 $f(x)$가 손실 함수를 의미하는데, 손실 함수는 예측 값과 목표 값의 오류를 의미한다.\n또한 x는 현재의 가중치나 bias를 의미한다.\n즉, $f(x)$를 계산하기 위해서는 신경망이 예측을 한 번 수행하고, 목표 값과의 차이를 계산해야 한다.\n여기까지만 하더라도 계산이 상당히 크다는 것을 짐작할 수 있으나, 미분 값을 구하기 위해서는\n$f(x), f(x + h)$를 구해야 하므로, 두 지점에서 신경망의 예측이 필요하다.\n요약하면, 단 하나의 가중치를 계산하는 데 신경망이 두 번이나 동작한다.\n하나의 epoch에 가중치 하나, bias 하나가 있다고 생각하면, 학습을 위한 망 계산은 총 4번이 된다.\n아무리 단순한 모델을 구성하더라도, 연산량이 너무 많다.\nex) layer 3층, 은닉층 노드 10개, epoch 1000인 경우\n가중치 뭉치 3개, 편차 3개 존재\n(4 * 3) * 1000 = 12,000번의 신경망 예측.\n수치 미분은 속도가 너무 느리다.\n이를 보완하기 위해 오류 역전파 알고리즘이 등장했다.\n오류 역전파 알고리즘은 위와 같은 상황에서 신경망이 단 두 번만 동작하여 한 번의 가중치 학습을 완료한다.\n즉, 위의 예시에서 오류 역전파를 사용하면 총 2000번의 망 계산만 필요하다.\n"},{"id":44,"href":"/posts/2023-08-15-%EB%84%A4%EC%9D%B4%EB%B2%84-%EB%B6%80%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%94%84-AI-Tech-%ED%9A%8C%EA%B3%A0-1-%EA%B0%95%EC%9D%98-%EB%8C%80%ED%9A%8C/","title":"네이버 부스트캠프 AI Tech 회고 1 — 강의, 대회","section":"Blog","content":"\r{: lqip=\u0026quot;/imgs/boostcamp_logo.png\u0026quot; }\n드디어! 최종 프로젝트를 제출하면서, 길고 길었던 부스트캠프 AI Tech 5기의 모든 일정이 종료됐다.\n부스트캠프 전체에 대한 회고도 하면서, 기업연계 프로젝트에 대한 회고도 담아보고자 한다.\n처음에는 하나의 포스트로 작성했는데, 쓰다보니 너무 길어져 구분하여 글을 작성했다.\n왜 부스트캠프 추천 트랙에 지원했나?\r#\rAI 부스트캠프 지원자를 모집할 당시(22년 하반기), 나는 카카오 DS 최종면접을 준비하고 있었다.\n1년간 통계학과와 수학과를 넘나들며 나름 AI의 수학적 지식기반을 쌓았(다고 생각했)고, 여러 경진대회를 경험하고 AI 관련 과목을 수강하면서 점점 자신감이 차오르던 시기였다.\n해당 시점에 채용 프로세스를 미리 경험해보자는 취지에서 졸업은 염두에 두지 않은 채로 카카오 공채에 지원했다. ML 응용분석과 추천시스템 직무중 선택해서 지원할 수 있었는데, 나는 이 때 처음으로 추천시스템이라는 용어를 접했다.\n이후, 카카오 최종면접에서도 추천시스템과 관련된 질문이 들어왔으나 제대로 대답하지 못했다.\n그 당시에는 별 생각 없이 지원했다가 최종 면접까지 올라가게 되며 점점 간절해졌었으나 실력이 많이 부족했다.\n나는 AI 개발자를 자처했지만, AI 모델은 유명한 라이브러리를 활용하여 가져다 쓰는 것이 전부였고, 모델의 구조에 대한 이해도 없었고, 모델을 직접 구현할 능력도 없었다.\n또한 대회 경험도 많지 않은 상태였고 수상 경력도 없었기 때문에 내세울 것이 전혀 없었다.\n심지어 면접때 질문으로 나왔던 추천시스템에 대해서는 금시초문이었다. 학교에서 배울 수도 없었기 때문에 부캠 AI Tech의 커리큘럼을 확인하고는 고민없이 바로 추천시스템을 선택했다.\n대회 경험을 채우고 모델을 직접 만들어 서비스에 포함하는 역량을 기르고 싶었으며, CV와 NLP는 배울 수 있는 방법이 많다고 생각했기 때문이다.\n부스트캠프를 참가하며 얻어가고자 했던 것 (지원 동기)\r#\r인맥 모델링 역량 추천 도메인 정보 습득 대회 경험 end-to-end ML 프로젝트 경험 Data Engineering 경험 Front / Backend 프레임워크에 익숙해지기 5번부터는 최종 프로젝트를 통해 얻어가고자 했던 것인데, 원하는 만큼 습득하지는 못한 것 같아 아쉬움이 있다.\n얻어가고자 하는 것을 부스트코스의 어떤 강의에서 배웠는지를 돌이켜보면, 내가 생각하는 최고의 강의도 쉽게 말할 수 있다.\n부스트캠프 AI Tech 강의 Best 3\r#\r1. Pytorch (최성철 마스터님)\r#\rPytorch 강의를 통해 모호하기만 했던 모델링 과정을 세부적으로 배울 수 있게 되었고, 이는 학습의 기반이 되어 이제는 논문에 언급된 모델의 구조를 보며 모델을 구현할 수 있게 되었다.\n부덕이와 함께하는 Pytorch 과제도 많은 도움이 됐다.\n개인적으로는 해당 강의를 통해 가장 크게 발전했다고 생각한다.\n2. Recsys (이준원 마스터님)\r#\rRecsys 강의에서는 추천 모델들의 발전 순서에 따라 핵심 개념들을 배우고, 큰 틀을 알려준다.\n또한 Recsys의 내용은 이후에 다른 강좌에서 몇 번이나 동일한 내용이 반복된다. 이 때부터 나도 그랬지만, 모두가 강의 정리를 힘들어했다. 이전 강의와 중복되는 내용이 많아 굳이 다시 정리해야 할까? 싶으면서도, 다른 내용이 꽤 많았기 때문에 기존에 정리한 내용을 잘 활용하는 것이 중요했다.\n즉, 연관 개념들이 끊임없이 가지치기가 되며 강의가 진행됐는데, 나는 Recsys 강의를 핵심 줄기로 삼아 이후의 강의 내용들을 추가하며 정리했다.\n내심 시간이 오래 지났을 때, 추천과 관련하여 기억에 남는 부분은 Recsys 강의의 흐름 뿐이라는 생각도 있기 때문에, 나는 Recsys 강의도 아주 마음에 들었다.\n3. Product Serving (변성윤 마스터님)\r#\r최종 프로젝트를 전개하는데 필요한 다양한 배경 지식을 얻을 수 있었던 강의.\n폭넓은 분야를 다루는 만큼 깊게 다루지는 않지만, 각 영역을 더 잘 배우고 활용할 수 있게 만들어준다. 해당 강의도 실력 향상에 크게 도움이 되었다.\n보통 이런 강의는 시간이 길어지고 지루해지기 정말 쉽지만, 아주 집약적으로 강의가 구성되어있다는 점이 인상 깊었다.\n다만 개인적으로는 강의 내용을 정리하기가 꽤 어려웠다. 변성윤 마스터님이 ppt에 광범위하게 적힌 내용을 세부적으로 반박하거나 보충하며 강의를 전개하는 경우가 종종 있기 때문인데, ppt 중심적으로 강의 내용을 정리하면 마스터님이 말하고자 하는 바가 제대로 담기지 않을 때가 있다.\n물론 강의 주제가 개념보다는 구현에 초점을 맞추었다는 점도 강의 내용 정리가 어려운 이유에 해당된다.\n대회 경험\r#\r대회 경험도 부스트캠프를 통해 얻을 수 있는 아주 큰 경험치이다.\n9주차부터 진행되는 세 번의 대회를 통해 배운 지식을 활용할 수 있었다.\n앞에선 언급한 Recsys 강의를 끝낸 직후, 배운 내용을 흡수할 수 있도록 대회를 진행한 것이 아주 마음에 들었다.\n세 번의 대회 모두 Baseline이 제공되었기 때문에, Pytorch로 모델이 구현될 때의 프로젝트 구조에 익숙해질 수 있었다.\n첫 번째 대회: 책 평점 예측\r#\r처음으로 수행하게 된 대회. 2주 동안 진행됐다.\n대회의 목표는 사용자의 책에 대한 평점을 예측하는 것인데, 단순히 유저-아이템 상호작용 정보 뿐만 아니라 책의 표지부터 책에 대한 다양한 정보가 함께 제공되기 때문에, CARs(맥락 기반 추천시스템)을 잘 활용해야 하는 대회였다.\n해당 대회를 통해 FM, FFM, WDN, DeepCoNN, GBDT 등 다양한 모델의 구조를 비교하고 이해할 수 있었다.\n평점별 점수 분포를 확인함으로써 각 모델의 예측이 얼마나 상이한 지를 파악할 수 있었고, 이는 앙상블을 수행할 때 큰 도움이 되었다.\n무엇보다, 모델들을 직접 구현하며 구름처럼 둥둥 떠다니던 Pytorch 강좌의 내용을 제대로 습득할 수 있었다.\n돌이켜보면 짧은 기간인 만큼 가장 집약적으로 수행한 대회라고 생각한다.\nPreprocess, Bagging, Boosting, ensemble, Stacking, Hybrid Model, Postprocess(min max 확인하기), Visualization, CV\n두 번째 대회: DKT\r#\r첫 번째 대회와 약간의 간격을 두고 진행된 두 번째 대회.\n사용자가 푼 문제 기록을 학습하여 특정 문제를 맞힐지, 틀릴지 예측하는 대회이다.\n순차 데이터셋으로 변경되면서 이전 대회에서 쓰던 모델의 대부분을 사용할 수 없었기 때문에 대회가 꽤 어렵게 느껴졌다.\n나는 해당 대회에서 데이터를 담당하여 전처리와 EDA를 통해 파생변수를 잔뜩 생성하고, 생성한 변수들에 대해 다양한 변수선택 기법과 차원축소 기법을 적용하여 LightGBM의 성능을 개선했다.\n비록 최종 앙상블에서 LGBM이 Transformer와 성능 차이가 심해 가중치를 많이 부여하지는 못했지만, 일반화 성능을 높이는 데 일조했다고 생각한다.\n세 번째 대회: Movie Rec\r#\r두번째 대회가 끝나자마자 진행된 마지막 대회.\n이전과 동일하게 영화 시청 기록을 학습하여 다음에 볼 영화를 예측(추천)하는 대회이다.\n다만 DKT와 다른 점은 마지막 영화만 예측하는 것이 아니라 중간 중간에 비어 있는 영화를 예측하는 것이 목표였다.\n팀원들의 면접 이슈도 있었고, 최종 프로젝트도 앞둔 상황이라 많이 집중하지는 못한 대회였으나, Recbole 라이브러리를 활용해본 것이 유의미했다.\n대회 후기\r#\r모델별로 예측 추이가 어떻게 다른지를 파악하는 것이 앙상블을 통한 성능 개선에 크게 도움이 되었다. 평가 메트릭을 다양하게 확인해도 좋고, 시각화가 가능하다면 추론 결과를 시각적으로 확인하여 분포의 차이를 확인하는 것도 유의미하다고 느껴졌다.\n또한, 파생 변수를 열심히 생성해내는 것보다 모델을 변경하거나 모델의 구조를 살짝 변경하는 것이 성능을 훨씬 크게 끌어올리는 경우도 많았기 때문에, 사용하는 모델을 정확히 이해하는 것이 중요했다.\n대회의 순위에 얽매이다 보면 강의에 소홀해지기가 쉬웠고, 순위가 높은 상태이거나 대회 기간이 4주일 때는 마음에 여유가 생겨 시간을 알뜰하게 쓰기가 어려웠다.\n무엇보다 강의가 대회 길라잡이처럼 구성되어있기 때문에 강의에서 언급되는 내용들을 최대한 활용하는 방향으로 대회를 진행하는 것이 훨씬 더 도움이 됐다.\n이후에 진행된 프로젝트는 다음 글에서 마저 후기를 작성하겠다.\n"},{"id":45,"href":"/posts/2023-09-04-%EB%84%A4%EC%9D%B4%EB%B2%84-%EB%B6%80%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%94%84-AI-Tech-%ED%9A%8C%EA%B3%A0-2-Upstage-%EA%B8%B0%EC%97%85%EC%97%B0%EA%B3%84-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/","title":"네이버 부스트캠프 AI Tech 회고 2 — Upstage 기업연계 프로젝트","section":"Blog","content":"\r최종 프로젝트는 변성윤 마스터님(유튜버 카일스쿨)의 Product Serving 강좌와 함께 진행됐다.\n내가 강의를 통해 최종 프로젝트의 흐름에 대해 정리한 바로는 AI를 활용하는 End-to-End 서비스를 구축하는 것이 1차 목표이고, 2차 목표로는 사용자 피드백을 받아 서비스를 개선하는 것이다.\n다만 우리 팀은 기업 연계 프로젝트를 진행하여 AI 활용 서비스를 개발하는 것에 초점을 두지 않았다.\n업스테이지 기업연계 프로젝트\r#\r전체 트랙에서 지원을 받아 최종적으로 뽑힌 팀이 기업이 제안한 주제로 프로젝트를 진행할 수 있다.\n지원 배경\r#\r기연프에 지원하기 위해선 팀원 모두가 기업에서 제안한 프로젝트 주제가 마음에 들어야 한다.\n우리 팀은 대화형 추천 시스템의 모니터링을 위한 interactive admin 페이지 (web) 개발 이라는 주제에 모두 동의하여 기업 연계 프로젝트를 신청했다.\n애초에 대화형 데이터셋을 활용하는 서비스를 계획하기도 했고, 우리 팀은 DA나 DS에 관심 있는 팀원이 많았기 때문에 아주 매력적인 선택지였다.\n게다가 팀 전원이 Looker Studio를 활용하여 대시보드를 만드는 법을 알고 있었기 때문에, 지원 기간 동안 대시보드 프로토타입을 완성하여 기연프 신청서에 함께 첨부했다.\n덕분에 원하는 대로 기업 연계 프로젝트를 진행할 수 있었다.\n기업 연계 프로젝트의 장점\r#\r1. 시니어 개발자에게 무한대의 질문 권한이 주어진다.\r#\r사실 나는 이 점 하나만 놓고 보더라도, 기업 연계의 메리트는 충분하다고 생각한다.\n프로젝트를 진행하며 모르는 점이나, 기술적으로 어려운 부분이 발생했을 경우 노션 페이지를 통해 바로 질문할 수 있도록 공간이 마련된다.\n이 장점은 후에 부스트캠프에서 진행하는 프로젝트 공개 멘토링 시간에 체감했었는데, 다른 팀들은 멘토링 1시간동안 질문을 통해 얻어가는 내용들을 우리 팀은 미리 다 들어서 알고 있었다.\n2. 두 번의 미팅 기회가 제공된다.\r#\r한 번은 상견례이고 한 번은 멘토링이지만, 서로 얼굴 맞대고 원하는 질문을 공유할 수 있는 자리라는 점에서, 상견례 또한 많은 정보를 얻을 수 있다.\n단, 상견례를 진행하기 전에 구체적인 질문을 많이 준비해가야 더 많은 답변을 얻을 수 있다.\n상견례 미팅 때 기업에서 프로젝트에 대해 설명해주고, 어떤 업무를 수행해야 하는지 설명해줄 것이라 생각하면 안된다.\n우리 팀의 경우 질문을 5개 정도 준비했는데, 질문에 대한 답변이 완료된 후 15분 만에 끝나버렸었다. 최대 1시간의 시간이 주어진 것을 감안하면 더 많은 질문을 준비해가지 않은 것이 살짝 아쉬웠다.\n멘토링은 모의 면접 형식으로 진행되었고, 나의 성장에는 큰 도움이 되었지만 아쉽게도 프로젝트에는 도움이 되지 않았다.\n멘토링 전에 제출한 구성원 역할 페이지를 보며 어떤 어려움이 있었는지, 어떤 방식으로 문제를 해결했는지 등을 여쭤보시며 면접 형식으로 진행됐다.\n나는 면접 경험이 부족했기 때문에 해당 시간은 나에게 큰 의미가 있었다. (다만 사전 예고 없이 갑작스럽게 진행된 터라 면접 준비를 하지 않고 진행된 것은 아쉬웠다.)\n그래도 실제 면접에서는 피드백을 얻을 수 없기 때문에, 시니어 개발자의 피드백이 존재하는 모의 면접은 엄청난 기회였다고 생각한다.\n면접에서 받은 피드백\n질문에 대한 답변을 하기 전에 생각을 정리한 후 여유를 가지고 천천히 답변하자.\n잔잔하게, 느리게, 깔끔하게, 차분하게 말하기\n프롬프트 엔지니어링에 대해 공부해보기. 프로토타입을 빠르게 만들어내는 능력이 대단히 중요하다. 3. 연계 기업에 얼굴 도장을 찍을 수 있다.\r#\r사실 이 부분을 명확하게 언급하기가 애매해서 이렇게 적었다. 아무래도 프로젝트를 사전에 함께 진행하고, 심지어 잘 진행했다면 당연히 채용에서 이점이 있지 않을까?\n4. 기업에서 필요한 프로젝트에 대한 경험\r#\r장점이자 단점일 수 있는데, 나는 프로젝트를 진행하며 부캠에서 배운 것과 기업에서 필요로 하는 것이 다르다는 느낌을 받았다.\n실제로 일을 하게 됐을 때도 동일하게 겪을 수 있는 문제 상황이라 생각하기 때문에, 좋은 경험을 쌓았다고 생각한다.\n기업 연계 프로젝트의 단점\r#\r나는 해당 글을 나의 프로젝트 경험을 바탕으로 작성했기 때문에 나중에는 상황이 바뀌게 될 수도 있다.\n그저 부캠 AI Tech 5기 때의 기업 연계 프로젝트 경험은 이랬구나 하고 넘어가면 좋겠다.\n1. 자유로운 듯 자유롭지 않은 프로젝트 방향성\r#\r기업 연계 프로젝트라고 하여 수행해야 하는 업무가 명확할 것으로 기대하고 있었으나 그렇지 않았다. 기업에서는 원하는 아이디어가 있었으나 세부적인 방향에 대해서는 이야기를 들을 수 없었다.\n따라서 우리가 기업 연계를 준비하며 챙겨 간 구체적인 아이디어는 사용할 수 없었고, 기업에서 제안한 아이디어를 어떤 방향으로 구체화할 것인지 다시 논의해야만 했다.\n게다가 우리 팀의 경우 운이 나쁘게도 일정이 맞지 않아 상견례 때와 멘토링 때 참가하신 기업 멘토님이 달랐는데, 두 분의 의견이 서로 꽤 달라서 프로젝트 마감 직전에 아쉬움이 컸다.\n2. 지연되는 일정\r#\r최종 프로젝트는 4주간 진행된다. 배운 내용을 실현하기에 이미 빠듯한 시간이라 생각되지만, 기업 연계 프로젝트에 참가하게 되면 이 일정은 추가로 조금씩 밀린다.\n프로젝트의 방향성을 논의하기 위해 상견례 자리가 필요하다고 생각했었으나, 상견례 일정을 기다리느라 프로젝트 구현에 주어진 시간이 3주밖에 남지 않게 되었었다.\n이 문제점은 1,3번 상황과 결합되어 상견례 직후 팀원 모두가 많이 걱정했다.\n3. 제공되는 데이터 없음\r#\r프로젝트의 주제가 데이터에 대한 모니터링 툴 개발이 목적이었기 때문에 당연히 분석 목적이 되는 데이터를 제공해줄 것이라 생각했다.\n하지만 제공된 데이터 없이 모니터링 툴 개발을 요청 받았기 때문에, 대시보드를 범용적으로 사용 가능하도록 구성해야 하는지 특정 데이터를 기준으로 만들어야 할 지 확정 짓기가 어려웠다.\n데이터 프라이버시 측면에서 어려움이 있었겠지만, 보안 유지 서약서에 동의를 하고 데이터를 제공 받지 못한 것이 좀 아쉬웠다. (받은 데이터가 없어 유지할 보안이 없었다.)\n프로젝트 진행\r#\r이번 프로젝트에서 나는 웹으로 대시보드를 구현하는 업무를 담당했다.\n처음 프로토타입을 만들 땐 Looker Studio를 활용했으나, 우리 팀에서 활용했던 대화형 데이터는 반정형 데이터이기 때문에 자유도가 더 높은 시각화 툴이 필요했다.\n알아보니 Python 문법을 지원하는 Dash라는 라이브러리가 있어 이를 활용하기로 했다. Dash는 Plotly와 Flask를 포함하기 때문에 Plotly로 그린 Figure을 Dash에서 바로 활용할 수 있었다.\n나는 PM 역할도 함께 수행했다. 프로젝트의 방향은 기업에서 원하는 대로 진행했기 때문에 나는 깃허브를 관리하고, 문제 상황을 정리하고 의견을 모으는 것에 힘썼다.\n브랜치는 Github flow 방식으로 관리했다. 팀원들이 아직 깃허브에 적응하는 단계였기 때문에 그나마 더 쉬운 방법을 적용하기도 했고, 로컬 중심인 git flow 방식으로 코드를 관리하게 되면 원격 레포지토리에 push하는 간격이 너무 길어질 것 같았기 때문이다.\n기간이 너무 짧았기 때문에 일정을 관리하기는 쉬웠다. 내가 PM 역할을 맡은 시점에 남은 기간이 2주였기 때문에, 한 주 만에 논의된 기능에 대한 구현을 끝내고 남은 한 주 동안 부가 기능을 추가했다.\n개요\r#\r절대적인 시간이 너무나 부족했기 때문에 기능 단위로 논의를 하고, 논의가 끝나면 나는 바로 구현에 들어갔다. 따라서 기능을 추가해가면서 페이지의 컨셉을 계속 변경시켰다.\n플롯 구상\n대시보드에 어떤 플롯을 추가할 것인가에 대한 논의는 프로젝트가 진행되는 3주 내내 있었다.\n기업 멘토님과 부스트캠프 멘토님께 각각 조언을 구하기도 하고, 논문도 찾아보며 추가할 기능을 선택했다.\n구상한 플롯을 Plotly로 그리기\nplotly 자체적으로 지원하는 callback이 아주 많았기 때문에 대시보드가 풍부해보였다.\n기본적으로 줌 인/아웃, 선택한 영역만 분포 확인하기 등의 기능을 지원한다.\n서버에 함수 형태로 추가하여 Dash에서 fig 객체 그리기\nPlotly로 fig 그리기를 완료했으면 서버에서 callback 함수를 통해 호출이 가능하도록 함수 형태로 변경해줬다.\n컨트롤 패널 추가하고 fig 객체와 연결하기\n플롯의 값을 변경할 수 있는 컨트롤 패널(e.g. 라디오 버튼, 슬라이더)을 추가한 후, callback 함수의 Input으로 넘겨줬다.\n디자인과 사용성을 고려하여 플롯 배치하기\n기능이 완성된 플롯의 크기를 조절하고 주제가 일치하도록 배치했다.\n대화형 추천 데이터\r#\r이번 프로젝트에서 가장 중요한 것은 대화형 추천 데이터로부터 어떤 정보를 뽑아내어 보여줄 수 있는가에 대한 고민이었다. 대화형 추천 데이터라는 포맷 자체가 익숙하지 않았기 때문에, 프로젝트를 진행하기 위해선 우선 대화형 추천 데이터에 대해서 잘 알아야 했다. 이를 위해 팀원 중 한 명이 관련 논문을 리뷰했으며, 블로그 리뷰도 참고했다.\n결론적으로 말하자면, 대시보드 사용자에게 도움이 되는 플롯을 구성하기 위해 대화형 데이터라는 점과 추천 데이터라는 점을 구분했다.\n대화의 품질을 알려주기 위해 어휘의 다양성(Distinct n-gram), 모델이 헷갈리는 정도(perplexity) 등의 평가 기준을 적용했으며, 추천의 효과 및 효율은 Precision과 함께 감정 분석을 통해 성공적인 추천인지 판별하여 통계치를 제공했다.\n또한, 대화 상황을 그래프로 표현하여 발화 간 거리와, 대화의 흐름을 직관적으로 확인할 수 있도록 구성했다.\nDash\r#\rDash를 처음 사용해본 것이기 때문에 필요한 기능이 있을 때마다 공식 문서를 참고했다.\nDash에서 지원하는 Callback 함수를 통해 element의 값이 변동될 때 특정 함수를 호출하여 동적으로 웹페이지를 구성할 수 있다.\n또한, dcc(dash core component)에서 지원하는 store 객체를 활용하여 여러 페이지에서 값을 공유할 수 있다.\nCallback 함수의 사용이 처음에 살짝 헷갈릴 수 있는데 간략하게 정리하자면 기본적인 형태는 아래와 같다. Dash에서 지원하는 Output, Input, State 객체가 존재하고, 해당 객체를 활용하여 코드를 간결하게 구성할 수 있다.\n@callback( Output(\u0026#34;element1\u0026#34;, \u0026#34;className\u0026#34;), Output(\u0026#34;element2\u0026#34;, \u0026#34;value\u0026#34;), Input(\u0026#34;element3\u0026#34;, \u0026#34;className\u0026#34;), State(\u0026#34;element4\u0026#34;, \u0026#34;value\u0026#34;), ) def function(input1, input2): ... return output1, output2 Output — 함수의 return값을 입력할 element id와 파라미터 선언 Input, State — 함수의 파라미터로 넘길 element id와 파라미터 선언 Input은 Trigger 역할을 수행하기 때문에, element의 값이 바뀌면 callback 함수가 호출된다.\nTailwind, Grid\r#\r이번에 대시보드를 구현하기 위해 어쩔 수 없이 UI에 대한 고민도 많이 했다.\nUI를 고민하는 과정에서 얼렁뚱땅 Tailwind도 배우고 Display 방식으로 Grid도 많이 활용했다.\n이 두 가지는 각각 작업이 끝난 후에 알게 되어 새로 코드를 수정하는 과정을 겪었는데, 미리 알고 시작했더라면 시간을 많이 단축할 수 있었을 것 같아 아쉬움이 남는다.\nCheat Sheet\r#\rCheat Sheet에는 자주 활용되는 기능이 빼곡하게 나열되어 있어 아직 라이브러리가 익숙하지 않은 상황에서 구글링 시간이 많이 줄어든다.\n나는 Tailwind와 Dash(Plotly)의 Cheat Sheet를 이번에 발견하고 활용하여 작업 능률을 올릴 수 있었다. 유명한 라이브러리마다 Cheat Sheet가 존재하는 것 같으니 익숙지 않은 라이브러리를 많이 사용해야 하는 일이 생기면 Cheat Sheet를 검색해보자.\nCheatsheet\n좋았던 점들\r#\r이번 프로젝트를 통해 비로소 나는 깃허브를 제대로 활용하게 되었다고 생각한다. 대화형 추천 데이터셋에 대해 보다 잘 이해하게 되었다. 피드백을 통해 사용자를 좀 더 고려하는 대시보드를 만들 수 있게 되었다. Dash와 Plotly를 익힌 덕분에, Streamlit, Tableau, Looker Studio등보다 자유도가 높은 대시보드를 만들 수 있게 되었다. 또한, 내가 모델을 구축하거나 예측 결과를 생성해냈을 때 이를 잘 표현해주고 사용하기 좋게 만들어주는 방법을 익힐 수 있었다. 아쉬웠던 점들\r#\r하고 싶은 일은 많았으나, 시간이 짧아 아쉬움이 큰 프로젝트였다. 게다가 아쉬운 마음 때문에 마지막으로 갈수록 온 힘을 다하지 못했다. UI의 구성에 시간을 덜 쏟고, 다른 부분에 시간을 할애했다면 더 많은 것을 배울 수 있었을 것이라고 생각한다. 마음은 아프지만 다음 프로젝트의 발전을 위해 기록해둔다.\nDash의 활용 시간이 부족하여 대시보드에 비동기 처리를 도입하지 못한 것이 아쉬웠다. Backend \u0026amp; Ops Dash에서 자체적으로 Flask를 지원하기 때문에, API 서버를 따로 구성하지 않고 서비스를 완성할 수 있었다. 이를 위해 반정형 데이터인 대화형 추천 데이터셋을 정형 데이터로 변환하는 작업을 수행했다. 하지만 데이터 처리 속도 측면에서 이슈가 꽤 있었기에 Elastic Search로 데이터를 관리했더라면 더 나았을 것이라는 생각이 든다. 프로젝트를 관리하며 Github Action이나 테스팅도 추가해보고 싶었으나 그러지 못했다. 깃허브에 PR, Issue Template을 추가하고 Pre-commit을 도입해보았으나, 익숙하지 않은 팀원들이 제대로 활용하도록 이끌어주진 못했던 것 같다. Log 관리, A/B Test, ETL, 세션 관리 등 다음 프로젝트에서 해보고 싶은 것들이 더 많아졌다.\n글을 마무리하며\r#\r비록 프로젝트 결과물은 아쉬웠으나 훌륭한 사람들과의 협업으로 결과를 내고, 또 다른 팀들과 결과물을 공유하며 피드백을 받을 수 있어 좋았다.\n프로젝트를 하면서도 많이 배웠지만, 다른 팀들의 프로젝트를 보면서 또 많이 배울 수 있었다.\n다음 번에 수행할 프로젝트는 더 나아질 것이라 생각한다.\n"},{"id":46,"href":"/posts/2023-09-24-1-epoch/","title":"모델 학습 시 1 epoch에 어떤 일이 발생하나요?","section":"Blog","content":"criterion = torch.nn.MSELoss() optimizer = torch.optim.SGD(model.parameters(), lr=learningRate) ... for epoch in range(epochs): optimizer.zero_grad() outputs = model(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() 1. optimizer.zero_grad() : 이전 epoch의 미분값 초기화\r#\roptimizer에서 업데이트하는 파라미터에 저장된 그래디언트를 모두 0으로 만들어준다.\n해당 코드는 왜 필요할까?\nzero_grad()를 실행해주지 않으면 이후의 backward에서 해당 step의 gradient 값이 계속 누적으로 더해져 모델이 이상하게 학습할 수 있기 때문이다.\n왜 굳이 default를 이전의 gradient가 넘어오도록 설정했을까?\nRNN 계열의 모델이나, 가중치 공유가 필요한 모델의 경우 이전 gradient를 그대로 가져오는 것이 필요하기 때문이다.\n각 epoch의 손실 함수에서 반환하는 텐서 객체는 서로 다른데, 어떻게 이전 학습 단계의 미분 값을 넘겨받을까?\nOptimizer 객체에서 미분 값을 저장하기 때문이다.\nzero_grad() 코드 리뷰\nmodel.zero_grad()와 optimizer.zero_grad()의 차이는 뭘까?\nmodel.zero_grad()와 optimizer.zero_grad()의 차이\n2. outputs = model(inputs) : 모델 예측 수행\r#\r3. loss = criterion(outputs, labels) : 손실 함수를 통한 loss 계산\r#\r4. loss.backward() : loss의 미분값 계산\r#\r$\\mathbf w$에서의 loss에 대한 미분 연산을 수행한다.\n수치 미분에는 많은 연산이 필요한데, 이를 Back Propagation(오차 역전파 알고리즘)을 통해 해결한다.\n계산된 미분 값을 GD: gradient descent(경사하강법)을 통해 $\\mathbf w$에 반영한다. Backward\n5. optimizer.step() : 미분값을 parameter에 반영\r#\r"},{"id":47,"href":"/posts/2023-09-19-PyTorch-Datasets-DataLoaders/","title":"모델에 데이터를 먹이는 방법(PyTorch Datasets \u0026 DataLoaders)","section":"Blog","content":"모델에 데이터를 먹이는 방법\n1. Dataset\r#\r모아놓은 데이터에 대해 Dataset이라는 클래스를 통해 시작, 길이, mapstyle 등을 선언해준다.\n__getitems__() : 하나의 데이터를 불러올 때 어떤 식으로 데이터를 반환할 지를 선언해준다.\n데이터 입력 형태를 정의하는 클래스\n데이터를 입력하는 방식의 표준화\nImage, Text, Audio 등에 따라 다르게 입력이 정의된다.\n데이터의 형태에 따라 각 함수를 다르게 정의한다.\n모든 것을 데이터 생성 시점에 처리할 필요는 없다.\nimage의 Tensor 변화는 학습에 필요한 시점에 변환해주면 된다.\n데이터 셋에 대한 표준화된 처리 방법 제공이 필요하다.\n후속 연구자 또는 동료들에게는 빛과 같은 존재가 될 수 있다.\n최근에는 HuggingFace 등 표준화된 라이브러리를 사용한다.\nimport torch from torch.utils.data import Dataset class CustomDataset(Dataset): def __init__(self, text, labels): # 초기 데이터 생성 방법을 지정 self.labels = labels self.data = text def __len__(self): return len(self.labels) # 데이터의 전체 길이 def __getitem__(self, idx): # idx 값을 입력으로 받고, dict 타입으로 데이터를 반환해준다. label = self.labels[idx] # 반환되는 데이터의 형태 (X,y) text = self.data[idx] sample = {\u0026#34;Text\u0026#34;: text, \u0026#34;Class\u0026#34;: label} return sample 2. Transforms\r#\rData Augumentation 등의 동작을 수행한다.\nToTensor() : 모아놓은 데이터를 Tensor로 변환해준다.\n3. DataLoader\r#\rData의 Batch를 생성해주는 클래스\n정리된 데이터를 묶어서 모델에 넣어준다.\nbatch를 만들거나, shuffle 등의 역할을 수행한다.\n학습 직전(GPU feed 전) 데이터의 변환을 책임진다.\nTensor로 변환 + Batch 처리가 메인 업무이다.\n병렬적인 데이터 전처리 코드를 고민하게 된다.\nDataLoader(dataset, batch_size=1, shuffle=False, **sampler=None**, **batch_sampler=None**, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None, *, prefetch_factor=2, persistent_workers=False) sampler : Data를 어떻게 뽑을 지 index를 정해주는 기법\ncollate_fn : [[data,label],[data,label]] 형태로 묶인 데이터를 [data,data],[label,label]로 바꿔준다.\n흔하게 사용되지는 않는다.\nvariable length(가변인자) 텍스트 처리에서 padding을 위해 많이 쓰인다. Sequence형 데이터를 처리할 때도 많이 쓰인다. 4. Model\r#\r예제\r#\rDatasets — Torchvision main documentation\nDatasets \u0026amp; DataLoaders — PyTorch Tutorials 2.0.1+cu117 documentation\nDataLoader에서 사용할 수 있는 각 sampler들을 언제 사용하면 좋을지 논의해보기 데이터의 크기가 너무 커서 메모리에 한번에 올릴 수 없을 때 Dataset에서 어떻게 데이터를 불러오는 것이 좋을지 논의해보기 "},{"id":48,"href":"/posts/2023-09-21-Hyperparameter_tuning/","title":"모델의 성능이 더이상 오르지 않을 때 (Hyper-Parameter Tuning)","section":"Blog","content":"하이퍼 파라미터\n모델 스스로 학습하지 않는 값.\n사람이 직접 지정해주어야 한다.\n결과를 개선하고 싶을 때\r#\r모델을 바꾸기\n중요하지만, 이미 높은 성능의 모델이 공개되어있기 때문에 상대적으로 덜 중요.\n데이터를 바꾸기 → 성능 개선을 위해 가장 중요하다.\n하이퍼 파라미터 Tuning\n약간의 성능 개선이 간절한 경우 수행한다.\n마지막 0.01의 성능 개선이라도 필요한 경우 사용한다.\ngeneralization 등 적용\nHyperparameter Tuning\r#\r가장 기본적인 방법 - grid vs random\ngrid\n적절한 하이퍼파라미터를 찾을 때, 값들을 일정한 범위를 정해 선택하는 것.\nrandom\n값을 랜덤하게 찾아서 가장 성능이 잘나오는 것을 선택한다.\n요즘에는 잘 쓰이지 않고, 베이지안 기반 기법이 많이 쓰인다.\nRay\r#\rmulti-node multi processing 지원 모듈\nML/DL의 병렬 처리를 위해 개발된 모듈\n기본적으로 현재의 분산병렬 ML/DL 모듈의 표준\nHyperparameter Search를 위한 다양한 모듈 제공\ndata_dir = os.path.abspath(\u0026#34;./data\u0026#34;) load_data(data_dir) # search space 지정 config = { \u0026#34;l1\u0026#34;: tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)), \u0026#34;l2\u0026#34;: tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)), \u0026#34;lr\u0026#34;: tune.loguniform(1e-4, 1e-1), \u0026#34;batch_size\u0026#34;: tune.choice([2, 4, 8, 16]) } # 학습 스케줄링 알고리즘 지정 scheduler = ASHAScheduler( # ASHAS : 실행 도중 낮은 loss를 가지는 metric들을 버리는 알고리즘 metric=\u0026#34;loss\u0026#34;, mode=\u0026#34;min\u0026#34;, max_t=max_num_epochs, grace_period=1, reduction_factor=2) # 결과 출력 양식 지정 reporter = CLIReporter( metric_columns=[\u0026#34;loss\u0026#34;, \u0026#34;accuracy\u0026#34;, \u0026#34;training_iteration\u0026#34;]) # 병렬 처리 양식으로 학습 시행 result = tune.run( partial(train_cifar, data_dir=data_dir), resources_per_trial={\u0026#34;cpu\u0026#34;: 2, \u0026#34;gpu\u0026#34;: gpus_per_trial}, config=config, num_samples=num_samples, scheduler=scheduler, progress_reporter=reporter) data_dir = os.path.abspath(\u0026#34;./data\u0026#34;) load_data(data_dir) config = { \u0026#34;l1\u0026#34;: tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)), \u0026#34;l2\u0026#34;: tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)), \u0026#34;lr\u0026#34;: tune.loguniform(1e-4, 1e-1), \u0026#34;batch_size\u0026#34;: tune.choice([2, 4, 8, 16]) } scheduler = ASHAScheduler( metric=\u0026#34;loss\u0026#34;, mode=\u0026#34;min\u0026#34;, max_t=max_num_epochs, grace_period=1, reduction_factor=2) reporter = CLIReporter( # parameter_columns=[\u0026#34;l1\u0026#34;, \u0026#34;l2\u0026#34;, \u0026#34;lr\u0026#34;, \u0026#34;batch_size\u0026#34;], metric_columns=[\u0026#34;loss\u0026#34;, \u0026#34;accuracy\u0026#34;, \u0026#34;training_iteration\u0026#34;]) result = tune.run( partial(train_cifar, data_dir=data_dir), resources_per_trial={\u0026#34;cpu\u0026#34;: 2, \u0026#34;gpu\u0026#34;: gpus_per_trial}, config=config, num_samples=num_samples, scheduler=scheduler, progress_reporter=reporter) 모델의 모든 layer에서 learning rate가 항상 같아야 할까? 하이퍼 파라미터 탐색의 우선순위 어떻게 될까? Pytorch와 Ray 같이 사용하기 "},{"id":49,"href":"/posts/2023-11-15-TF-IDF/","title":"문서의 순위를 매기는 방법, TF-IDF","section":"Blog","content":"\rBackground\rBackground\r#\r이때까지 우리의 쿼리는 모두 Boolean을 활용한 것이었다.\nBoolean은 자신들의 원하는 검색결과를 정확하게 아는 전문가들이 사용하기에 좋다.\n또한 많은 정보를 탐색하는 전문가들에게 유용하다.\n하지만 대부분의 사람들이 편하게 사용하기엔 적절하지 않다.\n대부분의 유저들은 boolean 쿼리를 작성하지 못한다.\n사용자들은 그렇게 많은 결과물이 필요하지 않다.\n대부분 Boolean query는 문서가 너무 많이 나오거나, 너무 적게 나온다.\nQuery 1: “standard user dlink 650” → 200,000 hits\nQuery 2: “standard user dlink 650 no card found”: 0 hits\nAND는 너무 적게 나오고, OR은 너무 많이 나온다.\n심지어 순서도 없이 뒤죽박죽 나온다.\nQuiz 1: Search results\nX AND Y에대해 구글 검색할 때, 총 2000개의 결과가 리턴 X AND Y AND Z에대해 구글 검색할 때, 총 3500개의 결과가 리턴 왜 2번째 쿼리가 더 많은 결과를 리턴하는가?\nRanked Retreival Models\r#\rAND, OR 이렇게 검색하지 않고, 사람에게 말하듯이 검색하고자 한다.\n즉, 쿼리 표현식을 만족하는 문서의 집합이 아닌, 시스템이 쿼리에 대한 컬렉션에 대한 상위 랭킹의 문서를 리턴한다.\nfree text query: 쿼리 언어의 precise query(연산자나 표현) 보다는 사용자의 쿼리는 한단어 이상의 자연어가 입력된다. 실전에서는 보통 ranked retreival이 free text 쿼리랑 조합된다. 이 때, 랭킹 알고리즘 품질을 좋게 유지해야 한다.\n랭킹을 매기는 문서의 양을 줄이는 것은 품질면에서는 큰 이슈가 아니다.\r#\r구글 검색의 클릭률을 보면 대부분 1페이지의 10개의 검색결과의 클릭률이 94%이다.\n유저는 2페이지로 이동할 가능성 조차 낮다.\nRanked Retreival의 기준 점수 매기기\r#\r가장 그럴듯한 문서 순서대로 리턴해주고 싶은데, 쿼리마다 문서의 랭킹을 어떻게 정할 수 있을까?\n각 문서가 쿼리에 매칭되는 정도를 0과 1 사이의 값으로 점수를 매긴다.\n해당 점수는 query time에 계산된다.\n계산이 오래 걸려선 안된다.\nQuery-document matching scores\r#\r쿼리-문서 쌍에 대해 점수를 할당하는 방법\n복잡한 것을 배우기 전에 term 한개짜리 쿼리부터 시작해보자.\n만약 query term이 문서에 없다면 0점 query term의 출현 빈도가 클수록 높은 점수를 할당 앞으로 이 방식에 대한 몇가지 대안을 살펴볼 예정 Jaccard coefficient\r#\r앞에서 단어간 유사도를 확인할 때 사용했었다.\n일반적으로 쓰여지는 A와 B집합의 관계는 아래와 같이 나타낸다. jaccard(A,B)=$|A∩B||A∪B|$ jaccard(A,A)=1 jaccard(A,B)=0 if $A∩B=0$ A와 B가 같은 크기일 필요는 없다. 문서의 term 개수보다 query term이 적은 것이 당연하다. 항상 0~1 값을 가진다. 쿼리-문서 match 점수에서 Jaccard coefficient는 어떻게 계산할까?\nQuery: ides of march 일 때\nDocument 1: caesar died in march ⇒ 1 / 3 + 4 - 1 Document 2: the long march ⇒ 1 / 3 + 3 - 1 doc1 : $1\\over6$ doc2 : $1\\over5$ 즉 doc2가 점수가 조금 더 높다.\nJaccard coefficient의 문제점\r#\rterm frequency를 고려하지 않는다.\n문서 안에서 동일한 term이 몇 번 발생했는지는 관심이 없다.\n하지만 이 값은 중요하다.\n▪️ frequency\rterm frequency($tf_{term}$)\n어떤 document 안에서 해당 term이 나타난 횟수\ndocument frequency($df_{term}$)\n어떤 term이 나타나는 document의 개수\ncollection frequency($cf_{term}$)\ncollection 전체에서 어떤 term이 나타난 횟수\nScoring의 목적이 query와 document 사이의 관계이다.\ncollection에서 드물게 나타나는 term은 흔한 term보다 문서를 특정하기에 훨씬 더 유용하다.\n하지만 Jaccard는 frequency를 고려하지 않기 때문에 이 정보를 고려하지 않는다.\n길이를 normalize 할 더 세련된 방법이 필요하다.\n문서의 길이가 긴 경우 동일한 단어가 더 많이 출몰할 것이다.\n이를 문서의 길이가 짧은 경우의 단어 출몰 횟수랑 비교하기 위해 정규화할 필요가 있다.\n나중에 이 수식을 사용한다.\n$|A∩B||A∪B|$\nRecall: Binary term-document incidence matrix\r#\r예를 들어 antony and brutus and not(calpurnia)라면\n$110001$ $110100$ $101111 -\u0026gt; 100000$ 위 비트와이즈 연산을 통해 “Antony and Cleopatra”가 만족하는 소설책임을 찾을 수 있다.\n각 문서를 바이너리 벡터로 표시한다.\n$vector ∈ {0,1}^{V}$\nTerm-document count matrices\r#\rfrequency를 고려하기 위해 0/1 벡터 대신에 횟수를 벡터화한다.\n문서에 term이 등장한 횟수를 고려함\n각 문서는 자연수를 담은 count vector로 표시\n문서에서 단어의 등장횟수가 많은 것들이 중요하다.\nBag of words model\r#\r벡터 표현은 문서안의 단어의 순서를 고려하지 않는다.\nJohn is quicker than Mary Mary is quicker than John 위의 두 문장은 다른 뜻이지만 같은 벡터를 가지게 된다.\n이를 BOW(bag of words) 모델이라고 부른다.\n위의 두 문장의 차이를 구별할 수 있는 positional index에 비해 BOW는 후퇴한 것처럼 보인다.\n하지만 positional index는 presentation을 판별하기 위해 사용됐던 것이다.\n나중에 positional index가 다시 언급된다.\nTF: Term frequency\r#\rterm frequency($tf_{t,d}$): 문서 d에서 term t가 발생한 빈도\ntf를 query-document가 얼마나 일치하는지 계산하기 위해 쓰고 싶다.\nraw tf 값은 활용하기 불편하다.\ntf 10인 문서가 tf 1인 문서보다 더 연관도가 높다.\n하지만 숫자의 크기가 해당 문서가 10배 더 유의미하다는 의미는 아니다.\n문서의 연관성은 tf의 수에 따라 비례적으로 증가하지는 않는다.\n게다가, 단어의 빈도가 0개인 문서와 1개인 문서의 차이는 매우 크지만,\n100개인 문서와 101개인 문서의 차이는 아주 작다.\n따라서 단어의 개수에 따라 달라지는 영향력을 표현하기 위해, 단어의 빈도에 log를 취한다.\n이 때, 단어가 하나 있는 것과 아예 없는 것의 차이는 훨씬 크기 때문에, 0과 1은 따로 구분한다.\n$$ \\tt score = ∑_{t∈q∩d}(1+log tf_{t,d}) $$\n문서의 점수를 계산하기 위해선, query와 document에서 공통으로 나타나는 단어의 빈도를 log로 계산하면 된다.\n문서에서 query term이 하나도 발견되지 않으면 점수는 0이다. ex term frequency weight 0 0 1 1 2 1.3 10 2 1000 4 DF: Document Frequency\r#\r희귀한 term은 흔한 term 대비 더 유용하다.\nstop word와 같은 것들은 문서를 구별짓는데 도움이 되지 않는다.\narachnocentric이 문서를 구별짓는데 훨씬 많은 도움이 된다.\n이렇게 희귀한 term을 포함한 문서는 쿼리 term에 매우 연관도가 높을 것이다.\n희귀한 arachnocentric같은 term에 가중치를 부여해야 한다.\n요약하면, Document frequency가 작은 단어일수록 유용하고, term frequency가 큰 단어일수록 문서를 특정짓는데 유용하다.\n효과적인 검색을 위해 document frequency($df$)에 대한 정보도 활용해야 한다.\n모든 document에서 나타나는 term들은 문서를 검색하는데 도움이 크게 되지 않는다.\n컬렉션 내에서 흔한 term을 생각해보자. (ex: high, increase, line)\n물론 이러한 term을 포함하는 문서가 그러지 않은 문서보다는 연관있을 가능성이 높다.\n하지만 확실한 연관도의 척도가 될 수는 없다.\nterm frequency가 높은 단어들에게 높은 가중치를 부여해야 한다.\ndocument frecuency가 낮은 단어들에게 높은 가중치를 부여해야 한다.\nIDF: Inverse Document Frequency\r#\r$$ \\tt idf_t=log_{10}(N/df_t) $$\nN = 전체 document 수 df가 작은 term의 점수를 더 높게 주기 위해 df를 뒤집어서 분모로 사용한다.\nidf값을 완화시키기 위해 log를 취해준다.\nlog의 base가 꼭 10일 필요는 없다.\nex) N = 1 million\nN(문서의 개수) = 1,000,000이고,\n$idf_t=log_{10}(N/df_t)$인 경우\nterm df_t idf_t calpurnia 1 6 animal 100 4 sunday 1,000 3 fly 10,000 2 under 100,000 1 the 1,000,000 0 the처럼 모든 document에서 나타나는 단어는 가중치가 0이 되어버린다. 전체 collection에 존재하는 term마다 고유한 idf 값이 존재한다. 쉽게 이해하자면 idf를 적용하면 calpurnia는 promoting하고 the는 demoting한다. idf는 one term 쿼리에 있어서는 랭킹에 변화가 없다.\n어차피 가중치를 구할 때 모든 document에 항상 같은 값이 곱해지게 된다.\nidf는 적어도 2개의 term 이상에 대해 효과가 있다.\n“capricious person”라는 쿼리가 있으면 idf 가중치는 capricious 라는 희귀한 단어에 person 이라는 흔한 단어 보다 상대적으로 높은 가중치를 부여하게 된다.\nex) query : iphone box\nCF vs. DF\nt에 대한 Collection Frequency는 전체 컬렉션 내에서 t가 발생한 빈도수를 집계한다.\n여러번 등장한 것을 모두 센다.\nex\n두 단어의 collection frequency가 비슷하지만, insurance의 document frequency에 비해 try의 document frequency가 훨씬 크다.\n그러므로 insurance가 더 높은 가중치를 받아야 한다.\nTF-IDF\r#\r문서에 등장한 단어들의 중요도를 나타내는 값\n단어마다 TF-IDF 값이 계산된다.\nIR에서 가장 핵심적인 가중치 공식\n$$ \\tt W_{t,d}=(1+log_{10}tf_{t,d}) \\times log_{10}(N/df_t) $$\nterm의 tf-idf 가중치는 tf 가중치와 idf 가중치의 곱이다.\ntf.idf나 tf x idf라고 부르기도 한다.\n가중치는 collection에서 term의 발생빈도에 따라 증가한다.\n가중치는 컬렉션 내에 term이 희귀할수록 증가한다.\n쿼리에 대한 문서의 Score 계산\r#\r$$ \\tt Score(q,d)=∑_{t∈q∩d}tf.idf_{t,d} $$\n위 수식은 q(query)와 d(document)에서 공통되는 term을 가진 document의 score만 계산한다는 의미이다.\n문서들의 Score을 계산할 때 다양한 옵션이 존재한다.\ntf를 계산하는 방법\nlog 적용 여부 log의 base 크기 쿼리를 구성하는 term에 가중치 부여 여부\n가중치 부여 없이, query도 하나의 document처럼 처리하는 방법도 있다.\nquery는 document의 한 종류다.\n문서를 나타내는 방법\r#\r문서들을 tf-idf 가중치 행렬로 나타낸다.\nAntony and Cleopatra Julius Caesar The Tempest Hamlet Othello Macbeth d1 d2 d3 d4 d5 d6 Antony t1 5.25 3.18 0 0 0 0.35 Brutus t2 1.21 6.1 0 1 0 0 Caesar t3 8.59 2.54 0 1.51 0.25 0 Calpurnia t4 0 1.54 0 0 0 0 Cleopatra t5 2.85 0 0 0 0 0 Mercy t6 1.51 0 1.9 0.12 5.25 0.88 worser t7 1.37 0 0.11 4.15 0.25 1.95 각 문서는 tf-idf 가중치의 실수값 벡터로 표현된다.\n즉, 각 문서를 구성하는 Term들을 tf-idf 값으로 전환하여 문서를 벡터화한다.\ntf-idf 가중치 행렬 $∈R^{|V|}$\n$V$는 문서에 포함된 단어의 개수를 의미한다.\n결국 $|V|$ 차원의 벡터 공간을 가지게 된다.\nterm은 공간의 차원이 된다.\n문서는 공간에서의 벡터(점)이라고 이해할 수 있다.\n쿼리도 문서와 같은 크기로 들어가야 한다.\n쿼리도 문서로 취급하여 벡터로 표현한다.\n하지만 만약 이 개념을 웹 검색엔진에 적용한다면 차원이 수억개가 된다.\n이는 매우 sparse한 벡터이고 대부분의 값은 0일 것이기에, 다른 방법이 필요하다.\n공간에서 쿼리 벡터(문서)의 유사도(proximity)에 대해 랭킹을 매긴다.\nscore(q,d1), score(q,d2)\u0026hellip;는 벡터공간 상에서 문서벡터가 쿼리벡터와 얼마나 흡사한지를 판별한다.\nproximity ≈ inverse of distance\n즉, 거리가 가까울수록 문서와 쿼리가 비슷하다\nboolean 모델에서 벗어나기 위해 이 작업을 수행한다.\n대신에 더 연관있는 문서에 더 높은 랭크를 부여한다.\nTF-IDF의 다양한 선택지\r#\rtf-idf의 가중치 알고리즘은 선택의 폭이 다양하다.\n가장 많이 쓰이는 것은 붉은 색 표시가 되어있다.\n많은 검색 엔진들이 쿼리나 문서에 대해 다양한 가중치 부여방식을 허용한다.\n표기법\nddd.qqq\n앞의 3글자: 문서에 대한 알고리즘\n뒤의 3글자: 쿼리에 대한 알고리즘\nex) lnc.ltc\ndocument → lnc\nlogarithmic tf no idf cosine normalization query → ltc\nlogarithmic tf (t) ⇒ idf cosine normalization 매우 표준적인 가중치 부여 방식으로 lnc.ltc가 있다.\nquiz: document에 no idf를 적용하는것이 나쁜 아이디어인가?\nltc.lnc가 더 일반적으로 보인다.\nex — lnc.ltc\r#\r문서: car insurance auto insurance 쿼리: best car insurance tf-raw: term의 발생횟수\ntf-wt: $1+log(tf_{t,d})$. 즉, term의 발생빈도를 가중치로 바꾼 것.\nidf: $log{N\\over df_t}$\nwt: tf-wt * idf : $(1+log(tf_{t,d}))\\times log{N\\over df_t}$\nn\u0026rsquo;lize: 문서 길이(wt 제곱 총합의 루트) 로 wt를 나눈 것\n문서의 길이: $\\sqrt {1^2+0^2+1^2+1.3^2} \\simeq 1.92$\n실제 코사인 유사도는 내적값의 합으로 auto에 대한 내적값 0, best에 대한 내적값 0, car에 대한 내적값 0.27(0.52 * 0.52)과 insurance에 대한 내적값 0.53(0.78 * 0.68)을 더한 0.8이다.\nquiz: 문서의 수, N은 몇일까? "},{"id":50,"href":"/posts/2023-09-23-Loss-function/","title":"손실 함수(Loss Function)에 대해 알아보자.","section":"Blog","content":" ✔️ 간단 요약\n신경망의 학습 중 받는 벌점의 기준\n회귀와 분류 문제에서 다른 loss function을 사용한다.\n{: .prompt-info } Gradient, MAE, MSE, RMSE\nLoss : 예측 값과 실제 값의 차이\n신경망의 학습 중 오답에 대해 받는 벌점\n두 값의 차이는 단순히 뺄셈의 절댓값을 의미하는 것은 아니며, 상황에 따라 다양하게 나타난다.\nex) 정답과 완전히 동떨어진 대답을 하면 더 많은 벌점을 받는다.\nLoss Function\r#\r신경망이 벌점을 받는 기준\n신경망의 학습 과정에서 가중치 $\\mathbf w$를 평가하는 함수.\n나는 손실 함수가 함수라는 것을 제대로 인지하지 못했을 때 모델 평가 Metric과 헷갈렸기 때문에, 손실 함수라는 것을 다시 한번 인지하고 지나가자.\n2차원 그래프로 비유했을 때, 가중치 $\\mathbf w$는 x좌표에 해당하고 손실 함수의 값은 y좌표에 해당한다.\n손실 함수의 최솟값이 되는 지점에 $\\mathbf w$를 위치시키는 것이 신경망의 목표이다.\n고등 수학을 빌려 설명하자면, 단순히 미분값이 0이 되는 지점을 파악하여 손실 함수의 최솟값을 구하면 된다.\n하지만 고차원에서의 손실 함수 미분은 쉽지 않을 뿐더러, 함수 전체에서 미분값이 0이 되는 지점을 바로 찾아내는 것은 현실적으로 불가능하다.\n따라서, 신경망은 $\\mathbf w$에서 손실 함수의 기울기를 측정하여 loss가 낮아지는 방향으로 가중치를 조금씩 이동하는 전략을 사용한다.\n이 때의 조금을 결정하는 것이 Optimizer이다.\n해결하고자 하는 문제에 맞게 loss function을 설정해 사용해주면 된다.\n신경망 학습을 통해 손실 함수 $J$의 최저점을 찾아야 한다.\n신경망의 학습 알고리즘\r#\r훈련 데이터 입력 매개변수 $\\mathbf w$를 난수로 초기화 while (true): 손실 함수$J(\\mathbf w)$ 계산(loss 계산) loss를 낮추는 방향 $\\Delta \\mathbf w$ 계산 $\\mathbf w = \\mathbf w + \\Delta \\mathbf w$ return 가중치(매개변수) 손실 함수 J(w)의 조건\r#\rw가 훈련 집합에 있는 샘플을 모두 맞히면, $J(w) = 0$이다. w가 틀리는 샘플이 많을수록 $J(w)$의 값이 크다. 위의 조건을 만족하는 수식은 아주 다양하기 때문에, 적절한 손실 함수를 선택해야 한다.\n손실 함수의 종류\r#\r회귀(Regression)\r#\rMAE(Mean Absolute Error) — $\\left|정답 - 예측값\\right|$의 평균\n간단 요약\n틀린 만큼 벌점을 얻는다.\n모든 지점에서 그래디언트는 동일하다.\n가장 간단한 손실 함수.\n제곱을 취하지 않기 때문에, 모든 오차는 그대로 반영된다.\n직관적으로 말하자면, 오차만큼 벌점이 쌓인다.\n기울기 관점으로, 모든 가중치에서 그래디언트의 크기가 동일하다.\n따라서 MSE나 RMSE에 비해 상대적으로 이상치에 대해 Robust하다.\n(이상치도 오차만큼만 벌점이 쌓이기 때문)\n$$ \\frac{1}{n} \\sum_{i=1}^n\\left|{y_i}-\\hat y_i\\right| $$\nMSE(Mean Squared Error) — $(정답 - 예측값)^2$의 평균\n간단 요약\n정답과의 거리가 멀수록 더 많은 벌점을 부여하자!\n오차를 제곱 하면 되겠네?\n정답에서 멀어질수록 그래디언트의 크기가 증가한다.\n$$ M S E=\\frac{1}{n} \\sum_{i=1}^n\\left({y_i}-\\hat y_i\\right)^2 $$\n미니 배치 단위로 처리(샘플의 오차를 평균 낸다.)\n$$ \\begin{aligned}J\\left(\\mathbf{U}^1, \\mathbf{U}^2\\right) \u0026amp; =\\frac{1}{|M|} \\sum_{\\mathbf{x} \\in M}|\\mathbf{y}-\\mathbf{0}|^2 \\\u0026amp; =\\frac{1}{|M|} \\sum_{\\mathbf{x} \\in M}\\left|\\mathbf{y}-\\tau_2\\left(\\mathbf{U}^2 \\tau_1\\left(\\mathbf{U}^1 \\mathbf{x}^{\\mathrm{T}}\\right)\\right)\\right|^2\\end{aligned} $$\n오차값에 제곱을 취하기 때문에 0~1 사이의 값은 상대적으로 작게 반영되고, 1보다 큰 값은 상대적으로 더 크게 반영된다. 학습이 느려지거나 학습이 안되는 상황을 초래할 가능성이 있다. 정답과 예측값의 차이가 클수록 더 크게 반영되기 때문에, 이상치에 매우 민감하다. RMSE(Root MSE) — $\\sqrt{(정답 - 예측값)^2\\text {의 평}균}$\n간단 요약\nMSE에 루트 씌운 값.\n얼핏 MAE와 동일한 것 아니야? 생각할 수 있지만, 계산 순서에서 차이가 발생하고, $1\\over n$이 아니라 $1\\over \\sqrt n$을 했다는 점이 MAE와 다르다.\n$$ R M S E=\\sqrt{\\frac{1}{n} \\sum_{i=1}^n\\left(\\hat{y_i}-y_i\\right)^2} $$\nMSE와 마찬가지로 각 오차값의 크기에 따라 다른 그래디언트를 가지게 된다.\n분류(Classification)\r#\rEntropy\n확률 분포의 무작위성(불확실성)을 측정하는 함수\n$$ H(x)=-\\sum_{i=1, k} P\\left(e_i\\right) \\log P\\left(e_i\\right) $$\nCross-Entropy\n정보량을 상징한다. → 불공정성 문제 해결\n두 확률 분포 P와 Q가 다른 정도를 측정하는 함수\n$$ H(P, Q)=-\\sum_{i=1, k} P\\left(e_i\\right) \\log Q\\left(e_i\\right) $$\n공정한 주사위에는 특별한 정보가 존재하지 않는다.\n$$ -\\left(\\frac{1}{6} \\log \\frac{1}{6}+\\ldots+\\frac{1}{6} \\log \\frac{1}{6}\\right)=1.7918 $$\n찌그러진 주사위에서는 특정 값이 더 잘나온다는 정보가 추가된다.\n공정한 주사위와 찌그러진 주사위의 교차 엔트로피\n$$ -\\left(\\frac{1}{6} \\log \\frac{1}{2}+\\frac{1}{6} \\log \\frac{1}{10}+\\cdots+\\frac{1}{6} \\log \\frac{1}{10}\\right)=2.0343 $$\nBinary Cross-Entropy\ntf.nn.sigmoid_cross_entropy_with_logits( )\n$$ B C E=-\\frac{1}{N} \\sum_{i=0}^N y_i \\cdot \\log \\left(\\hat{y_i}\\right)+\\left(1-y_i\\right) \\cdot \\log \\left(1-\\hat{y_i}\\right) $$\nCategorical Cross-Entropy\ntf.nn.softmax_cross_entropy_with_logits_v2( )\n$$ C C E=-\\frac{1}{N} \\sum_{i=0}^N \\sum_{j=0}^J y_j \\cdot \\log \\left(\\hat{y_j}\\right)+\\left(1-y_j\\right) \\cdot \\log \\left(1-\\hat{y_j}\\right) $$\n"},{"id":51,"href":"/posts/2023-09-24-Gradient_Descent/","title":"손실 함수에서 최적 해를 찾는 방법: Gradient Descent(경사 하강법)","section":"Blog","content":" 손실 함수, 확률적 경사 하강법, 수치 미분, 배치 모드, 미니 배치 모드, 패턴 모드, Local Minima, Global Minima, Optimizer\nGradient Descent(경사하강법)\r#\r자연 과학과 공학에서 오랫동안 사용해온 최적화 방법\n손실 함수의 최적 해를 찾기 위한 방법\n1차 근삿값 발견을 위한 최적화 알고리즘\n미분 값 $\\partial J\\over\\partial w_1$의 반대 방향이 최적 해에 접근하는 방향이다.\n따라서, 현재 가중치 $w_1$에 $-{\\partial J\\over\\partial w_1}$을 더하면 최적 해에 가까워진다.\n굳이 가까워질 필요 없이, 손실 함수를 미분해서 바로 극값을 찾으면 되지 않을까? 일반적으로 손실 함수가 매우 복잡하고 비선형적인 경우가 많기 때문에, 미분을 통해 극값을 계산하기 어렵다. 미분을 구현하는 것보다 경사 하강법으로 최솟값을 찾는 것이 더 효율적이다. ▪️ 방향은 알지만, 최적해까지의 거리에 대한 정보가 없기 때문에 **학습률 $\\rho$**를 곱해서 조금씩 이동한다.\r$$ w_{t+1} = w_t + \\rho\\left(-{\\partial J\\over\\partial w_t}\\right) $$\n$$ w \\leftarrow w + \\eta \\left( -\\frac{\\partial L}{\\partial w}\\right) $$\n$J, L$ : 손실 함수 $\\rho,\\eta \\text{(로, 에타)}$ : 학습률 $\\leftarrow$ : 업데이트를 의미한다. 표기는 다양하다.\n매개변수가 여럿인 경우, 편미분으로 구한 기울기를 사용한다.\n매개변수마다 독립적으로 미분한다.\n$$ {\\tt{w = w + \\rho\\left(\\tt-\\triangledown w\\right)}} \\ \\tt\\triangledown w = \\left({\\partial J\\over\\partial w_0},{\\partial J\\over\\partial w_1},{\\partial J\\over\\partial w_2},\u0026hellip;,{\\partial J\\over\\partial w_d}\\right) $$\n적절한 학습률\r#\r학습률은 한번에 최적해를 향해 나아가는 거리를 의미한다.\n학습률이 너무 낮다면, 수렴하는 데 시간이 너무 오래 걸리게 되고,\n학습률이 너무 높다면, 최적해에 수렴하지 못하고 다른곳으로 발산하게 된다.\n학습률을 적절히 조정하는 것이 매우 중요하다.\r#\r기계 학습의 경사 하강법\r#\r여러 측면에서 표준 경사 하강법과 다르다. 잡음이 섞인 데이터의 개입 방대한 매개변수 일반화 능력이 필요 기계 학습에서 최적 해를 찾는 것은 쉽지 않다. 정확률이 등락을 거듭하며 수렴하지 않는 문제 훈련 집합에서의 높은 성능이 테스트 집합에서의 성능으로 이어지지 않는 문제 경사 하강법 적용 방법\r#\r1. BGD: Batch Gradient Descent\r#\r배치 모드\n틀린 샘플을 모은 다음 한꺼번에 매개변수 갱신한다.\n한 epoch에 매개변수 갱신이 단 한번만 일어난다.\n즉, 모든 샘플을 확인한 후, 최적의 방향으로 한 걸음 움직인다.\n계산량이 많고 시간이 오래 걸린다.\n2. SGD: Stochastic gradient descent(확률적 경사 하강법)\r#\r패턴 모드와 미니배치 모드의 경사하강법에는 랜덤 샘플링이 적용되기 때문에, Stochastic(확률적)이라는 수식어를 붙인다.\n데이터를 무작위로 선택하여 훨씬 적은 데이터셋으로 평균값을 추정할 수 있다.\n패턴 모드\n샘플 하나에 대해 전방 계산을 수행하고 오류에 따라 바로 매개변수 갱신\n패턴 별로 매개변수 갱신\nepoch가 시작할 때 샘플을 뒤섞어 랜덤 샘플링 효과 발생\n하나의 샘플을 확인한 후, 정보를 반영하여 바로 한 걸음 움직인다.\n반복이 충분하면 SGD가 효과를 볼 수 있지만, 노이즈가 매우 심해 최저점을 찾지 못할 수도 있다.\n미니 배치모드(딥러닝)\n배치 모드와 패턴 모드의 중간\n훈련 집합을 일정한 크기의 부분 집합으로 나눈 다음 부분 집합별로 처리한다.\n부분 집합으로 나눌 때 랜덤 샘플링을 적용한다.\n계산 속도가 훨씬 빠르다.\nLocal Minima에 빠지지 않고, Global Minima에 수렴할 가능성이 더 높다.\nbatch size\n미니배치 모드에서의 매개변수.\n배치 크기를 작게 두는 것이 Generalization 성능이 좋다.\n배치사이즈가 너무 커지면 Sharp Minimum에 빠지게 된다.\nFlat Minimum은 Generalization 성능이 좋다.\n반대로, 배치사이즈가 작을수록 noise의 영향력이 커지므로 Sharp Minimum에서 탈출할 확률이 높다.\n참고 논문 : On Large-batch Training for Deep Learning : Generalization Gap and Sharp Minima, 2017\nGradient Descent Algorithm에는 여러 문제점들이 존재하는데, 이를 해결한 Optimizer들이 등장한다.\nQuiz. $f(x,y,z)$의 그래디언트 벡터는?\n$f(x,y,z) = 9x^2 + 5y^3 - 3z$\n$\\tt ans = (18x, 15y^2, -3)$\n"},{"id":52,"href":"/posts/2023-11-13-%EC%97%B0%EA%B4%80-%EB%B6%84%EC%84%9D/","title":"연관 분석(Association Analysis) 정리","section":"Blog","content":"\r연관 규칙 분석(Association Rule Analysis)\r#\r추천 시스템의 가장 고전적인 방법론\n장바구니 분석, 서열 분석이라고도 불린다.\n상품의 구매, 조회 등 하나의 연속된 거래들 사이의 규칙을 발견하기 위해 적용하는 방법\n즉, 사용자의 장바구니 내에 포함된 상품들의 규칙을 발견하기 위해 적용하는 방법\n유저 정보(유저 행동 정보)를 활용하는 분석 방법\n규칙\nIF {condition} THEN {result}\n{condition} → {result}\n연관 규칙\n규칙 가운데 일부 기준(빈번함의 기준)을 만족하는 것\nIF {antecedent} THEN {consequent}\n빈번하게 발생하는 규칙을 의미한다.\nex) {기저귀} → {맥주}\n{우유} → {빵}\n이 때, 화살표는 연관 관계를 나타낼 뿐, 인과관계를 의미하지 않는다.\nItemset\n연관규칙을 구성하는 상품의 집합(antecedent, consequent)\n하나 이상의 집합으로 구성\nantecedent와 consequent는 disjoint(서로소)를 만족해야 한다.\nk-itemset: k개의 item으로 이루어진 itemset\nsupport count($\\sigma$)\n전체 transaction data에서 itemset이 등장하는 횟수\n$\\tt \\sigma(\\text{빵,\\ 우유}) = 3$\nsupport\nitemset에서 전체 transaction data에서 등장하는 비율\nsupport count로 계산된 값.\nsupport({빵, 우유}) = 3 / 5 = 0.6\n연관 규칙에서 가장 중요한 값.\nfrequent itemset\n유저가 지정한 minimum support 값 이상의 itemset\nminimum support 값을 넘지 못한 itemset은 infrequent itemset이라고 부른다.\n연관 규칙의 척도\r#\rfrequent itemset들 사이의 연관 규칙을 만들기 위해서 measurement가 필요하다.\n$X\\rightarrow Y$가 존재할 때, $(X,Y : \\text{itemset, N: 전체 transaction 수})$\nsupport\n두 itemset $X,Y$를 모두 포함하는 transaction의 비율\n즉, 전체 transaction에 대한 itemset의 확률값\n좋은 규칙을 찾거나, 불필요한 연산을 줄일 때 사용된다.\nconfidence\n$Y$의 $X$에 대한 조건부 확률\nconfidence가 높을수록 유용한 규칙이다.\nlift\n[$X$가 포함된 transaction가운데 $Y$가 등장할 확률] / [$Y$가 등장할 확률]\n1을 기준으로 나타난다.\n0~1 사이의 값이 아니다.\n$\\tt lift = 1 ⇒ X,Y\\ 독립$\n$\\tt lift \u0026gt; 1 ⇒ X,Y\\ 양의\\ 상관관계$\n$\\tt lift \u0026lt; 1 ⇒ X,Y\\ 음의\\ 상관관계$\n예시\nX = 빵, Y = 계란\nsupport $$ \\begin{aligned}s(X \\rightarrow Y)\u0026amp;=\\frac{n(X \\cup Y)}{N}=P(X \\cap Y)\\\u0026amp;=\\frac{n(2,5)}{5}=0.4 \\end{aligned} $$\nconfidence $$ \\begin{aligned} c(X \\rightarrow Y)\u0026amp;=\\frac{n(X \\cup Y)}{n(X)}=\\frac{n(2,5)}{n(2,4,5)}=0.66 \\\u0026amp; =P(Y \\mid X)=\\frac{P(X \\cap Y)}{P(X)}=\\frac{0.4}{0.6}=0.66\\end{aligned} $$\nlift $$ \\begin{aligned} l(X \\rightarrow Y)=\\frac{c(X \\rightarrow Y)}{s(Y)}\u0026amp;=\\frac{0.66}{0.4}=1.66 \\\u0026amp; =\\frac{P(X \\cap Y)}{P(X) P(Y)}=\\frac{s(X \\rightarrow Y)}{s(X) s(Y)}=\\frac{0.4}{0.6 \\cdot 0.4}=1.66\\end{aligned} $$\n연관 규칙의 사용\r#\rItem 수가 많아질수록, 가능한 itemset에 대한 rule의 수가 기하급수적으로 많아진다.\n이 중 유의미한 rule만 사용해야 한다.\nminimum support, minimum confidence로 의미없는 rule을 screen out\n전체 transaction 중에서 너무 적게 등장하거나, 조건부 확률이 아주 낮은 rule을 필터링한다.\nlift값으로 내림차순 정렬 후 의미있는 rule을 평가한다.\n사용자 입장에서 lift값을 사용하면 더 만족스러운 추천을 얻게 된다.\nex) 와인($X$), 와인 오프너($Y$), 생수($Z$)라고 할 때,\n$P(Y|X) = 0.1$, $P(Z|X) = 0.2$인 경우\n위 수식만 봤을 땐, 와인을 샀을 때 오프너가 아닌 생수를 살 확률이 더 높다.\n$P(Y) = 0.01$\n$P(Z) = 0.2$\n하지만, 각 물건을 살 확률을 기반으로 lift값을 계산하게되면 와인 — 와인오프너의 lift값이 10이 되고, 와인 — 생수의 lift값은 1이 된다.\nlift가 크다는 것은 rule을 구성하는 antecedent와 consequent가 연관성이 높고 유의미하다는 뜻\n연관 규칙의 탐색(Mining Association Rules)\r#\r주어진 트랜잭션 가운데, 아래 조건을 만족하는 가능한 모든 연관 규칙을 찾는다.\nsupport ≥ minimum support confidence ≥ minimum confidence 가장 쉽게 떠올리는 방법은 Bruth force.\n하지만 연산량이 너무 커서 매우 비효율적이다.\n효율적인 Association Rule Mining을 위한 단계\nFrequent Itemset Generation\nminimum support 이상의 모든 itemset을 생성한다.\n연산량이 가장 많다.\n연관 분석에서 가장 중요하다.\n생성 전략\n가능한 후보 itemset의 개수를 줄인다.\nApriori Algorithm : 가지치기를 활용하여 탐색해야 하는 M을 줄인다. 탐색하는 transaction의 숫자를 줄인다.\nItemset의 크기가 커짐에 따라 전체 N개 transaction보다 적은 개수를 탐색한다.\nDHP(Direct Hashing \u0026amp; Pruning) Algorithm 탐색 횟수를 줄인다.\n효율적인 자료구조를 사용하여 후보 itemset과 transaction을 저장한다.\n모든 itemset과 transaction의 조합에 대해 탐색할 필요가 없다.\nFP — Growth Algorithm Rule Generation\nminimum confidence 이상의 association rule을 생성한다.\n이 때, rule을 이루는 antecedent와 consequent는 서로소를 만족해야 한다.\n"},{"id":53,"href":"/posts/2023-06-14-%EC%9D%B8%EA%B8%B0%EB%8F%84-%EA%B8%B0%EB%B0%98-%EC%B6%94%EC%B2%9C/","title":"인기도 기반 추천이란?","section":"Blog","content":" 간단 요약\n가장 인기있는 아이템을 규칙을 기반으로 추천한다.\n인기도의 척도\n- 조회수, 평균 평점, 리뷰 개수, 좋아요/싫어요 수\n예시 네이버 쇼핑 랭킹 순 다음 뉴스, 댓글 추천 레딧 Hot 추천 Score 계산 방법\r#\rMost Popular: 조회수가 가장 많은 아이템\r#\r최신성을 고려하지 않으면 한번 조회수가 높은 아이템이 계속 추천되게 된다.\nScore Formula\n가장 많이 조회된 뉴스를 추천하기\n좋아요가 가장 많은 게시글을 추천하기\nHacker News Formula\n뉴스 추천 서비스\n$$ score = \\frac{pageviews -1}{(age + 2)^{gravity}} $$\ngravity = 1.8 조회수를 기반으로 추천해주면서, 시간이 지남에 따라 스코어를 감소시킨다.\nRaddit Formula\n시간에 따른 가점 방식\n$$ score = \\log_{10}{(ups-downs)} + \\frac{sign(ups-downs)\\times seconds}{45000} $$\n첫번째 term — Popularity\n해당 값이 높아질수록 점수가 높아진다.\nlog scale이기 때문에, 첫 vote가 가장 가치가 높고, vote가 쌓일수록 영향력이 점점 약해진다.\n두번째 term — 포스팅이 게시된 절대 시간\n최근 포스팅일수록 절대 시간값이 높기 때문에, 더 높은 score을 가진다.\nHighly Rated: 평균 평점이 가장 높은 아이템\r#\r평점의 신뢰도를 파악할 필요가 있다.\n평가의 개수가 충분한지도 고려해야 한다.\nSteam Rating Formula\n$$ avg_rating = \\frac{\\text{# of positive review}}{\\text{# of reviews}} $$\n$$ score = avg_rating - (avg_rating - 0.5) \\times 2^{-\\log\\text{(# of reviews)}} $$\nrating은 평균값을 사용하되, 전체 review 개수에 따라 rating을 보정한다.\nreview 개수가 아주 많아지면 score은 평균 rating과 거의 비슷해진다.\nSteam Rating Formula → Movie Rating\n$$ avg_rating = \\frac{\\text{# of positive review}}{\\text{# of reviews}} $$\n$$ score = avg_rating - (avg_rating - 3.0) \\times 2^{-\\log\\text{(# of reviews)}} $$\n"},{"id":54,"href":"/posts/2023-09-27-Recsys-Overview/","title":"추천 시스템 개요","section":"Blog","content":" Naver BoostCamp AI Tech에서 학습한 내용을 재구성했습니다.\n해당 게시글은 지속적으로 업데이트할 예정입니다.\n노션에 정리했던 내용을 복습하며 블로그에 조금씩 업로드하고 있습니다.\n{: .prompt-info }\n추천 시스템\r#\r추천 시스템 평가 패러다임\r#\rRule Base\r#\r인기도 기반 추천\n연관 분석(Association Analysis)\nCBF: Content Based Filtering\r#\r1. Vectorizer — 아이템 특성을 벡터 형태로 어떻게 표현하는가\r#\rTF-IDF\nTF-IDF 기반 추천\nBM25\nWord2Vec\n2. Similarity — 특성화된 아이템이 서로 얼마나 비슷한가\r#\rSimilarity\nDistance\nCF: Collaborative Filtering(협업 필터링)\r#\rNBCF: Neighborhood-based CF(이웃 기반 협업 필터링)\r#\rMBCF: Model based Collaborative Filtering(모델 기반 협업 필터링)\r#\rSupervised Learning Model\rML based CF\nNaive Bayes Classification GBM: Gradient Boosting Machine GBDT: Gradient Boosting Decision Trees XGBoost: Extreme gradient boosting LGBM: LightGBM CatBoost DL based CF\nBackground\rDL based CF의 장점\nNonlinear Transformation\ndata의 non-linearity를 효과적으로 나타낼 수 있다.\n복잡한 user-item interaction pattern을 효과적으로 모델링\nuser의 선호도 예측 용이\nRepresentation Learning\n사람이 직접 feature design하지 않아도 된다. 텍스트, 이미지, 오디오 등 다양한 종류의 정보를 추천 시스템에 활용할 수 있다. 과거 아이템의 이미지를 활용하여 새로운 아이템에 대한 특징 추출 가능 사용자가 남긴 텍스트를 활용하여 취향에 대한 특징 추출 가능 새로운 아이템이나 인기 없는 아이템도 추천이 가능 사용자에게 아이템을 왜 추천하는 이유에 대한 설명력이 증가 다양한 맥락 정보를 함께 활용하기 때문에 보다 정교한 추천이 가능 Sequence Modeling\nDNN은 자연어처리, 음성 신호 처리 등 sequential modeling task에서 성공적으로 적용된다. 추천 시스템에서 next-item prediction, session-based recommendation등에 사용된다. Various Architectures\nCNN, RNN 등 비정형 데이터 특징 추출에 특화된 구조 활용이 가능하다. Flexibility\nTensorflow, PyTorch 등 다양한 DL 프레임워크 오픈 추천시스템 모델링 flexibility가 높으며 더 효율적으로 서빙할 수 있다. end-to-end 구조로써 Domain adaptation,Generative modeling등의 응용 모델 활용이 가능하다. 단점\nInterpretability → Black Box Data Requirement → 많은 양의 데이터 필요 Extensive Hyperparameter Tuning → 많은 시간 소요 추천에서는 DL이 ML을 압도하지는 않는다.\n추천을 수행할 때 Latency가 중요하기 때문에, 너무 복잡한 모델은 사용하지 못한다.\nMLP: Multilayer Perceptron(다층 퍼셉트론) 계열 모델\nNCF: Neural Collaborative Filtering YouTube Recommendation AE: Autoencoder(오토인코더) 계열 모델\n입력값 (rating)을 reconstruction (decoding) 할 수 있게끔 학습함으로써 rating이 가지고 있는 잠재적인 패턴이 latent factor(information bottleneck)에 암호화 (encoding)된다.\nDAE: Denoising Autoencoder\nU/I-RBM AutoRec NeuMF: Neural MF CDAE: Collaborative Denoising Auto-Encoder GNN: Graph Neural Network 계열 모델\nGCN: Graph Convolution Network\nNGCF: Neural Graph Collaborative Filtering LightGCN CNN: Convolutional Neural Network(컨볼루션 신경망) 계열 모델\nImage-Based Recommendations VBPR: Visual BPR DeepCoNN(심층 협력 신경망) RNN:Recurrent Neural Network(순환신경망) 계열 모델\nLSTM(Long Short Term Memory), GRU(Gated Recurrent Unit)\nGRU4Rec RRN: Recurrent Recommender Network WDN: Wide \u0026amp; Deep Network DeepFM DIN: Deep Interest Network DCN: Deep \u0026amp; Cross Network BST: Behavior Sequence Transformer TabNet Unsupervised Learning Model\rBackground : User-free Model\r비지도학습 모델들 중, User-free 모델로 활용되는 경우가 많다.\rUser-free 모델의 장점 ($=\\gamma_u$를 사용하지 않을 때의 장점)\n새로운 사용자에 대해 inference가 가능하다.\n$\\gamma_u$는 새로운 사용자가 발생할 때마다 재학습을 필요로 한다.\n이력이 거의 없는 사용자에 대한 대응이 가능하다.\nMF 계열의 모델은 이런 상황에서 $\\gamma_u$가 제대로 학습되지 않으므로 성능이 좋지 않다.\nCF 모델에서 종종 무시되곤 하는 sequential 시나리오에 대해 대응이 가능하다.\nMF의 $\\gamma_u$는 sequence를 고려하지 않는다.\n실제 추천 시스템의 deployment를 고려하면, 새로운 사용자가 발생할 때마다 재학습이 필요한 점은 큰 단점이다. 따라서, user-free 모델은 전통적인 MF 계열의 모델보다 실용적이라고 볼 수 있다. Latent Factor Model(Embedding)\nSVD: Singular Value Decomposition(특이값 분해)\nMF: Matrix Factorization\nWRMF: Weighted Regularized MF (MF for Implicit Feedback) ALS: Alternating Least Square BPR: Bayesian Personalized Ranking Feedback\nWord2Vec CBOW: Continous Bag of Word SG: Skip-Gram SGNS: Skip-Gram with Negative Sampling Item2Vec Clustering(군집화)\nKNN: K-Nearest Neighbor(K-최근접 이웃)\nANN: Approximate Nearest Neighbor\nANNOY: Approximate Nearest Neighbor Oh Yeah HNSW: Hierarchical Navigable Small World Graphs IVF: Inverted File Index PQ: Product Quantization — Compression Clustering의 경우 다른 추천 방법론과 함께 사용하여 효과적인 추천 수행이 가능하다.\n군집내의 다른 사용자가 선호하는 아이템 추천 군집화 이후 협력 필터링(Collaborative Filtering) 사용을 통해 예측 정확도 향상 비슷한 사용자 군집의 데이터를 추출하여 아이템 선호도를 계산하고, 이를 사전 확률(prior probability)로 활용하여 베이지안 방법론 적용 RL(강화 학습)\r#\rMAB: Multi-Armed Bandit\r#\rHybrid CF\r#\rCARS: Context-aware Recommender System(맥락 기반 추천 시스템)\r#\rFM: Factorization Machine FFM: Field-aware Factorization Machine 추천 라이브러리\r#\rSurprise Implicit Lightfm MSrecommenders Spotlight Buffalo Torchrec TFrecommenders "},{"id":55,"href":"/posts/2023-06-06-%EC%B6%94%EC%B2%9C-%EC%8B%9C%EC%8A%A4%ED%85%9C-%ED%8F%89%EA%B0%80-%EC%A7%80%ED%91%9C/","title":"추천 시스템 평가 패러다임","section":"Blog","content":" MAP, NDCG\n비즈니스 / 서비스 관점\n추천 시스템 적용으로 인해 매출, PV(Page View) 증가\n추천 아이템으로 인해 유저 CTR(노출 대비 클릭)의 상승\n품질 관점\n정확성(Accuracy)\n연관성(Relevance): 추천된 아이템이 유저에게 관련이 있는가?\n다양성(Diversity): 추천된 Top-K 아이템에 얼마나 다양한 아이템이 추천되는가?\n신뢰성(Confidence) : 추천 결과를 제공하는 시스템이 신뢰할 만한가?\n표준편차가 적은 추천 시스템일수록 더 높은 Confidence를 가진다.\n신뢰성(Trust) : 사용자가 추천 결과에 얼마나 믿음을 가지는가?\n추천 결과에 설명이 추가된다면 사용자가 추천 결과를 더 믿게 된다.\nNovelty와 Trust는 Trade-off 관계에 있다.\n사용자가 이미 알고 있거나 좋아하는 아이템을 추천하면 추천 결과에 대한 신뢰도가 올라간다.\n적용 범위(Coverage): 추천되는 아이템이 전체 중 얼마나 차지하는가?\n개인화(Personalization): 개인화된 아이템이 추천되고 있는가?\n새로움(Novelty): 얼마나 새로운 아이템이 추천되고 있는가?\n인기 항목만 추천하는 경우를 줄이기 위해 사용\n참신함(Serendipity): 유저가 기대하지 못한 뜻밖의 아이템이 추천되는가?\nSerendipity ≠ novelty (un-awareness) Serendipity = novelty + relevance + unexpectedness 강인함(Robustness \u0026amp; Stability)\nScalability : 추천 시스템이 대용량 데이터 및 트래픽을 효과적이고 효율적으로 처리할 수 있는가?\n평점 예측 평가\r#\r(user, item) 쌍에 대한 compatibility score를 직접 예측한다.\nRMSE: Root Mean Squared Error\nMAE: Mean Absolute Error\nAUC\n랭킹 평가\r#\rTop-K Ranking은 user별로 예측된 compatibility score 순서에 따라 ranked list of items를 생성한다.\nUser Study\r#\r사용자들을 모집해서 시스템과 상호작용하게 한 후 피드백을 수집한다.\n활발한 사용자 참여에 바탕을 두고 있기 때문에, 실제 사용환경과 동떨어지는 경우도 있다.\n균일한 집단을 만들기 위해선 많은 시간과 비용이 소모되기 때문에, 현실적으로 적용하기가 쉽지 않다.\nOffline Test\r#\r이미 수집된 데이터 (historical datasets)를 활용하여 알고리즘의 성능을 평가하는 방법\n과거 데이터를 바탕으로 모델의 성능을 파악한다.\n새로운 추천 모델을 검증하기 위해 가장 우선적으로 수행되는 단계\n유저로부터 수집한 데이터를 train/valid/test로 나누어 모델의 성능을 객관적인 지표로 평가\n데이터 분할 전략에 따라서 시스템 성능 평가에 큰 영향을 줄 수 있다. 상황에 맞는 적절한 분할 전략이 필요 데이터 분할 전략\nLeave One Last\n사용자당 마지막 구매를 Test set으로, 마지막에서 2번째를 Valid set으로 분할\n장점\n학습 시 많은 데이터 사용 가능\n단점\n사용자당 마지막 구매로만 평가하므로 테스트 성능이 전체적인 성능을 반영한다고 보기 어렵다. 훈련 중에 모델이 테스트 데이터 상호작용을 특징으로 학습할 가능성 존재 Temporal User / Global Split\n시간을 이용한 분할 전략\nTemporal User 사용자 별로 시간 순서에 따라 일정 비율로 데이터 분할 Leave One last와 유사 Data leakage 문제 Temporal Global (권장됨) 각 유저 간에 공유되는 시점을 고정하여, 특정 시점 이후에 이뤄진 모든 상호작용을 test set으로 분할 학습 및 검증에 사용할 수 있는 상호작용이 적은 문제 현실과 가장 유사한 평가 환경을 제공 Random Split\n각 사용자 별 interaction을 random하게 아이템을 선택하여 분할\n사용하기 쉬움 많은 train set Data leakage 문제 User Split\n사용자가 겹치지 않게 사용자를 기준으로 분할\nCold-start 문제에 대응하는 모델 생성 가능 User-free 모델에만 사용 가능 Future Data leakage 문제 CV: Cross Validation(교차 검증)\n보통 offline test에서 좋은 성능을 보여야 online test에 투입된다.\n실제 서비스 상황에서는 다양한 양상을 보인다.(serving bias)\n한계\n결측값을 아무리 추론한다고 하더라도, 실제 유저가 좋아할지 싫어할지는 알 수 없다. 데이터 수집 이후, 시간의 흐름에 따라 사용자 선호도 및 아이템의 특성이 변화하는 것을 반영할 수 없다. accuracy 관련 지표만으로는 serendipity 및 novelty 와 같은 추천 시스템의 중요한 특성을 포착할 수 없다. 추천 시스템에 존재하는 feedback loop로 인해 다양한 bias들이 증폭되기 때문에 부정확한 상대평가로 이어질 수 있다. Data Bias Selection Bias Precision/Recall/MAP@K\r#\rPrecision@K\n우리가 추천한 K개 아이템 가운데 실제 유저가 관심있는 아이템의 비율\ndef precision_at_k(actual, predicted, k): act_set = set(actual) pred_set = set(predicted[:k]) result = len(act_set \u0026amp; pred_set) # normalized_prec = result / float(min(len(act_set),k)) return prec Recall@K\n유저가 관심있는 전체 아이템 가운데 우리가 추천한 아이템의 비율\ndef recall_at_k(actual, predicted, k): act_set = set(actual) pred_set =set(predicted[:k]) result = len(act_set \u0026amp; pred_set) / float(len(act_set)) return result ex) 우리가 추천한 아이템 개수: 5(=K)\n추천한 아이템 중 유저가 관심있는 아이템 개수: 2\n유저가 관심있는 아이템의 전체 개수: 3\n$\\tt Precision@5 = 2/5$\n$\\tt Recall@5 = 2/3$\nAP@K\nPrecision@1부터 Precision@K까지의 평균값\nPrecision@K와 달리, 관련 아이템을 더 높은 순위에 추천할수록 점수가 상승한다.\n$$ A P @ K=\\frac{1}{m} \\sum_{i=1}^K \\text { Precision@i } $$\nMAP(Mean AP)@K\n모든 유저에 대한 Average Precision 값의 평균\n$$ M A P @ K=\\frac{1}{|U|} \\sum_{u=1}^{|U|}(A P @ K)_u $$\nnDCG: Normalized Discounted Cumulative Gain\r#\r추천 시스템에 가장 많이 사용되는 지표 중 하나\n검색(IR)에서 등장한 지표.\nPrecision@K, MAP@K와 마찬가지로 Top K 리스트를 만들고 유저가 선호하는 아이템을 비교하여 값을 구한다.\nMAP@K와 마찬가지로 추천의 순서에 가중치를 더 많이 두어 성능을 평가하며, 1에 가까울수록 좋다.\nMAP와 달리, 연관성을 이진값이 아닌 수치로도 사용할 수 있다.\n유저에게 얼마나 더 관련 있는 아이템을 상위로 노출시키는지 알 수 있다.\nCG\n상위 K개 아이템의 관련도를 합한 것\n순서에 따라 Discount하지 않고, 동일하게 더한 값\n$$ C G_K=\\sum_{i=1}^K r e l_i\n$$\nDCG\n순서에 따라 Cumulative Gain을 Discount한다.\n$$ D C G_K=\\sum_{i=1}^K \\frac{r e l_i}{\\log _2(i+1)} $$\nIdeal DCG\n이상적인 추천이 일어났을 때의 DGC값\n즉, DCG의 최대값\n$$\nI D C G=\\sum_{i=1}^K \\frac{r e l_i^{o p t}}{\\log _2(i+1)}\n$$\nNormalized DCG\n$$ N D C G=\\frac{D C G}{I D C G} $$\nOnline A/B Test\r#\r동시에 대조군 A와 B의 성능을 평가한다.\n(대조군과 실험군의 환경은 최대한 동일해야 한다.)\n실제 서비스를 통해 얻어지는 결과를 통해 최종 의사결정이 이루어진다.\n대부분 현업에서 의사결정에 사용하는 최종 지표는 모델 성능이 아닌 매출, CTR 등의 비즈니스/서비스 지표\nMRR: Mean Reciprocal Rank\r#\r$$ M R R=\\frac{1}{|U|} \\sum_{u \\in U} \\frac{1}{\\operatorname{rank}_u\\left(i_u\\right)} $$\n"},{"id":56,"href":"/posts/2023-10-05-%EC%B6%94%EC%B2%9C-%EC%8B%9C%EC%8A%A4%ED%85%9C/","title":"추천 시스템이란?","section":"Blog","content":" 정보 필터링(IF) 기술의 일종. 특정 사용자가 관심 가질 만한 정보를 추천하는 것. Background\r#\r기존\n유저가 원하는 것을 검색하여 이에 맞는 아이템 결과를 보여주는 Pull 방식\n추천 시스템\n유저가 원하는 것을 유추하여 제시하는 Push 방식\n유저가 자신의 니즈를 쿼리로 표현하지 않아도 된다.\n다양한 종류의 아이템들을 유저에게 노출시킬 수 있다.\n추천 시스템의 필요성\n과거에는 유저가 접할 수 있는 상품, 컨텐츠가 제한적\nTV 채널, 영화관, 백화점, 신문 등\n웹/모바일 환경에 의해 다양한 상품, 컨텐츠 등장 → 정보 과다.\n일부 유명한 아이템이 많이 소비되는 것(\rThe Long Tail Phenomenon)이 아니라, 아주 많은 Long Tail 아이템이 추천을 통해 소비된다.(Long Tail 추천)\n정보를 찾는데 시간이 오래 걸린다.\n유저가 원하는 걸 어떤 키워드로 찾아야 하는지 모를 수 있다.\nLong Tail Recommendation 사례\n유튜브 동영상 추천 SNS 친구 추천 추천 시스템의 목적\n정보 수집, 탐색 시간 단축하기 선택의 폭을 넓히기 유저 → 아이템\n특정 유저에게 적합한 아이템을 추천\n아이템 → 유저\n특정 아이템에게 적합한 유저 추천\n추천시스템에서 사용하는 정보\r#\r유저 관련 정보\n유저 프로파일링\n추천 대상 유저에 관련된 정보를 구축하여, 개별 유저 혹은 유저 그룹별로 추천\n식별자(Idendifier)\n유저 ID, 디바이스 ID, 브라우저 쿠키\n데모그래픽 정보\n성별, 연령, 지역, 관심사\n유저 행동 정보\n페이지 방문 기록, 아이템 평가, 구매 등의 피드백 기록\n아이템 관련 정보\n추천 아이템 종류\n포탈: 뉴스, 블로그, 웹툰 등 컨텐츠 추천 광고/커머스: 광고 소재, 상품 추천 미디어: 영화, 음악, 동영상 추천 아이템 프로파일링\n아이템 ID 아이템의 고유정보 Content base Recommendation에서는 아이템의 고유정보만 활용하기도 한다. 상호작용 정보(유저 — 아이템)\n유저와 아이템의 상호작용 데이터\n유저가 온/오프라인에서 아이템과 상호작용할 때 발생하는 로그\n추천 시스템을 학습하는 데이터의 Feedback이 된다.\nExplicit Feedback\n유저에게 아이템에 대한 만족도를 직접 물어본 경우\nex) 영화에 대한 평점\nImplicit Feedback\n유저가 아이템을 클릭하거나 구매한 경우\nex) 쿠팡에서 아이템을 구매하면 → Implicit feedback = Y\n추천 Task\r#\r랭킹(Ranking)\r#\r유저에게 적합한 아이템 Top K개를 추천하는 문제\n평가 지표: Precision@K, Recall@K, MAP@K, nDCG@K\nTop K개를 선정하기 위한 기준 혹은 Score 필요하다. 유저(X)가 아이템(Y)에 가지는 정확한 선호도를 구할 필요는 없다. Top-k Ranking 문제는 0과 1의 binary-value로 이뤄진 implicit feedback을 예측하는 태스크에 주로 사용된다.\n예측(Prediction)\r#\r유저가 아이템에 가질 선호도를 정확하게 예측(평점 or 클릭/구매 확률)\n평가 지표: MAE, RMSE, AUC\nExplicit Feedback: 철수가 아이언맨에 대해 내릴 평점값을 예측 Implicit Feedback: 영희가 아이폰12를 조회하거나 구매할 확률을 예측 유저 — 아이템 행렬을 채우는 문제 real-value로 이뤄진 explicit feedback을 예측하는 태스크에 주로 사용된다.\n추천 시스템 특징\n도메인에 대한 높은 의존성 도메인 지식에서 비롯된 인사이트가 많다. 다양한 데이터를 볼 수 있는 기회에 대한 중요성이 크다. 폐쇄적인 데이터 대상 데이터인 User Data와 Item Data는 대부분 기업 내부의 기밀 사항에 해당한다. 추천 시스템 종류\r#\rSimple Aggregate (popularity, average score, recent uploads) Association Analysis Content-based Recommendation Collaborative Filtering Item2Vec Recommendation and ANN Deep Learning-based Recommendation Context-aware Recommendation Multi-Armed Bandit(MAB)-based Recommendation #\r추천 시스템에서는 ML을 주요하게 사용한다.\nML의 성능을 압도하는 DL이 아직 나오지 않았다.\n많은 유저가 사용하는 Service에서 큰 트래픽을 감당해야 한다.\n최대한 가벼운 모델을 쓰게 된다.\n추천 시스템의 분석 프로세스\r#\rPreprocessing\r#\rData Transform Data Split Data Split Strategy Random split by ratio Random split by user Leave one out split Split by timepoint Model\r#\rContent-Based Filtering Collaborative Filtering Context Aware Recommendation Hybrid(Content-Based Filtering + Collaborative Filtering) Evaluation\r#\rPrediction — Explicit Feedback을 예측하는 태스크에 주로 사용\nMAE MSE RMSE Rank — Implicit Feedback을 예측하는 태스크에 주로 사용\nPrecision@K Recall@K AP@K MAP@K NDCG@K "}]