<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Back Propagation on OMIN</title>
    <link>https://osmin625.github.io/tags/back-propagation/</link>
    <description>Recent content in Back Propagation on OMIN</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Fri, 27 May 2022 20:54:00 +0900</lastBuildDate>
    <atom:link href="https://osmin625.github.io/tags/back-propagation/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>경사 하강법에 오차 역전파가 없다면 무슨 일이 일어날까?</title>
      <link>https://osmin625.github.io/posts/%EC%88%98%EC%B9%98-%EB%AF%B8%EB%B6%84/</link>
      <pubDate>Fri, 27 May 2022 20:54:00 +0900</pubDate>
      <guid>https://osmin625.github.io/posts/%EC%88%98%EC%B9%98-%EB%AF%B8%EB%B6%84/</guid>
      <description>손실 함수, Gradient Descent, Back Propagation&#xA;수치 미분 한 점에서의 기울기. 변화량을 의미한다.&#xA;경사 하강법을 사용하기 위해서는 미분값이 필요하다.&#xA;$$ {df(x)\over dx} = \lim_{h \to 0} {f(x+h) - f(x)\over h} $$&#xA;수치 미분이 경사 하강법에 사용되는 방법 경사 하강법에서는 $f(x)$가 손실 함수이고, x가 현재의 가중치나 편향이 된다.&#xA;손실 함수는 대상 값과 예측 값의 오차를 의미하므로,&#xA;손실 함수에 대한 미분 값을 구한 후, 오차를 줄이는 방향으로 가중치와 편향을 수정할 수 있다.</description>
    </item>
    <item>
      <title>Back Propagation(오차 역전파 알고리즘)</title>
      <link>https://osmin625.github.io/posts/backpropagation/</link>
      <pubDate>Fri, 22 Apr 2022 23:21:00 +0900</pubDate>
      <guid>https://osmin625.github.io/posts/backpropagation/</guid>
      <description>이 알고리즘으로 인해 ML Network에서의 학습이 가능하다는 것이 알려져, 암흑기에 있던 신경망 학계가 다시 관심을 받게 되었다.&#xA;출력층에서 시작하여 역방향으로 오류를 전파한다는 뜻에서 오류 역전파라 부른다.&#xA;내가 뽑고자 하는 target값과 실제 모델이 계산한 출력의 차이를 계산한다. 오차값을 다시 뒤로 전파해가면서 각 노드가 가지고 있는 변수들을 갱신한다. 직관적인 이해는 끝났다. 이제 제대로 이해해보자.&#xA;오차 역전파가 중요한 이유를 알고 싶다면, 여기를 클릭하여 오차 역전파가 없을 시에 발생하는 문제점을 이해하자.&#xA;오차 역전파 신경망을 학습하는 방법.</description>
    </item>
  </channel>
</rss>
