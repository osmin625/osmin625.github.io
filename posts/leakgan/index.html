<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    
    
    
    
    

    
    <title>[논문 리뷰] LeakGAN: Long Text Generation via Adversarial Training with Leaked Information</title>
    <meta name="description" content="Interested in ML Engineering, Data Science.">
    <meta name="keywords" content='blog, gokarna, hugo, LeakGAN, GAN, Reinforcement Learning, Temperature Parameter, Highway Network, Paper Review'>

    <meta property="og:url" content="https://osmin625.github.io/posts/LeakGAN/">
    <meta property="og:type" content="website">
    <meta property="og:title" content="[논문 리뷰] LeakGAN: Long Text Generation via Adversarial Training with Leaked Information">
    <meta property="og:description" content="Interested in ML Engineering, Data Science.">
    <meta property="og:image" content="https://osmin625.github.io/images/from_scratch.webp">
    <meta property="og:image:secure_url" content="https://osmin625.github.io/images/from_scratch.webp">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="[논문 리뷰] LeakGAN: Long Text Generation via Adversarial Training with Leaked Information">
    <meta name="twitter:description" content="Interested in ML Engineering, Data Science.">
    <meta property="twitter:domain" content="https://osmin625.github.io/posts/LeakGAN/">
    <meta property="twitter:url" content="https://osmin625.github.io/posts/LeakGAN/">
    <meta name="twitter:image" content="https://osmin625.github.io/images/from_scratch.webp">

    
    <link rel="canonical" href="https://osmin625.github.io/posts/LeakGAN/" />

    
    <link rel="stylesheet" type="text/css" href="/css/normalize.min.css" media="print">

    
    <link rel="stylesheet" type="text/css" href="/css/main.min.css">

    
    <link id="dark-theme" rel="stylesheet" href="/css/dark.min.css">

    
    <script src="/js/bundle.min.4ffdc838c15e2e2971b91a99fe21b6cfe58ddb8410dd0e3487b6b9b92cc3caaa.js" integrity="sha256-T/3IOMFeLilxuRqZ/iG2z&#43;WN24QQ3Q40h7a5uSzDyqo="></script>

    
    
</head>
<body>
        <script type="text/javascript">
            
            setThemeByUserPref();
            
            const sessionId = getSessionId();
            console.log('현재 세션 ID:', sessionId);
        </script><header class="header">
    <nav class="header-nav">

        
        <div class="avatar">
            <a href="https://osmin625.github.io">
                <img src='/images/from_scratch.webp' alt="OMIN" />
            </a>
        </div>
        

        <div class="nav-title">
            <a class="nav-brand" href="https://osmin625.github.io">Robust dev O</a>
        </div>

        <div class="nav-links">
            
            <div class="nav-link">
                <a href="https://osmin625.github.io/"><span data-feather='home'></span> Home </a>
            </div>
            
            <div class="nav-link">
                <a href="https://osmin625.github.io/categories/"><span data-feather='list'></span> Categories </a>
            </div>
            
            <div class="nav-link">
                <a href="https://osmin625.github.io/tags/"><span data-feather='tag'></span> Tags </a>
            </div>
            
            <div class="nav-link">
                <a href="https://osmin625.github.io/posts/"><span data-feather='book'></span> archive </a>
            </div>
            

            <span class="nav-icons-divider"></span>
            <div class="nav-link dark-theme-toggle">
                <span id="dark-theme-toggle-screen-reader-target" class="sr-only"></span>
                <a>
                    <span id="theme-toggle-icon" data-feather="moon"></span>
                </a>
            </div>

            <div class="nav-link" id="hamburger-menu-toggle">
                <span id="hamburger-menu-toggle-screen-reader-target" class="sr-only">menu</span>
                <a>
                    <span data-feather="menu"></span>
                </a>
            </div>

            
            <ul class="nav-hamburger-list visibility-hidden">
                
                <li class="nav-item">
                    <a href="https://osmin625.github.io/"><span data-feather='home'></span> Home </a>
                </li>
                
                <li class="nav-item">
                    <a href="https://osmin625.github.io/categories/"><span data-feather='list'></span> Categories </a>
                </li>
                
                <li class="nav-item">
                    <a href="https://osmin625.github.io/tags/"><span data-feather='tag'></span> Tags </a>
                </li>
                
                <li class="nav-item">
                    <a href="https://osmin625.github.io/posts/"><span data-feather='book'></span> archive </a>
                </li>
                
                <li class="nav-item dark-theme-toggle">
                    <span id="dark-theme-toggle-screen-reader-target" class="sr-only">theme</span>
                    <a>
                        <span id="theme-toggle-icon" data-feather="moon"></span>
                    </a>
                </li>
            </ul>

        </div>
    </nav>
</header>
<main id="content">
    <div class="post container">
    <div class="post-header-section">
        <h1>[논문 리뷰] LeakGAN: Long Text Generation via Adversarial Training with Leaked Information</h1>
        <small role="doc-subtitle"></small>
        <p class="post-date">10월 7, 2023
        
        </p>

        <ul class="post-tags">
        
            <li class="post-tag"><a href="https://osmin625.github.io/tags/LeakGAN">LeakGAN</a></li>
        
            <li class="post-tag"><a href="https://osmin625.github.io/tags/GAN">GAN</a></li>
        
            <li class="post-tag"><a href="https://osmin625.github.io/tags/Reinforcement-Learning">Reinforcement Learning</a></li>
        
            <li class="post-tag"><a href="https://osmin625.github.io/tags/Temperature-Parameter">Temperature Parameter</a></li>
        
            <li class="post-tag"><a href="https://osmin625.github.io/tags/Highway-Network">Highway Network</a></li>
        
            <li class="post-tag"><a href="https://osmin625.github.io/tags/Paper-Review">Paper Review</a></li>
        
        </ul>
    </div>

    <div class="post-content">
        <p>
            <blockquote>
<p>✔️ <strong>간단 요약</strong><br>
Sparsity와 Non-Informative를 효과적으로 해결한다.</p>
<p>분별망에게 스파이를 심어 생성망이 분별망을 더 잘 속일 수 있도록 구성한다.</p>
<p>Hierarchical RL architecture (MANAGER, WORKER)</p>
<ul>
<li>
<p>MANAGER (LSTM)</p>
<ul>
<li>중재자 역할</li>
<li>D로부터 고수준 feature representation을 받음 → <em>Leakage</em></li>
</ul>
</li>
<li>
<p>WORKER (LSTM)</p>
<ul>
<li><code>$s_t$</code>를 인코딩한 후, MANAGER가 넘겨준 Goal 임베딩과 결합한다. (내적)</li>
</ul>
<p>D가 넘겨준 guiding signal은 scalar 보상 값으로도 쓰이고, 문장 생성 과정에서 Goal 임베딩으로도 쓰인다.
{: .prompt-info }
logit, temperature parameter, highway network(gate), leakgan의 3가지 학습 방법, CNN for text classification, truncated normalization</p>
</li>
</ul>
</blockquote>
<h2 id="배경">배경</h2>
<h3 id="1-rnn--문장-생성을-위한-가장-기본적인-방법">1. <strong>RNN – 문장 생성을 위한 가장 기본적인 방법</strong></h3>
<ul>
<li>
<p>이전에 생성된 단어를 활용하여 다음 단어를 생성해내는 방식</p>
</li>
<li>
<p><del>ground-truth 단어들의 log-likelihood를 최대화한다.</del></p>
</li>
<li>
<p>Supervising(Ground-Truth에 대한 설정) 필요</p>
</li>
<li>
<p>학습과 추론 단계의 불일치에 의해 편차가 발생</p>
<p>해결책으로 Scheduled sampling approach 제안 → 실패</p>
</li>
</ul>
<h3 id="2-gan--목적은-생성망-g의-성능을-개선하는-것">2. <strong>GAN – 목적은 생성망 G의 성능을 개선하는 것</strong></h3>
<ul>
<li>이를 위해 생성물의 진위 여부를 평가하는 분별망 D와 대립</li>
<li>Jenson-Shannon 거리 활용</li>
<li>생성망의 성능이 충분히 좋아지면 분별망 갖다버림</li>
</ul>
<h3 id="3-gan의-한계-및-해결책"><strong>3. GAN의 한계 및 해결책</strong></h3>
<ul>
<li>
<p>제한적인 생성 가능한 문장의 길이(최대 20단어)</p>
</li>
<li>
<p><strong>Non-informative guiding signal</strong></p>
<p>문장 → 스칼라 값(guiding signal)</p>
<p>변환 과정에서 G가 학습하는 문장의 구조 및 의미를 보장하지 않음.</p>
<p>⇒ D가 G에게 점수와 함께 임베딩(feature representation)을 제공하여 해결</p>
<p>G는 D의 feature representation에 일치하도록 임베딩 학습</p>
</li>
<li>
<p><strong>Sparsity</strong></p>
<p>긴 문장 생성 시 binary guiding signal을 활용 → 전체 문장이 생성되었을 때만 가능</p>
<p>⇒ 문장 생성을 여러 단계(계층)으로 구분하여 signal을 더 많이 제공</p>
<p>Sparsity가 일부 해결될 뿐만 아니라, Task가 작아져 모델 학습 용이</p>
<p><strong>but, 문장 생성 단계에 대한 사전 정의가 필요</strong></p>
<p><strong>⇒ 랜덤 문장 생성에는 적용 불가능</strong></p>
</li>
</ul>
<h2 id="아이디어">아이디어</h2>
<p>Sparsity와 Non-Informative를 효과적으로 해결하기 위해 <strong>LeakGAN</strong> 제안한다.</p>
<p>분별망에게 스파이를 심어 생성망이 분별망을 더 잘 속일 수 있도록 구성한다.</p>
<h3 id="manager-lstm"><strong>MANAGER (LSTM)</strong></h3>
<ul>
<li>중재자 역할</li>
<li>D로부터 고수준 feature representation을 받는다. → <em>Leakage</em>
<ul>
<li>따라서 해당 정보는 전역적으로 관리된다.</li>
<li>물론 게임 진행 중에는 G에게 해당 정보를 제공하지 않는다.</li>
<li>해당 정보를 바탕으로 Goal 임베딩 생성 후 WORKER에게 넘긴다.</li>
</ul>
</li>
</ul>
<h3 id="worker-lstm"><strong>WORKER (LSTM)</strong></h3>
<ul>
<li>현재까지 생성된 문장을 인코딩한 후, MANAGER가 넘겨준 Goal 임베딩과 결합한다. (내적)</li>
</ul>
<p>D가 넘겨준 guiding signal은 scalar 보상 값으로도 쓰이고, 문장 생성 과정에서 Goal 임베딩으로도 쓰인다.</p>
<h1 id="구체적-방법론">구체적 방법론</h1>
<p><img src="/imgs/leakgan.png" alt="leakgan"></p>
<p>텍스트 생성 문제 → Sequential Decision Making Process</p>
<ul>
<li><code>$s_t : t$</code> 시점까지 생성된 단어들. <code>$(x_1,\dots,  x_i, \dots, x_t)$</code>
<ul>
<li><code>$x_i:$</code> 단어(token)</li>
</ul>
</li>
</ul>
<h2 id="생성망-g_theta">생성망 <code>$G_\theta$</code></h2>
<p><code>$G_\theta:$</code> 파라미터가 <code>$\theta$</code>인 생성망</p>
<ol>
<li>
<p><strong><code>$s_t$</code>를 전체 어휘 분포와 매핑시킨다.</strong></p>
<p>ex) <code>$x_{t+1}$</code>에서 <code>$G_\theta( \cdot | s_t)$</code> 학습</p>
</li>
<li>
<p><strong>분별망이 유출해준 정보를 계층 구조를 통해 효과적으로 포함하여 문장을 생성한다.</strong></p>
</li>
</ol>
<h3 id="생성망의-계층-구조">생성망의 계층 구조</h3>
<p>D의 유출된 정보를 이용하기 위한 MANAGER-WORKER 계층 구조</p>
<ul>
<li>
<p><strong>MANAGER</strong>: <code>$t$</code>시점마다 추출된 <code>$f_t$</code>를 활용해 <code>$g_t$</code> 생성</p>
<p><code>$f_t$</code>를 LSTM에 입력한 후 goal vector <code>$g_t$</code>를 생성한다.</p>
<p><code>$$ \begin{aligned} \hat{g}_t, h_t^M &amp; = \mathcal{M}\left(f_t, h_{t-1}^M; \theta_m \right)\\ g_t &amp; =\hat{g}_t /\left|\hat{g}_t\right| \end{aligned} $$</code></p>
<ul>
<li>
<p><code>$M:$</code> LSTM 모델</p>
</li>
<li>
<p><code>$\mathcal{M}:$</code> MANAGER 모듈</p>
</li>
<li>
<p><code>$\theta_m :$</code>  <code>$\mathcal M$</code>의 파라미터</p>
</li>
<li>
<p><code>$h_t:$</code> t시점의 hidden state</p>
</li>
<li>
<!-- raw HTML omitted -->
<ul>
<li>
<p><code>init, init_params</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> __init__(self, batch_size, hidden_dim, goal_out_size):
</span></span><span style="display:flex;"><span>        super(Manager, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>batch_size <span style="color:#f92672">=</span> batch_size
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>hidden_dim <span style="color:#f92672">=</span> hidden_dim
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>goal_out_size <span style="color:#f92672">=</span> goal_out_size
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>recurrent_unit <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>LSTMCell(
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>goal_out_size, <span style="color:#75715e">#input size</span>
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>hidden_dim <span style="color:#75715e">#hidden size</span>
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>hidden_dim, <span style="color:#75715e">#in_features</span>
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>goal_out_size <span style="color:#75715e">#out_features</span>
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>goal_init <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Parameter(torch<span style="color:#f92672">.</span>zeros(self<span style="color:#f92672">.</span>batch_size, self<span style="color:#f92672">.</span>goal_out_size))
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>_init_params()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_init_params</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> param <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>parameters():
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>normal_(param, std<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>goal_init<span style="color:#f92672">.</span>data <span style="color:#f92672">=</span> truncated_normal(
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>goal_init<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>shape
</span></span><span style="display:flex;"><span>        )
</span></span></code></pre></div></li>
<li>
<p><strong><code>forward</code></strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, f_t, h_m_t, c_m_t):
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  f_t = feature of CNN from discriminator leaked at time t, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                     it is input into LSTM
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  h_m_t = ouput of previous LSTMCell
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  c_m_t = previous cell state
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>  h_m_tp1, c_m_tp1 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>recurrent_unit(f_t, (h_m_t, c_m_t))
</span></span><span style="display:flex;"><span>  sub_goal <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>fc(h_m_tp1)
</span></span><span style="display:flex;"><span>	<span style="color:#75715e"># 하위 텐서의 p-norm이 값 maxnorm보다 낮도록 </span>
</span></span><span style="display:flex;"><span>	<span style="color:#75715e"># 차원에 따라 입력의 각 하위 텐서가 정규화되는 텐서를 반환한다.</span>
</span></span><span style="display:flex;"><span>  sub_goal <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>renorm(sub_goal, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1.0</span>)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> sub_goal, h_m_tp1, c_m_tp1
</span></span></code></pre></div></li>
</ul>
<!-- raw HTML omitted -->
</li>
</ul>
</li>
<li>
<p><strong>WORKER</strong>: MANAGER의 <code>$g_t$</code>를 토대로 보상을 높이는 다음 단어 생성</p>
<p>MANAGER의 <code>$g_t$</code>를 포함하기 위해 가중치 행렬 <code>$W_\psi$</code>로 최근 c개의 목표들에 대한 선형 변환을 수행한다.</p>
<p>이를 통해 k차원의 goal embedding vector <code>$w_t$</code>를 얻는다.</p>
<p><code>$$ w_t=\psi\left(\sum_{i=1}^c g_{t-i}\right)=W_\psi\left(\sum_{i=1}^c g_{t-i}\right) $$</code></p>
<ul>
<li><code>$\psi:$</code> 선형 변환(행렬 곱셈)</li>
</ul>
<p><code>$$ \begin{aligned}O_t, h_t^W &amp; =\mathcal{W}\left(x_t, h_{t-1}^W ; \theta_w\right) \\ G_\theta\left(\cdot \mid s_t\right) &amp; =\operatorname{softmax}\left(O_t \cdot w_t / \alpha\right) \end{aligned} $$</code></p>
<ul>
<li>
<p><code>$\mathcal W:$</code> WORKER 모듈</p>
</li>
<li>
<p><code>$x_t:$</code> input. (t 시점의 단어)</p>
</li>
<li>
<p><code>$\theta_w :$</code>  <code>$\mathcal W$</code>의 파라미터</p>
</li>
<li>
<p><code>$O_t :$</code> 행렬 내적으로 <code>$w_t$</code>와 추가로 결합된 행렬. <code>$\|V\| \times k$</code></p>
<p>모든 단어에 대한 벡터 집합을 의미한다.</p>
<p>따라서, <code>$O_t \cdot w_t$</code> 는 모든 단어에 대해 logit을 계산한다.</p>
</li>
<li>
<p><code>$\alpha :$</code>  generation entropy를 조절하기 위한 temperature parameter</p>
<p>즉, 생성되는 문장의 참신함을 조절한다.</p>
</li>
</ul>
<p>softmax를 통해 현재까지 생성된 단어 집합 <code>$s_t$</code>에서 최종 action space 분포를 결정한다.</p>
<ul>
<li>
<!-- raw HTML omitted -->
<ul>
<li>
<p><code>init, init_params</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> __init__(self, batch_size, vocab_size, embed_dim, hidden_dim, 
</span></span><span style="display:flex;"><span>                goal_out_size, goal_size):
</span></span><span style="display:flex;"><span>    super(Worker, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>batch_size <span style="color:#f92672">=</span> batch_size
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>vocab_size <span style="color:#f92672">=</span> vocab_size
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>embed_dim <span style="color:#f92672">=</span> embed_dim
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>hidden_dim <span style="color:#f92672">=</span> hidden_dim
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>goal_out_size <span style="color:#f92672">=</span> goal_out_size
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>goal_size <span style="color:#f92672">=</span> goal_size
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">**</span>self<span style="color:#f92672">.</span>emb <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Embedding(self<span style="color:#f92672">.</span>vocab_size, self<span style="color:#f92672">.</span>embed_dim)<span style="color:#f92672">**</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">**</span>self<span style="color:#f92672">.</span>recurrent_unit <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>LSTMCell(self<span style="color:#f92672">.</span>embed_dim, self<span style="color:#f92672">.</span>hidden_dim)<span style="color:#f92672">**</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">**</span>self<span style="color:#f92672">.</span>fc <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(self<span style="color:#f92672">.</span>hidden_dim, self<span style="color:#f92672">.</span>goal_size<span style="color:#f92672">*</span>self<span style="color:#f92672">.</span>vocab_size)<span style="color:#f92672">**</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">**</span>self<span style="color:#f92672">.</span>goal_change <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Parameter(torch<span style="color:#f92672">.</span>zeros(self<span style="color:#f92672">.</span>goal_out_size, self<span style="color:#f92672">.</span>goal_size))<span style="color:#f92672">**</span>
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>_init_params()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_init_params</span>(self):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> param <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>parameters():
</span></span><span style="display:flex;"><span>        nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>normal_(param, std<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>)
</span></span></code></pre></div></li>
<li>
<p><strong><code>forward</code></strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x_t, h_w_t, c_w_t):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        x_t = last word
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        h_w_t = last output of LSTM in Worker
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        c_w_t = last cell state of LSTM in Worker
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    x_t_emb <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>emb(x_t)
</span></span><span style="display:flex;"><span>    h_w_tp1, c_w_tp1 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>recurrent_unit(x_t_emb, (h_w_t, c_w_t))
</span></span><span style="display:flex;"><span>    output_tp1 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>fc(h_w_tp1)
</span></span><span style="display:flex;"><span>    output_tp1 <span style="color:#f92672">=</span> output_tp1<span style="color:#f92672">.</span>view(self<span style="color:#f92672">.</span>batch_size, 
</span></span><span style="display:flex;"><span>																 self<span style="color:#f92672">.</span>vocab_size, 
</span></span><span style="display:flex;"><span>																 self<span style="color:#f92672">.</span>goal_size)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> output_tp1, h_w_tp1, c_w_tp1
</span></span></code></pre></div></li>
</ul>
<!-- raw HTML omitted -->
</li>
</ul>
</li>
</ul>
<h3 id="생성망-g-학습">생성망 G 학습</h3>
<p>앞에서 설명한 G의 모든 과정은 미분 가능한 구조로 되어있다.</p>
<p>따라서, REINFORCE와 같은 policy gradient algorithm을 적용하여 모델을 학습할 수 있다.</p>
<p>LeakGAN 모델이 유의미한 의미 패턴을 찾을 수 있도록 MANAGER와 WORKER는 개별적으로 훈련한다.</p>
<ul>
<li>
<p><strong>MANAGER — 식별 가능한 feature space에서의 이동 방향을 예측하도록 훈련된다.</strong></p>
<p>MANAGER의 gradient</p>
<p><code>$$ \nabla_{\theta_m}^{\mathrm{adv}} g_t=-Q_{\mathcal{F}}\left(s_t, g_t\right) \nabla_{\theta_m} d_{\cos }\left(f_{t+c}-f_t, g_t\left(\theta_m\right)\right) $$</code></p>
<ul>
<li>
<p><code>$Q_{\mathcal{F}}\left(s_t, g_t\right)=Q\left(\mathcal{F}\left(s_t\right), g_t\right)=Q\left(f_t, g_t\right)=\mathbb{E}\left[r_t\right]$</code></p>
<p>몬테 카를로 탐색으로 추정한 현재 정책에 대한 보상 기댓값</p>
</li>
<li>
<p><code>$d_{\cos }:$</code> cosine similarity(similarity인지 distance인지 확인해보기)</p>
<p><code>$c$</code>번의 전환 후 feature representation의 변화<code>$(f_{t+c} - f_t)$</code>와 목적 벡터 <code>$g_t$</code>의 차이</p>
</li>
</ul>
<p>손실 함수에서는 높은 보상을 달성하기 위해 <code>$g_t$</code>가 특징 공간의 전환과 일치하도록 강제한다.</p>
<p><code>$$ \begin{aligned}&amp; \nabla_{\theta_w} \mathbb{E}_{s_{t-1} \sim G}\left[\sum_{x_t} r_t^I \mathcal{W}\left(x_t \mid s_{t-1} ; \theta_w\right)\right]\\ = &amp; \mathbb{E}_{s_{t-1} \sim G, x_t \sim \mathcal{W}\left(x_t \mid s_{t-1}\right)}\left[r_t^I \nabla_{\theta_w} \log \mathcal{W}\left(x_t \mid s_{t-1} ; \theta_w\right)\right]\end{aligned} $$</code></p>
</li>
<li>
<p><strong>WORKER — MANAGER의 지시를 따르도록 보상이 주어진다.</strong></p>
<p>REINFORCE 알고리즘을 활용하여 보상을 최대화한다.</p>
<p>이는 <code>$s_{t-1}$</code> 상태와 함께 WORKER가 취한 <code>$x_t$</code> 작업을 샘플링하여 근사할 수 있다.</p>
<p>WORKER에 제공되는 보상은 다음과 같이 정의된다.</p>
<p><code>$$ r_t^I=\frac{1}{c} \sum_{i=1}^c d_{\cos }\left(f_t-f_{t-i}, g_{t-i}\right) $$</code></p>
</li>
<li>
<p><strong>실제로는 <code>$G_\theta$</code>는 적대적 학습 전에 사전 학습이 필요하다.</strong></p>
<p>사전 학습 시 일관성을 유지하기 위해 MANAGER의 기울기를 통한 별도의 훈련 체계를 사용한다.</p>
<p><code>$$ \nabla_{\theta_m}^{\mathrm{pre}} g_t=-\nabla_{\theta_m} d_{\cos }\left(\hat{f}_{t+c}-\hat{f}_t, g_t\left(\theta_m\right)\right) $$</code></p>
<ul>
<li><code>$\hat{f}_t=\mathcal{F}\left(\hat{s}_t\right), \hat s_t, \hat s_{t + c}:$</code> 실제 텍스트의 상태</li>
</ul>
<p>해당 수식은 앞에서 정의한 MANAGER 미분식에서 <code>$Q_{\mathcal{F}}\left(s_t, g_t\right)$</code>가 <code>$1$</code>인 상태이다.</p>
<p>사전 학습에 사용된 데이터는 모두 실제 문장이기 때문이다.</p>
<p>feature space에서 실제 문장 샘플의 전환을 모방하도록 학습된다.</p>
<p>MLE(Maximum Likelihood Estimation)를 통해 훈련된다.</p>
</li>
</ul>
<p>학습 과정에서 <code>$G_\theta$</code>와 <code>$D_\phi$</code>는 번갈아가며 훈련된다.</p>
<p>생성망에서도 MANAGER와 WORKER는 번갈아가며 서로를 고정한 채 훈련된다.</p>
<h2 id="분별망-d_phi">분별망 <code>$D_\phi$</code></h2>
<p><code>$D_\phi:$</code> 파라미터가 <code>$\phi$</code>인 분별망</p>
<h3 id="1-scalar-guiding-signal-d_phis-제공">1. <strong>Scalar Guiding Signal <code>$D_\phi(s)$</code> 제공</strong></h3>
<p>전체 문장 <code>$s_T$</code>가 생성된 후 생성망이 파라미터를 조정할 때 가이드 역할을 한다.</p>
<p>이 때, <code>$D_\phi(s)$</code>는 문장이 길어질수록 정보량이 적어지므로, 이를 해결하기 위해 추가적인 정보 <code>$f_t$</code>를 제공한다.</p>
<h3 id="guiding-signalleaked-features">Guiding Signal(Leaked Features)</h3>
<p><code>$$ D_\phi(s)=\operatorname{sigmoid}\left(\phi_l^{\top} \mathcal{F}\left(s ; \phi_f\right)\right)=\operatorname{sigmoid}\left(\phi_l^{\top} f\right) $$</code></p>
<ul>
<li><code>$s:$</code> input. 생성된 문장.</li>
<li><code>$\mathcal F:$</code> CNN (특징맵 추출기)</li>
<li><code>$f : D_\phi(s)$</code> 의 마지막 Layer에서의 feature vector(유출된 정보)</li>
<li><code>$\phi_l^{\top}:$</code> 가중치 벡터</li>
</ul>
<p>즉, <code>$f$</code>에 의해 Reward Value가 결정되기 때문에, 보상을 높이도록 feature(특징맵)을 뽑아야 한다.</p>
<p>LeakGAN에서는 Feature Extractor로 CNN을 활용하지만, LSTM이나 다른 신경망을 활용하여 구현할 수도 있다.</p>
<h3 id="2-f_t--s_t에서의-features">2. <strong><code>$f_t = s_t$</code>에서의 features</strong></h3>
<p><code>$f_t$</code>는 분별망이 분별을 위해서 쓰이는 정보이기도 하다.</p>
<p>따라서, 전역적으로 관리된다.</p>
<h3 id="3-learned-reward-function을-설정한다">3. <strong>Learned Reward Function을 설정한다.</strong></h3>
<p>Black Box인 기존 RL 모델들과 대비된다.</p>
<ul>
<li>
<!-- raw HTML omitted -->
<p>text 분류를 위한 CNN 모델</p>
<p>num_filters (int): This is the output dim for each convolutional layer, which is the number of &ldquo;filters&rdquo; learned by that layer.</p>
<ul>
<li>
<p><code>__init__</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> __init__(self, seq_len, num_classes, vocab_size, dis_emb_dim, 
</span></span><span style="display:flex;"><span>             filter_sizes, num_filters, start_token, goal_out_size, 
</span></span><span style="display:flex;"><span>						 step_size, dropout_prob, l2_reg_lambda):
</span></span><span style="display:flex;"><span>    super(Discriminator, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>seq_len <span style="color:#f92672">=</span> seq_len
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>num_classes <span style="color:#f92672">=</span> num_classes
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>vocab_size <span style="color:#f92672">=</span> vocab_size
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>dis_emb_dim <span style="color:#f92672">=</span> dis_emb_dim
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>filter_sizes <span style="color:#f92672">=</span> filter_sizes
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>num_filters <span style="color:#f92672">=</span> num_filters
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>start_token <span style="color:#f92672">=</span> start_token
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>goal_out_size <span style="color:#f92672">=</span> goal_out_size
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>step_size <span style="color:#f92672">=</span> step_size
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>dropout_prob <span style="color:#f92672">=</span> dropout_prob
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>l2_reg_lambda <span style="color:#f92672">=</span> l2_reg_lambda
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>num_filters_total <span style="color:#f92672">=</span> sum(self<span style="color:#f92672">.</span>num_filters)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#Building up layers</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">**</span>self<span style="color:#f92672">.</span>emb <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Embedding(self<span style="color:#f92672">.</span>vocab_size <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>, self<span style="color:#f92672">.</span>dis_emb_dim)<span style="color:#f92672">**</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">**</span>self<span style="color:#f92672">.</span>convs <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ModuleList([
</span></span><span style="display:flex;"><span>        nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">1</span>, num_f, 
</span></span><span style="display:flex;"><span>									(f_size, self<span style="color:#f92672">.</span>dis_emb_dim))
</span></span><span style="display:flex;"><span>				<span style="color:#66d9ef">for</span> f_size, num_f <span style="color:#f92672">in</span> zip(self<span style="color:#f92672">.</span>filter_sizes, self<span style="color:#f92672">.</span>num_filters)
</span></span><span style="display:flex;"><span>    ])<span style="color:#f92672">**</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">**</span>self<span style="color:#f92672">.</span>highway <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(self<span style="color:#f92672">.</span>num_filters_total, 
</span></span><span style="display:flex;"><span>															self<span style="color:#f92672">.</span>num_filters_total)<span style="color:#f92672">**</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#in_features = out_features = sum of num_festures</span>
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>dropout <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Dropout(p <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>dropout_prob)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#Randomly zeroes some of the elements of the input tensor </span>
</span></span><span style="display:flex;"><span>		<span style="color:#75715e"># with probability p using Bernouli distribution</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#Each channel will be zeroed independently onn every forward call</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">**</span>self<span style="color:#f92672">.</span>fc <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(self<span style="color:#f92672">.</span>num_filters_total, self<span style="color:#f92672">.</span>num_classes)<span style="color:#f92672">**</span>
</span></span></code></pre></div></li>
<li>
<p>highway</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Highway</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#Highway Networks = Gating Function To Highway = y = xA^T + b</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, in_size, out_size):
</span></span><span style="display:flex;"><span>        super(Highway, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(in_size, out_size)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(in_size, out_size)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#highway = F.sigmoid(highway)*F.relu(highway) + (1. - transform)*pred # sets C = 1 - T</span>
</span></span><span style="display:flex;"><span>        g <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>relu(self<span style="color:#f92672">.</span>fc1)
</span></span><span style="display:flex;"><span>        t <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>sigmoid(self<span style="color:#f92672">.</span>fc2)
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> g<span style="color:#f92672">*</span>t <span style="color:#f92672">+</span> (<span style="color:#ae81ff">1.</span> <span style="color:#f92672">-</span> t)<span style="color:#f92672">*</span>x
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> out
</span></span></code></pre></div><p>t가 1이면 out = g</p>
<p>t가 0이면 out = x</p>
<p>t는 torch.sigmoid(self.fc2)에 의해 결정됨.</p>
</li>
<li>
<p>truncated_norm : 난수(절단된 정규분포)로 가중치 초기화에 사용</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy.stats <span style="color:#f92672">import</span> truncnorm
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn.functional <span style="color:#66d9ef">as</span> F
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">truncated_normal</span>(shape, lower<span style="color:#f92672">=-</span><span style="color:#ae81ff">0.2</span>, upper<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>):
</span></span><span style="display:flex;"><span>    size <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> dim <span style="color:#f92672">in</span> shape:
</span></span><span style="display:flex;"><span>        size <span style="color:#f92672">*=</span> dim
</span></span><span style="display:flex;"><span>    w_truncated <span style="color:#f92672">=</span> truncnorm<span style="color:#f92672">.</span>rvs(lower, upper, size<span style="color:#f92672">=</span>size)
</span></span><span style="display:flex;"><span>    w_truncated <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>from_numpy(w_truncated)<span style="color:#f92672">.</span>float()
</span></span><span style="display:flex;"><span>    w_truncated <span style="color:#f92672">=</span> w_truncated<span style="color:#f92672">.</span>view(shape)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> w_truncated
</span></span></code></pre></div></li>
<li>
<p><strong>forward</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Argument:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        x: shape(batch_size * self.seq_len)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">           type(Variable containing torch.LongTensor)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Return:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        pred: shape(batch_size * 2)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              For each sequence in the mini batch, output the probability
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              of it belonging to positive sample and negative sample.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        feature: shape(batch_size * self.num_filters_total)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                 Corresponding to f_t in original paper
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        score: shape(batch_size, self.num_classes)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#1. Embedding Layer</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#2. Convolution + maxpool layer for each filter size</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#3. Combine all the pooled features into a prediction</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#4. Add highway</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#5. Add dropout. This is when feature should be extracted</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#6. Final unnormalized scores and predictions</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    emb <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>emb(x)<span style="color:#f92672">.</span>unsqueeze(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    convs <span style="color:#f92672">=</span> [F<span style="color:#f92672">.</span>relu(conv(emb))<span style="color:#f92672">.</span>squeeze(<span style="color:#ae81ff">3</span>) <span style="color:#66d9ef">for</span> conv <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>convs] <span style="color:#75715e"># [batch_size * num_filter * seq_len]</span>
</span></span><span style="display:flex;"><span>    pooled_out <span style="color:#f92672">=</span> [F<span style="color:#f92672">.</span>max_pool1d(conv, conv<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">2</span>))<span style="color:#f92672">.</span>squeeze(<span style="color:#ae81ff">2</span>) <span style="color:#66d9ef">for</span> conv <span style="color:#f92672">in</span> convs] <span style="color:#75715e"># [batch_size * num_filter]</span>
</span></span><span style="display:flex;"><span>    pred <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat(pooled_out, <span style="color:#ae81ff">1</span>) <span style="color:#75715e"># batch_size * sum(num_filters)</span>
</span></span><span style="display:flex;"><span>    highway <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>highway(pred)
</span></span><span style="display:flex;"><span>    highway <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>sigmoid(highway)<span style="color:#f92672">*</span> F<span style="color:#f92672">.</span>relu(highway) <span style="color:#f92672">+</span> (<span style="color:#ae81ff">1.0</span> <span style="color:#f92672">-</span> torch<span style="color:#f92672">.</span>sigmoid(highway))<span style="color:#f92672">*</span>pred
</span></span><span style="display:flex;"><span>    features <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>dropout(highway)
</span></span><span style="display:flex;"><span>    score <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>fc(features)
</span></span><span style="display:flex;"><span>    pred <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>log_softmax(score, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>) <span style="color:#75715e">#batch * num_classes</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> {<span style="color:#e6db74">&#34;pred&#34;</span>:pred, <span style="color:#e6db74">&#34;feature&#34;</span>:features, <span style="color:#e6db74">&#34;score&#34;</span>: score}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">l2_loss</span>(self):
</span></span><span style="display:flex;"><span>    W <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>fc<span style="color:#f92672">.</span>weight
</span></span><span style="display:flex;"><span>    b <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>fc<span style="color:#f92672">.</span>bias
</span></span><span style="display:flex;"><span>    l2_loss <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>sum(W<span style="color:#f92672">*</span>W) <span style="color:#f92672">+</span> torch<span style="color:#f92672">.</span>sum(b<span style="color:#f92672">*</span>b)
</span></span><span style="display:flex;"><span>    l2_loss <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>l2_reg_lambda <span style="color:#f92672">*</span> l2_loss
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> l2_loss
</span></span></code></pre></div></li>
</ul>
<!-- raw HTML omitted -->
</li>
</ul>
<h2 id="학습-기술">학습 기술</h2>
<h3 id="bootstrapped-rescaled-activation"><strong>Bootstrapped Rescaled Activation</strong></h3>
<ul>
<li>
<p>배경</p>
<p>SeqGAN의 적대적 훈련 과정에서, <code>$D$</code>가 <code>$G$</code>보다 너무 강한 경우 심각한 gradient 소멸 문제가 발생한다.</p>
<p>즉, 파라미터를 갱신하기에 보상이 너무 작기 때문에 <code>$G$</code>에게 값을 넘기기 전에 스케일 조정이 필요하다.</p>
</li>
</ul>
<p>RankGAN로부터 영감을 받은 rank 기반 방법</p>
<p>보상 행렬 : <code>$R_{B\times T}$</code></p>
<ul>
<li>
<p>다음 수식으로 <code>$t$</code>번째 열 벡터 <code>$R^t$</code>의 스케일을 재조정한다.</p>
<p><code>$$ R_i^t=\sigma\left(\delta \cdot\left(0.5-\frac{\operatorname{rank}(i)}{B}\right)\right) $$</code></p>
</li>
<li>
<p><code>$\text {rank}(i):$</code> 열 벡터에서 i번째 원소의 ranking</p>
</li>
<li>
<p><code>$\delta :$</code> rescale 작업의 smoothness를 조정하는 하이퍼 파라미터</p>
</li>
<li>
<p><code>$\sigma(\cdot) :$</code>  활성 함수(논문에서는 sigmoid)</p>
<p>등간격 점수를 rank 기반으로 보다 효과적인 분포로 재구성한다.</p>
</li>
</ul>
<p><strong>장점</strong></p>
<ol>
<li>
<p>각 미니 배치에서 보상의 기대와 분산이 일정하다.</p>
<p>값을 안정시켜 수치형 분산에 민감한 알고리즘에 도움이 된다.</p>
</li>
<li>
<p><em>모든 ranking 방법과 동일하게</em>, 모델 수렴을 가속화하는 gradient 소실 문제를 방지한다.</p>
</li>
</ol>
<h3 id="interleaved-training">Interleaved Training</h3>
<p>사전 훈련 후 전부 GAN으로 학습하는 대신 일부는 지도 학습(ex — MLE)으로, 일부는 적대적 학습(ex — GAN)을 적용한다.</p>
<p>ex) 1 epoch 지도 학습 + 15 epoch 적대적 학습</p>
<ul>
<li>GAN이 local minima를 제거하는 데 도움을 준다.</li>
<li>mode collapse를 예방한다.</li>
</ul>
<p>삽입된 지도 학습이 생성 모델에 대해 암시적 규제를 수행하여 MLE 결과로부터 너무 멀리 떨어지는 것을 방지한다.</p>
<h3 id="temperature-control">Temperature Control</h3>
<p>볼츠만 temperature <code>$\alpha$</code>.</p>
<p>탐험와 탐사의 균형을 맞추는 데 사용할 수 있는 요소</p>
<ul>
<li>모델 훈련 시 높은 temperature 설정</li>
<li>샘플 생성을 위해 모델 적용 시 낮은 temperature 설정</li>
</ul>
<h2 id="pseudo-code">Pseudo Code</h2>
<p><img src="/imgs/leakgan1.png" alt="leakgan"></p>
<h3 id="필요한-요소"><strong>필요한 요소</strong></h3>
<ul>
<li>
<p><strong>계층 구조 생성망 <code>$G(θ_m, θ_w)$</code></strong></p>
<p>MANAGER와 WORKER로 구성</p>
</li>
<li>
<p><strong>분별망 <code>$D(φ)$</code></strong></p>
<p>이진 분류기</p>
</li>
<li>
<p><strong>훈련 데이터 셋</strong></p>
<p>시퀀스 데이터 집합 <code>$S = {X_1:T}$</code></p>
</li>
</ul>
<h3 id="알고리즘-단계"><strong>알고리즘 단계</strong></h3>
<ol>
<li>
<p><strong>파라미터 초기화</strong></p>
<p><code>$G(θ_m, θ_w), D(φ)$</code>를 랜덤 가중치 <code>$θ_m, θ_w, φ$</code>로 초기화</p>
</li>
<li>
<p><strong>사전 학습</strong></p>
<ol>
<li>
<p><code>$**D(φ)$</code> 사전 학습**</p>
<p><code>$D(φ)$</code>를 시퀀스 데이터 집합 <code>$S$</code>를 양성 샘플로,
<code>$G$</code>에서 생성된 시퀀스를 음성 샘플로 사용하여 사전 학습한다.</p>
<p>이때, <code>$D(φ)$</code>는 특징 추출기(<code>$\mathcal F$</code>)와 출력 레이어(sigmoid)로 구성된다.</p>
<p><code>$$ D_\phi(s)=\operatorname{sigmoid}\left(\phi_l^{\top} \mathcal{F}\left(s ; \phi_f\right)\right)=\operatorname{sigmoid}\left(\phi_l^{\top} f\right) $$</code></p>
</li>
<li>
<p><code>$**G(θ_m, θ_w)$</code> 사전 학습**</p>
<p><code>$D(φ)$</code>로부터 유출된 정보를 사용하여 학습한다.</p>
</li>
</ol>
</li>
<li>
<p><strong>사전 학습을 수렴할 때까지 번갈아 수행한다.</strong></p>
</li>
<li>
<p><strong>적대적 학습</strong></p>
<ul>
<li>
<p><strong>생성망 단계 (g-steps)</strong></p>
<ul>
<li>
<p><code>$G(θ)$</code>를 사용하여 시퀀스 <code>$Y_1:T$</code>를 생성</p>
</li>
<li>
<p>각 <code>$t$</code>에 대해 <code>$D(φ)$</code>로부터 유출된 정보 <code>$f_t$</code>를 저장</p>
</li>
<li>
<p><code>$Q\left(f_t, g_t\right)=\mathbb{E}\left[r_t\right]$</code>을 통해 Monte Carlo Search를 사용하여 <code>$Q(f_t, g_t)$</code>를 얻어낸다.</p>
</li>
<li>
<p>MANAGER로부터 계산된 방향 <code>$g_t$</code>를 얻는다.</p>
</li>
<li>
<p>WORKER 매개변수 <code>$θ_w, ψ$</code>, softmax를 갱신한다.</p>
<p><code>$$ \begin{aligned} &amp; \nabla_{\theta_w} \mathbb{E}_{s_{t-1} \sim G}\left[\sum_{x_t} r_t^I \mathcal{W}\left(x_t \mid s_{t-1} ; \theta_w\right)\right] \\ = &amp; \mathbb{E}_{s_{t-1} \sim G, x_t \sim \mathcal{W}\left(x_t \mid s_{t-1}\right)}\left[r_t^I \nabla_{\theta_w} \log \mathcal{W}\left(x_t \mid s_{t-1} ; \theta_w\right)\right] \end{aligned} $$</code></p>
</li>
<li>
<p>MANAGER 매개변수 <code>$θ_m$</code>을 갱신한다.</p>
<p><code>$$ \nabla_{\theta_m}^{\mathrm{adv}} g_t=-Q\left(f_t, g_t\right) \nabla_{\theta_m} d_{\cos }\left(\mathcal{F}\left(s_{t+c}\right)-\mathcal{F}\left(s_t\right), g_t\left(\theta_m\right)\right) $$</code></p>
</li>
</ul>
</li>
<li>
<p><strong>분별망 단계 (d-steps)</strong></p>
<ul>
<li>
<p>현재 <code>$G(θ_m, θ_w)$</code>를 사용하여 음성 예제를 생성하고 주어진 양성 예제 S와 결합한다.</p>
</li>
<li>
<p>k-epoch 동안 <code>$D(φ)$</code>를 훈련한다.</p>
<p><code>$$ D_\phi(s)=\operatorname{sigmoid}\left(\phi_l \cdot \mathcal{F}\left(s ; \phi_f\right)\right)=\operatorname{sigmoid}\left(\phi_l, f\right) $$</code></p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>LeakGAN이 수렴할 때까지 반복한다.</strong></p>
</li>
</ol>
<h3 id="참고">참고</h3>
<p><a href="https://arxiv.org/abs/1709.08624">Long Text Generation via Adversarial Training with Leaked Information</a></p>
<p><a href="https://paperswithcode.com/task/text-generation">Papers with Code - Text Generation</a></p>
<p><a href="https://github.com/nurpeiis/LeakGAN-PyTorch">LeakGAN Implement code with PyTorch - github</a></p>

        </p>
        
    </div>

    <div class="prev-next">
        
    </div>

    
    
    <svg id="btt-button" class="arrow-logo" xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 384 512" onclick="topFunction()" title="Go to top">
        
        <path d="M177 159.7l136 136c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0L160 255.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9 0L7 329.7c-9.4-9.4-9.4-24.6 0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1z"/>
    </svg>
    
    <script>
        let backToTopButton = document.getElementById("btt-button");

        window.onscroll = function() {
            scrollFunction()
        };

        function scrollFunction() {
            if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
                backToTopButton.style.display = "block";
            } else {
                backToTopButton.style.display = "none";
            }
        }

        function topFunction() {
            smoothScrollToTop();
        }

        function smoothScrollToTop() {
            const scrollToTop = () => {
                const c = document.documentElement.scrollTop || document.body.scrollTop;
                if (c > 0) {
                    window.requestAnimationFrame(scrollToTop);
                    window.scrollTo(0, c - c / 8);
                }
            };
            scrollToTop();
        }
    </script>
    
    
    <div id="tex">
        <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script> 
    </div>
    
</div>

<aside class="post-toc">
    <nav id="toc">
        <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#배경">배경</a>
          <ul>
            <li><a href="#1-rnn--문장-생성을-위한-가장-기본적인-방법">1. <strong>RNN – 문장 생성을 위한 가장 기본적인 방법</strong></a></li>
            <li><a href="#2-gan--목적은-생성망-g의-성능을-개선하는-것">2. <strong>GAN – 목적은 생성망 G의 성능을 개선하는 것</strong></a></li>
            <li><a href="#3-gan의-한계-및-해결책"><strong>3. GAN의 한계 및 해결책</strong></a></li>
          </ul>
        </li>
        <li><a href="#아이디어">아이디어</a>
          <ul>
            <li><a href="#manager-lstm"><strong>MANAGER (LSTM)</strong></a></li>
            <li><a href="#worker-lstm"><strong>WORKER (LSTM)</strong></a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#구체적-방법론">구체적 방법론</a>
      <ul>
        <li><a href="#생성망-g_theta">생성망 <code>$G_\theta$</code></a>
          <ul>
            <li><a href="#생성망의-계층-구조">생성망의 계층 구조</a></li>
            <li><a href="#생성망-g-학습">생성망 G 학습</a></li>
          </ul>
        </li>
        <li><a href="#분별망-d_phi">분별망 <code>$D_\phi$</code></a>
          <ul>
            <li><a href="#1-scalar-guiding-signal-d_phis-제공">1. <strong>Scalar Guiding Signal <code>$D_\phi(s)$</code> 제공</strong></a></li>
            <li><a href="#guiding-signalleaked-features">Guiding Signal(Leaked Features)</a></li>
            <li><a href="#2-f_t--s_t에서의-features">2. <strong><code>$f_t = s_t$</code>에서의 features</strong></a></li>
            <li><a href="#3-learned-reward-function을-설정한다">3. <strong>Learned Reward Function을 설정한다.</strong></a></li>
          </ul>
        </li>
        <li><a href="#학습-기술">학습 기술</a>
          <ul>
            <li><a href="#bootstrapped-rescaled-activation"><strong>Bootstrapped Rescaled Activation</strong></a></li>
            <li><a href="#interleaved-training">Interleaved Training</a></li>
            <li><a href="#temperature-control">Temperature Control</a></li>
          </ul>
        </li>
        <li><a href="#pseudo-code">Pseudo Code</a>
          <ul>
            <li><a href="#필요한-요소"><strong>필요한 요소</strong></a></li>
            <li><a href="#알고리즘-단계"><strong>알고리즘 단계</strong></a></li>
            <li><a href="#참고">참고</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
    </nav>
</aside>


    

        </main><footer class="footer">
    
    

    
    <span>&copy; 2024 오뚝이 개발자</span>
    
</footer>
</body>
</html>
